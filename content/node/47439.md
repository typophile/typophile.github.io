---
author:
  name: Ehague
  picture: 112252
body: "I have a coworker who maintains that the best practice for shrinking an image
  in PS is to decrease the image size in 10% (or smaller) increments until the desired
  width is achieved. The reasoning is that by making smaller jumps each time, PS has
  less opportunity for error.\r\n\r\nHaving tried this, specifically with rasterized
  PDFs with lots of small text, I've come to the position that you can achieve better
  results by simply jumping straight to the desired size of the image. The reasoning
  is that fewer resamplings = fewer errors, and also that the 10% method seems too
  time consuming and too easily, invisibly automated for it to still be necessary
  in CS3.\r\n\r\nWhat is the best practice? Is this something to do with older versions
  of PS/CS? "
comments:
- author:
    name: david h
    picture: 110928
  body: "10%, 15%, or 20% that's not the important factor. \r\n\r\nThe important factor
    is the interpolation setting: Bicubic Sharper; Bicubic; Bicubic Smoother. "
  created: '2008-07-15 20:29:14'
- author:
    name: jselig
  body: I'd be interested to see where 10% increments in recommended. I've not heard
    of that one before. As david said, it's the interpolation that matters most in
    resizing.
  created: '2008-07-15 20:47:32'
- author:
    name: jonathanhughes
  body: "It seems that for the reasons specified (fewer resamplings = fewer errors)
    that it's a myth. But I think the difference would be barely noticeable.\r\n\r\nI
    just tried it with an image going down to about 50% of the original size, and
    then taking a copy of the original and scaling it down to the exact size of the
    resized image. I layered the two images on top of each other and had to blow it
    up to 300% before I saw any difference (and the difference was just a few pixels
    in some highlight areas).\r\n\r\n\r\n\r\n\r\n"
  created: '2008-07-15 21:16:36'
- author:
    name: bojev
    picture: 110659
  body: Eric, it is a Graphic Design Urban Myth - David is correct it is the interpolation
    setting - just follow Adobe's recs in Image Size.
  created: '2008-07-15 21:57:04'
- author:
    name: charles ellertson
  body: 'Actually, you''ll get the sharpest image using "nearest neighbor." I use
    this when sampling down what will be a bilevel image, and occasionally for grayscale.
    Sharper is not always better, BTW. For grayscale, it is also helpful to work on
    your intermediate images in 16-bit, and apply curves, levels, etc. as layers.
    Cuts down on posturization.  '
  created: '2008-07-16 03:29:36'
- author:
    name: cerulean
    picture: 129904
  body: "\"The reasoning is that by making smaller jumps each time, PS has less opportunity
    for error.\"\r\n\r\n...What does that even <em>mean?</em> It's not a toddler crossing
    a brook. It's a computer program blending color values together.\r\n\r\nIf you
    halve the size of an image, each new pixel is made from four pixels from the original.
    You can do this three times and it will be exactly the same as if you reduced
    it directly to an eighth of the original size. However, if the ratio isn't whole
    -- that is, if one pixel in the new image corresponds to about 1.1 pixels in the
    original image, for example -- then every resampling will introduce a small amount
    of blur. So, yes, you want to minimize the number of times you do that.\r\n\r\n[img:sites/default/files/old-images/reductioncompare_5405.png]\r\nLeft:
    an image reduced to 95% ten times. Right: the same image reduced to 60% once."
  created: '2008-07-16 08:13:53'
- author:
    name: david h
    picture: 110928
  body: "> Actually, you\u2019ll get the sharpest image using \u201Cnearest neighbor.\u201D
    I use this when sampling down...\r\n\r\nI hope not with photos. This is the  lowest
    quality!\r\n\r\nNearest Neighbor: With this interpolation Photoshop simply looks
    side to side and makes the decision of what the new value (pixel) should be. Very
    basic, fast, lousy. However, lines, graphic shapes are fine with NN.  "
  created: '2008-07-16 18:48:58'
- author:
    name: charles ellertson
  body: "<cite>I hope not with photos. This is the lowest quality!</cite>\r\n\r\n\"Quality\"
    is a term that needs to be used with care. But what I said was \"for eventual
    bilevel.\" Usually pictures (\"photos\") are not bilevel. Occasionally you have
    an image (chart, graph) which comes in grayscale, and you do some work on it still
    in the grayscale mode, knowing all the while that you will go to bilevel in the
    end. The reason is you can do some work with curves & such (though I tend to use
    contrast masks) while still in grayscale mode. This will affect just which pixels
    go black and which go white when you select a threshold. NN can also be useful
    when the photo is, say, a shot of an old newspaper article & where you plan on
    a fake bilevel; you don't want the full gamut of tone, but you do want to bring
    out the print.\r\n\r\nWhile I'm no big fan of \"sharpness\" (USM should be banned),
    it does have a place."
  created: '2008-07-16 20:43:47'
- author:
    name: Paul Cutler
    picture: 110643
  body: "It's not a myth, it's just an old workflow. When Adobe introduced Bicubic
    Smoother for upsampling and Bicubic Sharper for downsampling that workflow went
    out the window.\r\n\r\nSharper doesn't always get better results downsampling,
    but it sometimes does and it certainly won't be worse than straight Bicubic.\r\n\r\nThe
    fewer moves you can make in PS the better. You don't want to interpolate an interpolation\u2026\r\n\r\npbc\r\n\r\nAll
    ideas, theories and statements are subject to change without notice."
  created: '2008-07-16 21:04:08'
- author:
    name: hrant
    picture: 110403
  body: "> The reasoning is that by making smaller jumps\r\n> each time, PS has less
    opportunity for error.\r\n\r\nIf I ever compose a dictionary, this will be the
    citation under \"Ludicrous\".\r\nSingle step is always best. Somewhat like measuring
    something with a long\r\nmeasuring tape rather than using a ruler multiple times
    end-to-end.\r\n\r\nAlso, besides the obvious bicubic versus nearest-neighbor stuff,
    here's something less obvious, although still pretty obvious really: you lose
    less quality by going down in even multiples: 50%, 33.33%, 25%, 20%, 16.67%, etc.
    And if you're really picky: before you scale it crop your image according to the
    multiple you're shooting for. For example if you'll be doing a 33.33%, make sure
    your dimensions are multiples of 3. Not that anybody will really see any difference
    in the end result. But it's in there!\r\n\r\nhhp\r\n"
  created: '2008-07-17 06:30:32'
- author:
    name: Ch
    picture: 112205
  body: as cerulean demonstrated, your friend is not only wrong - his method results
    in noticably inferior results. every interpolation is information loss. repeated
    interpolations is repeated information loss. mistake. the interpolation method
    is key, but also it's good to minimize the number of interpolation events.
  created: '2008-07-17 17:25:57'
date: '2008-07-15 20:08:17'
node_type: forum
title: Making Image Smaller/Resampling in Photoshop

---
