---
author:
  name: mike_duggan
  picture: 109519
body: "http://news.bbc.co.uk/2/hi/uk_news/magazine/8234637.stm\r\n\r\n\r\n\r\n"
comments:
- author:
    name: Simplicious
    picture: 117329
  body: "Regarding to the last paragraph: I don't think it's nonsense that lower-case
    letters are easier to read than capitals. The simple reason is that the distinction
    between different lower-case letters is much easier to grasp than the distinction
    between different capitals. I would not like to read a book that's all capitals.\r\n\r\nNevertheless
    I think that using capitals is not a reason for getting fired ;)"
  created: '2009-09-03 11:15:58'
- author:
    name: evanbrog
    picture: 129873
  body: 'It is absolutely harder to read something all caps. There was also a recent
    story on E-60 on ESPN about a guy who was almost completely blind, but didn''t
    want to learn braille because of the stigma. He put books right up to his face
    to read, and used the shapes of the letters to assist him in recognition. '
  created: '2009-09-03 13:40:49'
- author:
    name: riccard0
    picture: 117627
  body: "The reason why it's easier to read lowercase is because, when we read, we
    don't read every single letter, we read <em>words</em>.\r\nWords typed in lowercase
    have far more distinctive shapes."
  created: '2009-09-03 13:56:19'
- author:
    name: Chris Dean
    picture: 111971
  body: "In the beginning:\r\n\r\nBouma, H. (1973). Visual interference in the parafoveal
    recognition of initial and final letters of words, <em>Vision Research</em>, 13,
    762-782.\r\n\r\nFor an easier read check out [[http://en.wikipedia.org/wiki/Bouma|Wikipedia's
    definition of Bouma]].\r\n\r\nFor a slightly more in depth read see Larson's article
    [[http://www.microsoft.com/typography/ctfonts/WordRecognition.aspx|The science
    of word recognition]].\r\n\r\n<strong>HOWEVER</strong>\u2026\r\n\r\nBesner, D.
    (1989). On the role of outline shape and word-specific visual pattern in the identification
    of function words: None. <em>The Quarterly Journal of Experimental Psychology
    A: Human Experimental Psychology, Vol 41(1-A)</em>, Feb 1989. pp. 91-105.\r\n\r\nWhile
    it has been some time since I have read this one, this study, consisting of five
    experiments, showed that cASe aLterAtioN made no <em>significant</em> difference
    on human performance tasks such as naming and decision making. This refutes the
    Bouma law.\r\n\r\nIn my opinion, the jury is still out on this one."
  created: '2009-09-03 14:30:33'
- author:
    name: Maxim Zhukov
    picture: 110611
  body: "I am relieved to know that poor accountant is still alive. In his <a href=\"http://fontfeed.com/archives/erik-spiekermanns-typo-tips/\">Typo
    Tips</a> Erik Spiekermann calls what she did \u201CA Capital Mistake\u201D."
  created: '2009-09-03 14:38:59'
- author:
    name: Kevin Larson
    picture: 109739
  body: "Arditi & Cho argue that uppercase letters are more legible than lowercase
    letters, even when the size differences are taken into account. I think they are
    right.\r\nhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2016788\r\n"
  created: '2009-09-03 16:42:15'
- author:
    name: Chris Dean
    picture: 111971
  body: "From another thread I started, \"[[http://typophile.com/node/61279|Can typography
    save lives?]],\" I reference this study:\r\n\r\nHailstone M., & Foster J.J. (1967).
    Studies of the efficiency of drug labeling. <em>The Journal of Typographic Research,
    1(3)</em>, 275\u2013284.\r\n\r\nIn experiment 2, it showed that at 6 points, CAPS
    were more easily discriminated than Upper and Lower Case. Another case (pun intended)
    that refutes Bouma."
  created: '2009-09-03 16:59:43'
- author:
    name: riccard0
    picture: 117627
  body: "<cite>In experiment 2, it showed that at 6 points, CAPS were more easily
    discriminated than Upper and Lower Case. Another case (pun intended) that refutes
    Bouma.</cite>\r\n\r\nAt 6 points, the fact that caps are larger than lowercase
    would make a difference... Or are we talking about small caps?\r\nThen again,
    were \u201Cmore easily discriminated\u201D the single letters or the words?\r\n\r\nNot
    that I want to defend Bouma at any cost, but I\u2019m more interested in the overall
    legibility of a length of text than in constructed experiments (see also the serif
    vs. sans serif debate).\r\n\r\nI think there\u2019s no doubt about the appropriateness
    of all caps in some cases."
  created: '2009-09-03 18:35:23'
- author:
    name: aluminum
    picture: 110335
  body: "Seems to be a bit of a stretch to do historical forensics on all-caps = yelling
    in email. \r\n\r\nI think it's simply a matter of all-caps being used as emphasis
    in an ascii (early email)/single face (typewritten) world.\r\n\r\nShe wasn't fired
    for using all caps. She was fired for having perceived rude email demeanor. (or
    so says her employer)"
  created: '2009-09-03 19:25:12'
- author:
    name: Chris Dean
    picture: 111971
  body: "@ riccard0: \"<em>Then again, were \u201Cmore easily discriminated\u201D
    the single letters or the words?</em>\"\r\n\r\nParticipants (33 nurses) were searching
    for drug names such as \"Hydroxyzine & Phentolamine\" in a 10 \xD7 10 matrix of
    different drug names."
  created: '2009-09-03 20:05:31'
- author:
    name: Ricardo Cordoba
    picture: 110715
  body: "<em>Nevertheless I think that using capitals is not a reason for getting
    fired ;)</em>\r\n\r\nI think they used that as an excuse. If she had used all
    caps all the time, <em>then</em> maybe people would have found that annoying,
    but in that case her boss could have asked her to use U&lc... But they only presented
    one piece of \"evidence,\" in which one line was in all caps... Very fishy.\r\n\r\nP.S.:
    Related post <a href=\"http://typophile.com/node/61240\">here</a>."
  created: '2009-09-03 20:37:24'
- author:
    name: aluminum
    picture: 110335
  body: "\"I think that using capitals is not a reason for getting fired\"\r\n\r\nWhile
    that was my gut reaction, I've changed positions and now say that it's refreshing
    to see an employer take a stance on typographic integrity in the workforce. ;)"
  created: '2009-09-03 21:26:39'
- author:
    name: Theunis de Jong
    picture: 114717
  body: "it's a precedent;\r\ncertainly bad word\r\nfor our own resident\r\nlowercase
    bird."
  created: '2009-09-03 22:06:25'
- author:
    name: Simplicious
    picture: 117329
  body: "I personally feel more attacked by people who are writing e-mails with an
    average line-length of 300 characters because they are too lazy to hit the \"Enter-Key\".\r\n;)\r\n<em></em>\r\n<cite>\"Participants
    (33 nurses) were searching for drug names such as 'Hydroxyzine & Phentolamine'
    in a 10 \xD7 10 matrix of different drug names.\"</cite>\r\n\r\nI think that with
    such words (no one knows) there is no difference between caps and lower-case letters,
    but regarding to what ricard0 said there is a remarkable difference when the text
    contains words that are well known because people are reading words not letters.
    Reading is kind of a guess-work, maybe that's why you are getting faster when
    you're reading more."
  created: '2009-09-03 22:29:00'
- author:
    name: Chris Dean
    picture: 111971
  body: "I agree, the drug names are somewhat obscure, but due to the fact that participants
    were selected from the medical profession the confound of complex nomenclature
    is likely lessened due to their familiarity with the language. The same study
    run with high-school students would almost certainly produce (significantly?)
    different results. Cause for a followup study perhaps\u2026"
  created: '2009-09-04 00:14:20'
- author:
    name: joeclark
    picture: 110605
  body: "Case alteration \u2260\_all caps.\r\n\r\n\u2014  \r\nJoe Clark\r\nhttp://joeclark.org/"
  created: '2009-09-04 03:53:58'
- author:
    name: paragraph
  body: "Recognising a word or two in a matrix has almost nothing to do with reading
    an extended text passage, IMHO. Apples and oranges.\r\nLooking for a word-shape
    you know is there is not reading."
  created: '2009-09-04 07:06:05'
- author:
    name: bowerbird
    picture: 116972
  body: "in the 7-bit ascii-text world of emerging cyberspace,\r\ni.e., usenet, how
    else would people have indicated\r\nthey were screaming, if not with all-capital-letters?\r\n\r\nsince
    then, it's been traditionally accepted and taught\r\nthat all-caps is screaming.\r\n\r\nbut
    they fired that woman for some other reason\r\n-- i dunno, maybe she had b.o.
    -- and then just\r\nblamed her all-capital phrases as \"a good excuse\".\r\n\r\n-bowerbird\r\n"
  created: '2009-09-04 09:00:50'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> Recognising a word or two in a matrix has almost nothing to do with reading
    an extended text passage, IMHO\r\n\r\nI think they\u2019re very similar.\r\n\r\nWhen
    you read an extended passage you look at a single word, recognize it, and move
    on to the next word. If the next word is a function word or other frequently occurring
    short word, you may not have to move your eyes to recognize it. Most of the time
    you will move your eyes to the next word in order to recognize it.\r\n\r\nWhen
    you read the words in a matrix you will look at a single word, recognize it, and
    move on to the next word. You will always move your eyes to the next word as there
    are not function words or other high probability words in the matrix.\r\n\r\nThe
    higher level processes of understanding the syntax and semantics will be greatly
    different, but the low level processes of recognizing words will be the same.\r\n"
  created: '2009-09-04 15:54:10'
- author:
    name: faraqat
    picture: 112914
  body: "I think this is a bit nonsence and the real issue that should be discussed
    is that no employer can claim this as a reason to let go of an employee. This
    would certainly be a case for a complaint at the social security institute, but
    these are things that have nothing to do with typography, so i'll stop here.\r\nMy
    oppinion is that we cannot, must not, turn written language into spoken language.
    Screaming is sound, screaming has no correlation to any written letter, the best
    way you can write a scream is (depending on your particular cultural codes) by
    the use of onomatopoeia, that's why they exist. Of course all of this can change
    in the course of history, and the words \"must not, cannot\" have no meaning anymore
    realy... But I think it's important to remember that the intent of screaming turned
    into letters on paper/screan is not screaming at all! And sentences written in
    capitals are not screaming if the words themselves aren't offensive... but that's
    just my oppinion."
  created: '2009-09-04 16:22:53'
- author:
    name: John Hudson
    picture: 110397
  body: "There should be a rule that published reading studies should include not
    only their methods and results but also the experimental materials used. The Arditi
    and Cho paper is interesting, but I'd like to see what they gave subjects to read.
    The fact that Arditi and Cho clearly do not understand what constitutes font size\u2014\u2018the
    sum of cap height plus descent, which is usually specified in points\u2019\u2014is
    disturbing, as is the fact that they are testing at multiple sizes while apparently
    having no concept of size-specific type. Then they seek to \u2018minimize differences
    based on relative size of upper- and lower-case letters\u2019 by using \u2018a
    font (Arial) with a relatively large x-height\u2019, but in so doing obscure any
    possible legibility advantage of traditional book face proportions, i.e. smaller
    x-height.\r\n\r\nI'm perfectly willing to accept that allcaps might be more legible
    than mixed case or lowercase. But I don't find this paper convincing."
  created: '2009-09-04 18:20:41'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> The Arditi and Cho paper is interesting, but I\u2019d like to see what
    they gave subjects to read.\r\n\r\nYes, that would be great, but it\u2019s not
    really possible because of the inherent differences between screen and print.
    They used Arial (which has no optical size adjustments), on-screen at very large
    sizes - what information would better help you understand the original material:
    screen dpi plus ppem size?\r\n\r\n> The fact that Arditi and Cho clearly do not
    understand what constitutes font size.\r\n\r\nSince they\u2019re not comparing
    between two typefaces, they don\u2019t need a more accurate definition of font
    size for this study.\r\n\r\nI liked that they developed a way to control for the
    inherent size difference between upper and lowercase. They measured the minimal
    visual angle needed to recognize lowercase and the minimum visual angle to read
    uppercase. They took those sizes as equal (which involved a smaller point size
    for uppercase Arial than lowercase Arial). Reading speed at twice the minimal
    visual angle was faster with uppercase Arial than lowercase Arial.\r\n\r\nTheir
    size control is very clever.\r\n\r\nI think the unanswered question is why does
    this study differ from earlier studies that found that lowercase is read faster
    than uppercase?\r\n"
  created: '2009-09-04 20:19:56'
- author:
    name: paragraph
  body: "Kevlar: Looking for a word-shape <em>you know is there</em> is not reading.\r\n\r\nIt's
    almost the opposite. Spot the x, please:\r\nooooxoooo"
  created: '2009-09-05 00:30:12'
- author:
    name: _Palatine_
    picture: 115977
  body: All caps in long-running text are a big PITA to read. And it seems like over-emphasis
    when none is needed. Like someone using a hammer to drive in a needlepoint. It's
    sloppy and lazy.
  created: '2009-09-05 00:46:39'
- author:
    name: bowerbird
    picture: 116972
  body: "palatine said:\r\n>   And it seems like over-emphasis when none is needed.
    \r\n>   Like someone using a hammer to drive in a needlepoint.\r\n\r\nright, it's
    screaming.\r\n\r\nand sometimes people want to scream.\r\n\r\nsometimes people
    _want_ to \r\nuse a hammer to drive in a needlepoint.\r\n\r\nnot me.  i like to
    whisper.  \r\nthat's why i use lowercase exclusively...\r\n\r\n-bowerbird\r\n"
  created: '2009-09-05 05:51:55'
- author:
    name: John Hudson
    picture: 110397
  body: "<em>i like to whisper. that\u2019s why i use lowercase exclusively...</em>\r\n\r\nThat's
    whispering? I thought it meant you couldn't find the shift key."
  created: '2009-09-05 06:44:01'
- author:
    name: bowerbird
    picture: 116972
  body: "john said:\r\n>   That\u2019s whispering?\r\n\r\nactually, it's more like
    being very soft-spoken.     :+)\r\n\r\n-bowerbird\r\n\r\np.s.  i dunno why you'd
    think the shift-key would be\r\nhard to find.  on most keyboards, it's the biggest
    key,\r\nexcept for the space-bar, which is such a big key that\r\nwe don't even
    call it a \"key\", we call it a \"bar\"...  but yes,\r\neven though it's obvious,
    i ignore it.  just like advertising.\r\n"
  created: '2009-09-05 07:22:29'
- author:
    name: russellm
    picture: 111614
  body: "@ Kevlar, <cite>I think the unanswered question is why does this study differ
    from earlier studies that found that lowercase is read faster than uppercase?</cite>\r\n\r\nThe
    subjects were just reacting to being yelled at and wanted to get the experience
    over with so they could get back to that laid back feeling that one has when reading
    bowerbird's posts.\r\n\r\n\r\n\r\n-=\xAE=-"
  created: '2009-09-05 15:39:33'
- author:
    name: bowerbird
    picture: 116972
  body: "ommmmmmmmmm...\r\n\r\n-bowerbird\r\n"
  created: '2009-09-05 19:03:05'
- author:
    name: joeclark
    picture: 110605
  body: "I read the paper. In fact, I wish Kevlar had an RSS feed (any old blog would
    do) of interesting research papers he runs across so we can read what he does.\r\n\r\nI
    spent a couple of days with Aries Arditi a few years ago. (His first name, incidentally,
    is not pronounced like the astrological sign but exactly like \u201Cheiress.\u201D)
    He struck me as not letting anything get in the way of actually helping low-vision
    people who are the clients of his institution. That includes distorting letterforms
    and using nonsensical IE6-only CSS. He <em>really</em> doesn\u2019t like it when
    he or his colleagues are claimed to be wrong, let alone proved to be. Quite obviously
    I would have no idea whatsoever what that feeling is like.\r\n\r\nAt any rate,
    the paper showed the difference between all-UC and mixed-case text was pronounced
    at small sizes. There was a discrete threshold at which such a difference became
    large. I view this as merely a finding that below a certain size, raw height of
    character is an overriding factor. Capitals are taller than mixed case on average
    even with his method of smoothing out UC/U&lc differences.\r\n\r\nNow, it would
    be interesting to rerun this experiment with Cyrillic, as its U&lc is essentially
    caps and small caps, and any unicase alphabetic script, like Hebrew.\r\n\r\n\u2014
    \ \r\nJoe Clark\r\nhttp://joeclark.org/"
  created: '2009-09-06 22:08:43'
- author:
    name: William Berkson
    picture: 110306
  body: "Kevin, this paper tells us little about the readability of extended text
    by readers with normal vision under good conditions, as opposed to the legibility
    of a few words under difficult conditions.\r\n\r\nIn fact this paper's results,
    together with others they reference, support the reality of the distinction between
    readability and legibility.\r\n\r\n<strong>A misinterpretation</strong> \r\n\r\nBut
    first of all let me clear up one misinterpretation, to some extent by the authors,
    and also by you.   \r\n\r\n>Arditi & Cho argue that uppercase letters are more
    legible than lowercase letters, even when the size differences are taken into
    account. I think they are right.\r\n\r\nFirst of all, contrary to what you infer,
    they do not establish that Caps are more readable when size differences are taken
    into account. As they relate, Smith, Lott and Cronnell (1969) found that when
    you compare x-height caps with lower case, lower case wins in legibility. As they
    say, there is really no apples-to-apples comparison here, but you can also use
    simply the caps of the same font size. \r\n\r\nHowever, when you do use caps of
    the same font size, these are bigger in the sense that you have more white space
    within the caps than within lower case letters--which the Clearview Highway tests
    indicate is a key to legibility. Further, when everything is larger, they say
    the caps' advantage in legibility tends to disappear. Thus the more accurate inference
    from their data is that size of counters is critical to legibility, not that caps
    have a special advantage.       \r\n\r\nI think the authors also wrongly interpret
    that their results conflict with Tinker's, because, if I've got it right (I haven't
    read Tinker), Tinker had readers with good vision reading continuous text under
    normal conditions. \r\n\r\n<strong>What Arditi and Cho were testing</strong>\r\n\r\nIn
    Arditi and Cho, their main tests paper create very difficult reading conditions.
    The words are deliberately made hard enough to read that readers miss the correct
    words 50% of the time. In some cases the difficulties were created by readers'
    poor vision, and in others by making the text small or far away enough that acuity
    of those with normal vision declined precipitously.\r\n\r\nThus they were testing
    \"legibility\" in the sense of ability to decipher words under difficult conditions,
    not speed and comfort of reading with good comprehension, under good conditions,
    or \"readability\".\r\n\r\nHence under this long-standing typographer's distinction,
    the results of Tinker and Arditi and Cho are consistent, and complementary. The
    readability of all caps of the same point size of a font is lower, but the legibility
    is higher--because of larger visual size.   \r\n\r\nI don't know what your view
    is, but this paper does NOT establish that there is no difference between readability
    and legibility, nor that caps are more readable."
  created: '2009-09-07 23:09:00'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> I don\u2019t know what your view is, but this paper does NOT establish
    that there is no difference between readability and legibility\r\n\r\nI\u2019ve
    never quite understood the division of labor between legibility and readability.
    Can something be readable without being legible? I would propose a different division
    for reading: decoding and comprehension. Decoding is the ability to recognize
    words. Typographic quality is important here, but knowing the letters of the alphabet
    and the cipher between letters and sounds is a big part of this. Comprehension
    is the ability to make sense of the series of words. Under normal conditions comprehension
    is the limiting factor for reading speed. Easy-to-comprehend Harry Potter can
    be read faster than a difficult to understand book of philosophical writings.
    The philosophical writings take longer to comprehend even if the typographic quality
    is amazing.\r\n\r\n> The words are deliberately made hard enough to read that
    readers miss the correct words 50% of the time.\r\n\r\nWhile typographic quality
    does result in reading speed differences in normal conditions, the differences
    have to be pretty large to detect them. The time spent comprehending the philosophical
    writings can swamp any effect. Without running hundreds of people (as Tinker did),
    differences will frequently be missed. Instead it has become common to test typographic
    quality by measuring words under time or size constraints. The Clearview study
    was a size constraint study for instance. Typographic conditions that are easier
    to read under time or size constraints will also be easier to read under normal
    conditions.\r\n"
  created: '2009-09-08 15:44:08'
- author:
    name: Chris Dean
    picture: 111971
  body: '@ Larson & Berkson: Which [[http://www.clearviewhwy.com/|Clearview]] studies
    you are referring to?'
  created: '2009-09-08 16:17:51'
- author:
    name: Kevin Larson
    picture: 109739
  body: "This is the relevant Clearview study. To my knowledge it is not available
    online:\r\n\r\nGarvey, P.M., Pietrucha, M.T., & Meeker, D.T. (1997). Effects of
    font and capitalization on legibility of guide signs. <em>Transportation Research
    Record</em>, 1605, 73-79.\r\n"
  created: '2009-09-08 16:53:37'
- author:
    name: aluminum
    picture: 110335
  body: "\"And sentences written in capitals are not screaming if the words themselves
    aren\u2019t offensive... but that\u2019s just my oppinion.\"\r\n\r\nSure. But
    the majority likely has a much different opinion.\r\n\r\nCommunications are increasingly
    becoming informal-text centric rather than voice or traditional long-form formal
    text. Email, tweets, SMS, IM, etc.\r\n\r\nAs such, there are definite and defined
    type styles that do communicate things such as 'screaming'. \r\n\r\nAnd just as
    screaming in a work environment would potentially be seen as inappropriate communications,
    I find it very plausible that abuse of all-caps in email communication could be
    seen as inappropriate as well. "
  created: '2009-09-08 18:14:48'
- author:
    name: John Hudson
    picture: 110397
  body: "Kevin: <em>Typographic conditions that are easier to read under time or size
    constraints will also be easier to read under normal conditions.</em>\r\n\r\nIs
    that a hypothesis or an observation?\r\n\r\nIt seems to me possible that, just
    as difficult content such as your \u2018philosophical writings\u2019 can diminish
    or overcome positive effects of reading speed derived from good typography, so
    \u2018normal conditions\u2019 might diminish or overcome the positive effects
    of some typographies under time or size or other constraints. Consider two different
    typefaces or settings: just because one is more easily read than the other at
    6pt does not mean that the same type will be more easily read than the other at
    12pt. It is entirely possible that the one is better suited to 6pt than the other,
    but that both might perform equally well at a larger size or, even, that the other
    type is better suited to use at 12pt."
  created: '2009-09-08 18:27:24'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> Is that a hypothesis or an observation?\r\n\r\nI would call it a theory.
    There are multiple pieces of data that support this. For example, typefaces with
    letters that can be recognized with size constraints tend to be read faster at
    normal sizes. I don\u2019t know of any data that goes against this theory.\r\n\r\nOptical
    sizes is an interesting test for this theory. Clearly a font designed for 4 point
    is going to perform better than a font designed for 12 point when tested under
    size constraints. The theory would predict that the designed 4 point design would
    be read faster than the 12 point design when both are displayed at 12 point. That
    could be wrong, I don\u2019t know.\r\n"
  created: '2009-09-08 19:19:12'
- author:
    name: P A Hardy
  body: "\u201CParticipants (33 nurses) were searching for drug names such as \u2019Hydroxyzine
    & Phentolamine\u2019 in a 10 \xD7 10 matrix of different drug names.\u201D\r\n\r\nI
    was going to say that using such antiquated drugs as these would almost guarantee
    lack of familiarity to the nurses in the study. But then I saw that the paper
    dates from 1967.\r\n\r\nThis however brings me to two further points: firstly,
    it is quite possible that the nurses engaged had no more familiarity with those
    names than Mr Dean's hypothetical high school students. The practice of using
    generic names such as phentolamine & hydroxyzine was much less common in 1967,
    and the proprietary names (brand names) would probably be much better known to
    the nurses involved. And secondly, the problems of the literature around this
    issue do not seem to have changed much since then. Others have pointed out that
    the methods, materials and outcome measures used in readability/legibility studies
    (I'm ducking that one) are not standardized, and therefore there isn't a comparable
    set of research studies pointing to a reproducible outcome. You can always find
    at least one study to reinforce your preconceptions, if you so desire.\r\n\r\nIt
    is perhaps similar to Alex Poole's review of the literature on readability of
    sans vs serif - \r\nhttp://www.alexpoole.info/academic/literaturereview.html\r\n\r\nPaul
    Hardy\r\nUK\r\n"
  created: '2009-09-08 19:41:23'
- author:
    name: enne_son
    picture: 109487
  body: "I'm curious to know what Arditi and Cho mean by mixed case. Do they mean
    standard upper and lower case such as used in this message (capitalizing the initial
    letter of sentence-initial words and names), or classical mixed case, where every
    other letter is capitalized?\r\n\r\nThat is, are experiments 2 and 3 comparing
    all capitals with normal upper and lower case, or classical mixed case?\r\n\r\nI
    second issue is the claims about all subjects performance in experiment 1 manifesting
    a word superiority effect. As I read the charted results only in the normally
    sighted does this reach robust significance in both upper case and lower case.
    In the low vision result there is a weak trend in that direction, with a proportionately
    stronger effect for upper case than lower case with low vision. Why aren't the
    reasons for this explored? Are the authors too quick with their inferential logic?
    Is legibility the only factor at play here?\r\n\r\nAlso, the results for words
    in mixed case are not shown. Why?\r\n\r\n"
  created: '2009-09-08 20:11:29'
- author:
    name: William Berkson
    picture: 110306
  body: ">I\u2019ve never quite understood the division of labor between legibility
    and readability. \r\n\r\nWell I'll explain it to you, in operational terms. Legibility
    is whether words can be deciphered under difficult conditions, such as poor vision,
    poor light, distance. Readability is is whether they can be read under optimal
    conditions with comfort, speed and comprehension. Operationally defining comfort
    may be a little tricky, but the others are pretty straightforward. \r\n\r\nDo
    you understand it now?\r\n\r\nSo defined, readability and legibility are conceptually
    different. The question of the relationship between legibility and readability
    then can and should be experimentally investigated. There is no reason that they
    *have to* be the same. The gears in a car that are optimal for going up a steep
    hill are not optimal for going fast on a flat road. Similarly, the type that is
    optimal for very small size or viewing at night at a distance may well not be
    optimal for normal reading under good conditions. \r\n\r\n>For example, typefaces
    with letters that can be recognized with size constraints tend to be read faster
    at normal sizes. I don\u2019t know of any data that goes against this theory.\r\n\r\nHello?
    You have before you that Tinker found that all-caps reads more slowly, and you
    have Arditi and Cho showing that caps of the same point size are more legible
    under difficult reading conditions--including small visual size for normal readers.
    \r\n\r\nSo you have before you clear evidence that more legible type is *not*
    more readable. So you unscientifically dismiss Tinker, or do you retest and refine
    his results, as good scientific method would require?\r\n\r\n>Without running
    hundreds of people (as Tinker did), differences will frequently be missed. Instead
    it has become common to test typographic quality by measuring words under time
    or size constraints.\r\n\r\nAs I think you have evidence at the very least that
    agate proportions don't give an advantage in reading print at normal sizes a decision
    to *not* run tests that are harder to execute for the experimenter seems to me
    terrible methodology. \r\n\r\nIt is like the old story of the drunkard who was
    looking under the street lamp for his keys. A fellow asks \"where did you lose
    them?\"  And the drunk answers: \"Over there in the dark, but I can see here.\"\r\n\r\nAnd
    to repeat my earlier suggestion here, readability can be tested, and I think more
    efficiently than Tinker did. Have students do a lot of SAT reading tests, timed,
    over several hours, with different fonts. Then you can compare comprehension and
    speed among different fonts and layouts. Then you can get some real answers, instead
    of looking under the light, where there are no keys. \r\n\r\n>Can something be
    readable without being legible?\r\n\r\nTo be readable the words have to be legible
    *under the conditions* which you are reading them, in the sense that you can readily
    identify them. But there is no logical compulsion that the *most* legible under
    difficult conditions are the most readable under optimal conditions, which is
    what the distinction legible vs readable is designed to make.\r\n\r\nIn fact we
    know that very small type intended to be read over the centuries has generally
    been done with larger x-heights, somewhat wider and bolder, and with looser spacing.
    And these specifications have generally not been preferred by readers of extended
    text. Agate type is used for agate size, and text type for text size. \r\n\r\nThus
    the evidence of hundreds of years of preference would put the burden of proof
    on showing that agate type is more readable, whereas you are assuming without
    testing that it is so, which is hardly scientific. \r\n\r\nIn the tests you reported
    at Typecon, it seemed that you were assuming that legible glyph would be more
    readable. Since this is important to readability on screen, I don't understand
    why you don't have a priority on testing it, because otherwise this direction
    of research may well be irrelevant to screen reading. \r\n\r\nPs. Under good conditions
    and legible type, we are talking about relatively small differences in readability,
    but still significant. For example, we can read on current computer screens, but
    most of us prefer to read extended text in print. \r\n \r\n\r\n  \r\n\r\n "
  created: '2009-09-08 23:26:15'
- author:
    name: Kevin Larson
    picture: 109739
  body: "Arditi & Cho say in the methods section that they used conventionally mixed
    case text in the RSVP study. The MNREAD corpus does not contain any proper nouns,
    but by default the first letter of each 56 character sentence is capitalized.
    I assume that only the first letter of each sentence is set in uppercase.\r\n\r\n>
    I second issue is the claims about all subjects performance in experiment 1 manifesting
    a word superiority effect\r\n\r\nPeter, you don\u2019t seem to be questioning
    that there is a word superiority effect. Words had lower thresholds than random
    letters for both groups of participants. I think you\u2019re asking if there was
    an interaction effect between word superiority and visual condition. It might
    be interesting to know that, but I don\u2019t see how it\u2019s relevant.\r\n\r\nThe
    text of the article refers to two different Figure 2\u2019s: one for normally
    sighted participants and one for low vision participants. Something went wrong
    here.\r\n"
  created: '2009-09-08 23:28:54'
- author:
    name: enne_son
    picture: 109487
  body: "\"I assume that only the first letter of each sentence is set in uppercase.\"
    [Kevin]\r\n\r\nThan why is the chart labeled MiXeD?\r\n\r\n\"I think you\u2019re
    asking if there was an interaction effect between word superiority and visual
    condition. It might be interesting to know that, but I don\u2019t see how it\u2019s
    relevant.\" [Kevin]\r\n\r\nI'm wondering if there is an interaction effect between
    word superiority, visual condition and type of subject."
  created: '2009-09-09 00:10:16'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> Do you understand it now?\r\n\r\nYes, I see that you have described legibility
    and readability differently. What I still don\u2019t understand how these are
    different concepts. Sure, we happen to have two different words in English, but
    that doesn\u2019t mean they\u2019re actually different. In both cases light from
    a surface reaches our eyes. We use that light to recognize features, which we
    build up into recognized words. We read one word, then the next; our eyes move
    in predictable patterns. Environmental conditions can be good or bad, but the
    eyes do the same thing under any condition. I call this all decoding.\r\n\r\nDecoding
    is materially different from comprehension. I can comprehend text by listening
    to someone else decode it and read it to be aloud. They are distinctly different
    tasks. Are legibility and readability different tasks? According to your own description
    legibility is a component of readability. Can readability be separated from legibility?\r\n\r\n>
    Thus the evidence of hundreds of years of preference would put the burden of proof
    on showing that agate type is more readable, whereas you are assuming without
    testing that it is so, which is hardly scientific.\r\n\r\nWilliam, I am disappointed
    that you twice accused me of being unscientific. I put forward a strong, falsifiable
    theory that hypothesized that agate type is more readable. I even followed up
    that statement with: \u201CThat could be wrong, I don\u2019t know.\u201D Nothing
    could be more scientific that to create a theory that can be demonstrated false.
    I wish you would propose a theory of readability distinct from legibility that
    could be falsified."
  created: '2009-09-09 00:11:23'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> Than why is the chart labeled MiXeD?\r\n\r\nStudy 1 on size thresholds
    had 5 conditions including a mixed case which they describe in the methods as
    \u2018randomly selected case\u2019. Study 2 on RSVP reading is described in the
    methods section as using both uppercase and conventionally mixed case.\r\n"
  created: '2009-09-09 00:23:42'
- author:
    name: enne_son
    picture: 109487
  body: Thanx Kevin. The distinction wasn't clearly made and the labeling confusing.
  created: '2009-09-09 00:33:52'
- author:
    name: William Berkson
    picture: 110306
  body: "Kevin, I admit I am frustrated because I did define legibility and readability
    so that they may turn out to operate in a testably different way.  And I explained
    the two tests. I am not using the words in a conventional way, but in the technical
    sense that typographers have for over fifty years. It is a technical distinction,
    but a difference that can be tested for. It is testable, and I explained how,
    but I will again:\r\n\r\nYou test legibility of types as Arditi and Cho did or
    the Clearview tests did--testing decoding under difficult-to-read situations.
    Then you test the highest legibility type for reading speed and comprehension
    in the manner I said, in normal text conditions using the SAT tests. And you also
    take a good text font, like Minion in normal text case (lc with caps as conventionally),
    also test both under difficult circumstances, and using the SAT test. It may turn
    out that the more legible type--the type that comes out better in difficult-to-read
    situations--does equally as well or worse in the readability tests. That would
    experimentally establish that there is a meaningful distinction between legibility
    and readability. \r\n\r\nSorry to have been so brusque, but what upsets me is
    that you seem to dismiss the difference as non-existent or not worth testing,
    even though you now concede that your theory is untested. That's what struck me
    as not in the scientific spirit. \r\n\r\nThe heart of the matter that some type
    designers keep disagreeing with you about comes down to whether there is a difference
    between ability to decode letters or single words under difficult circumstances
    vs what is best for reading normal text, in terms of speed, comprehension, and
    comfort.  \r\n\r\nNow that John has added his voice on this--thanks John--you
    concede that agate proportions may in fact turn out not to be superior at bigger
    sizes. Yet in the beginning you seemed to dismiss this possibility--which is one
    case of exactly what I have been talking about--as not worth testing because contrary
    to the current weight of evidence. \r\n\r\nAnd this in spite of the evidence from
    Tinker on one hand and Arditi and Cho on the other, which seem to me together
    to show that on the contrary, one type that is more legible under difficult conditions--small
    size all caps--is in fact less readable in normal text sizes and conditions in
    terms of speed with comprehension, or in other words readability.\r\n\r\nPlease
    address the issue of the different results of Arditi and Cho on one hand, and
    Tinker on the other. For they, as I understand it, are tests of legibility, on
    one hand, and readability, on the other. \r\n\r\nThe issue here shouldn't be one
    of terminology. I can put the theory without using the terms readability and legibility:
    the type that can be decoded best in difficult circumstances--distant, small,
    low light--is not the type that reads most quickly with comprehension and comfort
    in normal circumstances in print at text sizes. Is that understandable? Do you
    think it's testable in the manner I described? "
  created: '2009-09-09 04:02:57'
- author:
    name: John Hudson
    picture: 110397
  body: "Bill: <em>I can put the theory without using the terms readability and legibility:
    the type that can be decoded best in difficult circumstances\u2014distant, small,
    low light\u2014is not the type that reads most quickly with comprehension and
    comfort in normal circumstances in print at text sizes.</em>\r\n\r\nI can go one
    better:\r\n\r\nThe type that can be decoded best in circumstance A is not necessarily
    the type that can be decoded best in circumstance B.\r\n\r\nIt is easy to imagine
    two extreme but distinct circumstances, e.g. very small type or type viewed at
    an angle, in which different types will perform better. From this it follows that
    the same may be true of the circumstance of 'normal' or preferred reading conditions.\r\n\r\nI
    think contrasting normal conditions with undifferentiated 'difficult conditions'
    is misleading, because each distinct condition may favour selection of a particular
    typeface. There are different kinds and degrees of difficult condition, and what
    more or less characterises typefaces that are optimised for these conditions are
    describable as distortions away from the characteristics of traditional text types.
    So to posit that any one such distortion will be better decoded in circumstance
    B because it was better decoded in circumstance A seems to me foolish."
  created: '2009-09-09 04:23:17'
- author:
    name: William Berkson
    picture: 110306
  body: "John, your succinct formulation is helpful, thanks. \r\n\r\nHowever, I do
    not want to reduce readability to accuracy of decoding, or even accuracy of decoding
    at a given speed. The 1967 definition of readability of my Uncle Ben Lieberman,
    in his book Types of Typefaces is: \"Ease with which the eye can absorb the message
    and move along the line.\" To me this implies a combination of speed, comprehension
    and comfort. And more important, those are the basics that readers actually appreciate
    in a text type. \r\n\r\nSo I would be happier reformulating your sentence as \"The
    type that can be read with the best speed, comprehension and comfort in situation
    A, is not necessarily the type that can be the read with the best speed, comprehension
    and comfort in situation B.\"   \r\n\r\nLess comfort could be measured, I have
    suggested, by a decline in speed or comprehension with time. You might be able
    to decode one font as well as another in a short time, yet one might have superiority
    as far as comfort. In fact, I suspect that reading comfort may be the most important
    difference between reading current computer screens and reading print on paper.
    \ \r\n\r\nThis also answers Kevin's question above, \"Can readability be separated
    from legibility?\" They can be distinguished because accurate decoding is only
    one factor in readability; there is also speed and comfort at a given level of
    comprehension. \r\n\r\nI find 'legibility' a useful term in the narrower sense
    I have used it because there are specific design qualities that help decode type
    in difficult reading circumstances--such as large counters for the point size.
    But in larger sizes these same features though still more 'legible' in that restricted
    sense--if you bring in darkness or poor eyesight or distance from reading matter
    they still are an advantage--but they do not help you decode more quickly in normal
    circumstances. "
  created: '2009-09-09 05:15:09'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> Please address the issue of the different results of Arditi and Cho on
    one hand, and Tinker on the other. For they, as I understand it, are tests of
    legibility, on one hand, and readability, on the other.\r\n\r\nOn Sept. 4 I said
    \u201CI think the unanswered question is why does this study differ from earlier
    studies that found that lowercase is read faster than uppercase?\u201D I agree
    that the Arditi & Cho findings are divergent from other findings, and that there
    is something interesting to be learned when a type decoded best in circumstances
    A is not the same as a type that is decoded best in circumstances B.\r\n\r\nI
    don\u2019t take this as evidence that legibility and readability are distinct,
    because there was no finding here that could have falsified the hypothesis that
    legibility is distinct from readability. If Arditi & Cho had found that lowercase
    performed better under stressful conditions would you say that legibility and
    readability are the same? Likely no.\r\n\r\nSimilarly, I hypothesized that agate
    proportions would perform better both in a legibility/threshold test and in a
    readability/ reading speed test. This obviously goes against typographic wisdom
    and could be proven wrong \u2013 falsified. If agate proportions perform better
    in a threshold test and reading speed test, would that falsify that legibility
    and readability are distinct? Also likely no.\r\n\r\n> Sorry to have been so brusque,
    but what upsets me is that you seem to dismiss the difference as non-existent
    or not worth testing, even though you now concede that your theory is untested.\r\n\r\nYes,
    I am challenging the theory that readability is distinct from legibility because
    I am not convinced by it, but that doesn\u2019t mean I don\u2019t think it\u2019s
    worth testing. I am looking for a meaningful test of the theory. As you know a
    test isn\u2019t meaningful if the theory fits equally well with any result. There
    has to be a finding that the theory absolutely can\u2019t coexist with, else it
    is a useless theory.\r\n"
  created: '2009-09-09 07:46:02'
- author:
    name: paragraph
  body: "<em> I put forward a strong, falsifiable theory that hypothesized that agate
    type is more readable.\r\n\r\nI hypothesized that agate proportions would perform
    better both in a legibility/threshold test and in a readability/ reading speed
    test.</em>\r\n\r\nPersonally, I have problems even with your terminology. Theory
    requires proof. A hypothesis does not. "
  created: '2009-09-09 08:35:32'
- author:
    name: bowerbird
    picture: 116972
  body: "see, capital letters really _do_ annoy people!      :+)\r\n\r\nyou get all
    testy and unproductively argumentative...      ;+)\r\n\r\n-bowerbird\r\n"
  created: '2009-09-09 10:01:28'
- author:
    name: William Berkson
    picture: 110306
  body: "First, I should have kept to the definition of legibility in \"Types of Typefaces\":
    \"legibility is based on the ease with which one letter can be told from another.\"
    By keeping legibility to letters, and readability to words in extended text, the
    distinction is cleaner. I used a different definition: what can be read best under
    difficult conditions vs good conditions. \r\n\r\nKevin: \"I don\u2019t take this
    as evidence that legibility and readability are distinct, because there was no
    finding here that could have falsified the hypothesis that legibility is distinct
    from readability. If Arditi & Cho had found that lowercase performed better under
    stressful conditions would you say that legibility and readability are the same?
    Likely no.\"\r\n\r\nAny claim that \"you can find that x and y behave differently
    in some way\" is not in a refutable form--you are correct. However, if you specify
    the ways in which they should differ, the list is finite and it becomes testable.
    And I did give the list: speed, comprehension, and comfort. Further the hypothesis
    that \"x and y never behave differently\" is in a refutable form, and refutation
    and finding of a difference is enough to establish the utility of a distinction.
    And in this case the hypothesis of no difference is refuted. \r\n\r\nArditi and
    Cho have refuted the claim that there is no difference. For they found that speed
    in reading at 50% accuracy is different between all caps and normal mixed case
    of the same point size under difficult reading conditions, but these differences
    disappear for normal readers at bigger size. That is a difference. If the same
    holds for identifying single letters--and in their tests ability to identify single
    letters was a factor--that would establish the difference under Lieberman's clearer
    definitions as well.  \r\n\r\nI'm sorry I missed your Sept 4 statement saying
    that the question remained of the reason for the differences between Arditi &
    Cho and past results; had I read it, I would not have been so skeptical about
    your willingness to experiment on this issue. But I am still curious as to what
    earlier studies made you think that the same design conditions are equally legible
    (speed + comprehension, leaving out comfort) under difficult conditions and easy
    ones? \r\n\r\nI would be delighted if you are willing to do experimental tests
    on this issue. If you are, another test of readability under relatively good reading
    conditions is frequency of proof-reading mistakes. It is widely recognized that
    it is easier to proof extended text on paper than on the screen, so that, as well
    as the timed test of speed + comprehension with difficult material, seems to me
    a promising indicator of readability.   "
  created: '2009-09-09 12:19:35'
- author:
    name: Kevin Larson
    picture: 109739
  body: "Yes, the theory that any typographic variable (e.g. uppercase versus lowercase)
    will show that one condition (e.g. uppercase) performs best in all tests has been
    refuted. I will have to develop a better theory.\r\n\r\nWilliam, I think you\u2019re
    proposing that for any typographic variable that one condition will never perform
    best in all tests (speed, comprehension, comfort, size threshold, and time threshold).
    I think I can refute that with a thought experiment: I hold the firm belief that
    12 point text is a better size for reading than 2 point text (I am hopeful that
    everyone else holds this impression too). I believe that 12 point text will perform
    better than 2 point text in all of these tests. \r\n"
  created: '2009-09-09 13:21:50'
- author:
    name: William Berkson
    picture: 110306
  body: ">William, I think you\u2019re proposing that for any typographic variable
    that one condition will never perform best in all tests.\r\n\r\nNo, I didn't and
    I'm not proposing that. I don't pretend to know about all conditions in all circumstances.
    \r\n\r\nWhat I am saying is simply what is regarded by type designers for a very
    long time as fundamental: different designs are most suitable for different purposes:
    very small type, extended text, headings, display, screen, newspaper, etc. So
    *some* conditions are best changed, depending on the intended purpose of the type.
    \r\n\r\nAnd the changed conditions affect readability under different circumstances,
    such as size, print medium, or computer screen. \r\n\r\nIn the case of agate proportions,
    I would be willing to bet money that a face with such proportions will not beat
    out in readability (measuring speed comprehension and comfort) a good text face
    like Minion in print at normal sizes and decent layout. \r\n\r\nI do think that
    somewhat longer extenders have a readability advantage at normal sizes, but I
    concede that this is going to be hard to test. I think it is most likely to show
    up in the tests I have mentioned--either the one using the SAT or the frequency
    of proofing errors. \r\n\r\nI do think that such tests--rather than under small
    sizes, low light, etc.--are also most likely to enable us to identify reliably
    the characteristics which make screen less readable than print, the effects of
    spacing, etc. "
  created: '2009-09-09 13:54:36'
- author:
    name: paragraph
  body: You are right, bowerbird. All yours.
  created: '2009-09-09 14:46:47'
- author:
    name: dberlow
  body: "Kevin, if a single powerful vendor decided 2 point was the \"new world order\",
    you know as well as I do we'd just all have to design 2 point masters and fit
    up the masses with thick glasses (it sounds catchy-phrase-able already), until
    the monitor manufacturers could fit their products with thick glasses for the
    poor, while the rich would 'go nano' and not need glasses, (or fossil fuels;).
    Then...I believe 2 point text would perform better than 12 point text in all tests.
    Even I could design <em>that</em> study.\r\n\r\nBill>And the changed conditions
    affect readability under different circumstances, such as size, print medium,
    or computer screen.\r\n\r\nI agree completely. This is why I think that tests
    in cleartype labs and optometrically designed studies are so far away.\r\n\r\nIn
    print, from the type's contrast to paper to the light the user employs, there
    is plenty of 'positive' wiggle room and designers and readers use it... On screens,
    e.g. it's only a little funny that the style is selected by one user, before the
    size, scaling and rendering are selected by the reader. Positive wiggle room is
    scarce, and we see that in the number of both complaints, studies on the topic,
    and reader flight to better platforms.\r\n\r\nFortunately, identifying reliably
    the characters who've make the major platform's screens less readable than print,
    is becoming easier. \r\n\r\nCheers!\r\n\r\n"
  created: '2009-09-09 14:48:25'
- author:
    name: William Berkson
    picture: 110306
  body: "Thanks, Kevin, for your gracious acknowledgment that the Arditi and Cho paper
    refutes the idea that all characteristics which work better under difficult reading
    conditions also work better under normal conditions. That's the true scientific
    spirit!\r\n\r\n"
  created: '2009-09-09 15:23:28'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> In the case of agate proportions, I would be willing to bet money that
    a face with such proportions will not beat out in readability (measuring speed
    comprehension and comfort) a good text face like Minion in print at normal sizes
    and decent layout.\r\n\r\nSwell, but there is no theory if every set of conditions
    is decided on a case by case basis. What is the theory that determines that agate
    proportions will perform well at small sizes, but not at larger sizes? The theory
    that legibility is separate from readability is unscientific (according to Popper)
    because there is no set of conditions that would show it to be false. It is useless
    because it can't predict anything.\r\n"
  created: '2009-09-09 16:14:30'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> Kevin, if a single powerful vendor decided 2 point was the \u201Cnew world
    order\u201D, you know as well as I do we\u2019d just all have to design 2 point
    masters and fit up the masses with thick glasses\r\n\r\nDavid, you caught on to
    my master plan. Listen up people, buy your shares now in glass manufacturing companies!\r\n"
  created: '2009-09-09 16:15:38'
- author:
    name: enne_son
    picture: 109487
  body: "\u201CWhat is the theory\u2026\u201D [Kevin]\r\n\r\nI'll propose one.\r\n\r\nAt
    thresholds simple discrimination affordance issues become the dominant and limiting
    factor, and these depend on 1) the detectability of distinctive features like
    closure, aspect and where role architectural components meet; 2) the difference
    in perceptual distances between lower case glyphs as compared to the perceptual
    distances between the comparable glyphs in upper case.\r\n\r\nAt peaks or performance
    plateaus issues surrounding the the rapidity and automaticity of \u2018visual
    word-form resolution\u2019 or \u2018gestalt processing\u2019 become the more decisive
    factor. Here gestalt integrity is probably the dimension around which performance
    varies.\r\n\r\nThe consequence of this is that adjusting the size of counters
    or the proportions of the letters relative to each other at agate sizes to enhance
    threshold-level performance might create problems with the rhythmic tuning of
    counters and the phase alignment beneficial to robust, rapid and automatic visual
    word-form resolution on the plateau or at the peaks. As well, the phasal structure
    of an all caps setting and the relatively greater salience of the whites in caps
    that an agate setting allows (compared to all lower case or conventional upper
    and lower case) might be beneficial to the subject's making out what's there at
    thresholds, but suboptimal for gestalt integrity at peaks or plateaus.\r\n\r\n\r\n\r\n"
  created: '2009-09-09 17:41:40'
- author:
    name: William Berkson
    picture: 110306
  body: ">The theory that legibility is separate from readability is unscientific
    (according to Popper) because there is no set of conditions that would show it
    to be false. It is useless because it can\u2019t predict anything.\r\n\r\nI didn't
    explain clearly enough. The general idea that there are differences between legibility--ability
    to identify letters under difficult conditions--and readability under good conditions
    is a general research program, and not a testable theory in itself. \r\n\r\nHowever,
    specific claims of differences are testable and scientific. For example, the theory
    that bigger counters are helpful to identifying letters at very small visual sizes--helpful
    to legibility--but those bigger counters do not help readability (speed, comprehension,
    comfort) at larger sizes is testable. Thus the terminology of legibility and readability
    can be useful, as you can couch testable theories in it. \r\n\r\nAnd, given Arditi
    and Cho, as well as typographic practice, the theory I have stated is very likely
    true, as well as testable. \r\n\r\nAs Popper always said, we don't want to be
    stuck on terminological debates, and the theories of what features work best in
    what situations are what are important, and not the terminology. The point is,
    the idea that all features that help reading in one situation help in every other
    has been refuted, as you say. The question is what's next. \r\n\r\nPeter's discussion
    (which I think I understand) gives some ideas on how to further identify and test
    such features. "
  created: '2009-09-09 20:00:10'
- author:
    name: John Hudson
    picture: 110397
  body: "Kevin: <em>I don\u2019t take this as evidence that legibility and readability
    are distinct, because there was no finding here that could have falsified the
    hypothesis that legibility is distinct from readability.</em>\r\n\r\nBill has
    put forward two different definitions of legibility and readability: one his own
    and one from Lieberman's <em>Types of Typefaces.</em> The latter is closer to
    my use of the terms, and how I believe most typographers reckon the difference.
    I believe this usage and Kevin's belief that legibility and readability are not
    distinct can be reconciled.\r\n\r\nI would put it this way: legibility is the
    property of individual recognisability of letters, and readability is a <em>hierarchical
    set</em> of properties of text including both perceptual or input properties (recognisability
    of words, eye comfort) and cognitive or output properties (ease of comprehension,
    clear use of language, etc.). I suspect Kevin would simply say that what I call
    legibility is simply another part of the readability set of properties and operationally
    indistinct from the whole \u2018decoding\u2019 process. In his favour, it must
    be said, we have a word \u2018reading\u2019 but no parallel gerund for recognising
    individual letters and, of course, the etymology of the word legible is synonymous
    with readable. Further, since Kevin maintains that we recognise words by recognising
    their constituent letters, \u2018leg-ing\u2019 is simply part of reading.\r\n\r\nYet
    it remains the case that recognisability of individual letters -- within the superset
    of properties that constitute readability -- is distinct from other properties,
    and why shouldn't it have a name. Further, because the set of properties is hierarchical,
    each property relying on the lower properties, one can say of legibility, as the
    foundational property, that it is necessary but not sufficient for readability.
    In the same manner, one can say that word recognition is necessary but not sufficient,
    or indeed that any of the perceptual properties are necessary but not sufficient:
    it is perfectly possible to recognise all the words in a text and still not understand
    what the text means. [Yes, I think reading requires comprehension, and if we have
    not understood something -- even imperfectly or incorrectly -- then we have not
    really read. I know how to pronounce Latin, such that I can speak it aloud from
    a text and am good enough at recognising Latin words that I can sight sing them.
    But I can't read Latin, and need to refer to an English translation to understand
    what I am singing.]\r\n\r\nThe \u2018not sufficient\u2019 clause of legibility
    may be expressed this way: individual letters may be recognisable while not contributing
    positively to readability. This is easily demonstrated. These four letters are
    all legible: <em>d</em> <strong>r <em>w</em></strong> o. But would a <strong><em>w</em></strong>o<strong>r</strong><em>d</em>
    set in this manner be readable? Would a page of such words? Letters of different
    sizes may be legible, but do different size letters make readable words when mixed
    together? [Building on an idea I put forward in my lecture at St Bride's, one
    can summarise all these distinctions by saying that letters of different spatial
    frequency may be legible, but will they create readable words when mixed together?]\r\n\r\nIt
    seems to me that in order for an operational distinction between legibility and
    readability to be ignored, it is necessary to assume consistency of letter proportions,
    style and weight, i.e. to assume the characteristics of a single typeface applied
    to, at minimum, words. Much of the time, this is a very reasonable assumption.
    But only because type designers have already absorbed and applied the assumption."
  created: '2009-09-09 20:06:50'
- author:
    name: William Berkson
    picture: 110306
  body: "John, I agree that Lieberman's definition is better. \r\n\r\n>one can say
    of legibility, as the foundational property, that it is necessary but not sufficient
    for readability\r\n\r\nI would add that once a threshold of legibility--of letters--is
    met under a given condition, it may well be that increased legibility under other
    conditions is irrelevant to the reading process under that condition. \r\n\r\nAs
    you know, at my talk at TypeCon this year I also argued that considerations of
    evenness of color and rhythm, aside from legibility of individual letters, also
    contribute to readability. \r\n\r\nAnd as I said, color and rhythm are important
    whether or not one accepts Peter's view that gestalt processes are at work in
    word recognition. (And I do suspect that Peter is right.) Frankly, I think that
    my slides--similar to your \"word\" illustration here, but more extended--made
    the case for the importance of even color and rhythm. And of course it doesn't
    have to be made to type designers, who have by and large been very sensitive to
    these issues. \r\n\r\nPs. I am curious as to when the distinction was made. Lieberman
    has on the same page as that definition photos of Beatrice Warde of Monotype and
    Paul Standard of Linotype, and his book is dedicated to them. He consulted them
    in the writing of the book, along with many others including a young James Mosley.
    I suspect that the distinction was introduced by Linotype folks in the 1930s,
    but I am guessing. "
  created: '2009-09-09 23:25:35'
- author:
    name: kentlew
    picture: 110411
  body: Griffith and Dwiggins, corresponding in 1939, did not make the distinction
    -- certainly not terminologically. For the most part, I've seen the terms used
    pretty much interchangeably. I'm sure they would recognize the broad concepts
    being differentiated here, but I don't think they ever articulated them quite
    as we do today.
  created: '2009-09-10 00:28:14'
- author:
    name: John Hudson
    picture: 110397
  body: "Bill: <em>And of course it doesn\u2019t have to be made to type designers,
    who have by and large been very sensitive to these issues.</em>\r\n\r\nAlthough
    I suspect, insofar as type designers think about <em>why</em> they are sensitive
    to evenness of colour and rhythm, they probably do so in aesthetic terms or, if
    they relate it to reading, they do so intuitively, anecdotally, or presumptively.
    This is why I am excited about Denis Pelli's spatial frequency study, because
    it suggests to me a strong perceptual bias for evenness of colour and rhythm:
    we will read more faster and more comfortably if we do not have to adjust to different
    spatial frequencies. That strikes me as a key insight into <em>why</em> we're
    sensitive to evenness of colour and rhythm, i.e. sensitive to maintaining consistent
    spatial frequency, within a single channel."
  created: '2009-09-10 02:24:40'
- author:
    name: Chris Dean
    picture: 111971
  body: "@ John Hudson: Is this the study you are referring to?\r\n\r\nMajaj, J.,
    Pelli, D., Kurshan1, P. and Palomares, M. (2002). The role of spatial frequency
    channels in letter identification. <em>Vision Research, 42(9)</em>. 1165-1184
    \r\n\r\n(doi:10.1016/S0042-6989(02)00045-7)"
  created: '2009-09-10 03:15:30'
- author:
    name: John Hudson
    picture: 110397
  body: 'Yes, that''s the one. It helps to understand the basic concept of spatial
    frequencies before tackling that study, particularly the concept of spatial frequency
    channels, which provides an explanation for the easily testable phenomenon of
    perceptual adjustment when spatial frequency changes. See: http://www.yorku.ca/eye/spafreq.htm'
  created: '2009-09-10 05:03:17'
- author:
    name: dberlow
  body: "JH> http://www.yorku.ca/eye/spafreq.htm\r\n\r\nNo saccades, no accolades.\r\n\r\nKL>What
    is the theory that determines that agate proportions will perform well at small
    sizes, but not at larger sizes?\r\n\r\nWell, in theory small sizes with agate
    proportions bring more light in just the right places to a reader. \r\nAnd in
    theory large sizes with agate proportions bring more cost in just the wrong places
    to the publisher. \r\nSo, until 5 or so years ago, it was almost never done. No
    one complained that it should be. So, in theory, it shouldn't be done. \r\n\r\nJust
    because people are now using agates large (out of desperation from causes unrelated
    to 'reading'), and there is no proof that it is inferior to use of properly designed
    large sizes, is it a bad theory Kevin? or just a bad situation being made worse
    by bad developers of bad font software for bad systems? being studied, of course,
    by 'good' behavioral psychologists? :) \r\n\r\nCjeers!"
  created: '2009-09-10 13:11:17'
- author:
    name: enne_son
    picture: 109487
  body: "Okay, another Enne-Bomb.\r\n\r\nI have grave difficulties with the terms
    of reference in these debates.\r\n\r\nOn the one hand, for Kevin, decoding is
    decoding. On the other hand, Bill and company refuse to seriously address issues
    of construct validity and quickly resort to easy operationalism.\r\n\r\n[Kevin]
    \u201CWe use that light to recognize features, which we build up into recognized
    words. We read one word, then the next; our eyes move in predictable patterns.
    Environmental conditions can be good or bad, <em>but the eyes do the same thing
    under any condition</em>.\u201D\r\n\r\nThe eyes might do the same thing under
    widely diverse environmental conditions, but does the visual cortex follow suit?
    The possibility exists that under good conditions the visual cortex \u201Cbuild[s]
    up features into recognized words\u201D one way, and that it does so another way
    in poor conditions. I tried to contrast these two ways in my TypeCon Atlanta presentation.
    Denis Pelli draws a similar contrast in his \u201CThe uncrowded window of object
    recognition\u201D when he says \u201Csome objects are recognized through a single
    combining of features over the whole object, whereas other objects require separate
    combining over each of several regions of the object.\u201D His work demonstrates
    that both happen.\r\n\r\nThe relevance of this is that the distinction could anchor
    a stronger differentiation of readability and legibility, where legibility becomes
    associated with performance under conditions in which the latter (slot-processing,
    as I like to call it) is provoked, and readability becomes associated with performance
    under conditions in which the former (a single combining) is enabled. This might
    not be entirely satisfactory however, because it doesn't tell us which functional
    dimensions of perceptual processing in reading legibility and readability relates
    to.\r\n\r\nI tried to lay a basis for specifying which functional dimensions are
    in play in legibility as distinct from readability in my earlier post. This post
    contrasted perceptual discrimination affordance with another kind of affordance
    which I associate with rapid automatic visual word-form resolution. Pelli draws
    a similar contrast when he differentiates between feature detection and feature
    integration. So then legibility becomes associated with performance under conditions
    in which the slot-processing is provoked and perceptual discrimination affordance
    comes into play; and readability becomes associated with performance under conditions
    in which the former (a single combining) is enabled and issues surrounding and
    extending the rapidity and ease of visual word-form resolution ( a single \u201Ctransglyphic\u201D
    gathering or combining) come into play.\r\n\r\nThis brings me to my \u2018refusal
    to address\u2019 complaint with Bill and company. Kevin raised the \u2018construct
    validity\u2019 question. Ole Lund in a Reading dissertation made it the key issue
    in Legibility research, and complain about the dependence on easy operationalism
    to make up for it. Bill, leaning on Popper, doesn't want to get into endless terminological
    debates, but in my opinion sustained reflection on the construct validity of the
    terms and a social contract is the only way to resolve terminological disputes.
    (I almost wrote \u2018therminological\u2019, I guess because these disputes get
    heated.)\r\n\r\nNeither the avuncular Ben Lieberman definition or it\u2019s Berksonian
    replacement are fully serviceable. Why? Because Uncle Ben\u2019s definition doesn\u2019t
    specify what in psychophysical functional terms eyes moving along a line, or telling
    one letter from another, or \u2014most flagrantly \u2014 eyes absorbing messages
    are. This doesn't make the definition garbage. It just makes it unserviceable
    for eliciting informative interpretations of empirical data, no matter how it
    is operationalized.\r\n\r\nBill\u2019s definition leaves unexplained whether or
    not the contrast between deciphering and reading is intended or not, and if intended,
    what in function perceptual processing terms distinguishes the two. Again, this
    doesn't make the definition garbage. It just makes it unserviceable for eliciting
    informative interpretations of empirical data, no matter how it is operationalized.
    What I find potentially useful in Bill\u2019s replacement is the difficult versus
    optimal contrast, because I can relate them to different positions on the typical
    reading performance curve, which, no matter what the variable, typically show
    a steep rise in performance, than a wide plateau followed by a gradual decline.\r\n\r\nSo
    while I am sympathetic to Kevin\u2019s complaints I am frustrated by the unquestionably
    attractive and ostensibly benign straightforwardness of his scheme. And while
    I am sympathetic to Bill and company\u2019s insistence that the broad experiential
    sense of distinguishable dimensions (which has crystallized into language) is
    real and able to be investigated, I am frustrated by his willingness to leave
    them be floating signifiers in terms of what in psycho-physically tractable perceptual
    processing or functional affordance terms the one as distinct from the other has
    a bearing on.\r\n\r\nWhat my provocations lead to in the context of the topic
    for this thread is a partial explanation of why we tolerate all caps on signage
    but are annoyed at them in extended text unless perhaps when they are used in
    the Bob, Bath comment to the story at the opening link."
  created: '2009-09-10 16:36:16'
- author:
    name: William Berkson
    picture: 110306
  body: ">[Lieberman's] definition doesn\u2019t specify what in psychophysical functional
    terms eyes moving along a line, or telling one letter from another, or \u2014most
    flagrantly \u2014 eyes absorbing messages are.\r\n\r\nI strongly disagree that
    this makes Lieberman's distinction between legibility and readability useless.
    On the contrary, when you load theory into it, as you seem to want to, you muddle
    the concept, and make it hard to understand. His definition is so well formulated
    that I regret departing from it. The idea that \"legibility\" applies to letters
    and \"readability\" to lines of words is a clear and understandable distinction,
    and serviceable for discussion and theorizing about type. \r\n\r\nWhenever people
    create technical terms it causes a new barrier to communication. Sometimes it's
    worth it, but the meanings should be a clear as possible, and not loaded with
    theory. The more you load it the higher the barrier to communication. \r\n\r\nFurthermore,
    I agree with Popper that theories, and not terminology are what is important.
    Classical physics can be formulated taking force and mass as primitive terms,
    or work and energy as primitive terms, if I remember rightly. That shows that
    terminology is not decisive. It is only helpful or not.\r\n\r\nFurthermore terminology
    is never, never, never completely clear and precise. Max Jammer wrote books \"The
    Concept of Mass\" \"The Concept of Force\", etc., and if you read them the punch
    line is more or less that nobody knows really what these are.  \r\n\r\nI think
    Lieberman's distinction is helpful because it enables you to formulate what is
    to me the \"fundamental principle of type design\": legible letters are not enough
    to make highly readable text. There's more to it. There's at least color and rhythm,
    and probably the gestalt effects you have theorized about.   "
  created: '2009-09-10 18:50:50'
- author:
    name: enne_son
    picture: 109487
  body: "Bill, I wrote: \"This doesn\u2019t make the definition garbage. It just makes
    it unserviceable for eliciting informative interpretations of empirical data,
    no matter how it is operationalized.\"\r\n\r\nI could have said \"fully informative.\"\r\n\r\nFurthermore,
    I agree that Lieberman\u2019s distinction might be helpful insofar as it associates
    legibility with letters and readability with words, but I need something more
    than 'ease' and 'identification,' or 'ease' and 'absorption' to tell me what functional
    factor performance measures. I want to <em>understand</em> why and in what sense
    it makes sense to say legible letters are not enough to make readable text. Clearly
    it is in any normal sense. Legible letters are enough: they make readily readable
    words. What sub-processes does the eye absorbing messages consist of? And what
    part of that does or should a test of readability measure? What does telling one
    letter from the other consist of, and what part of that does or should a test
    of legibility measure.\r\n\r\nI can't believe that you have no sympathy for my
    hesitations."
  created: '2009-09-10 20:26:21'
- author:
    name: enne_son
    picture: 109487
  body: "Adding some further thoughts.\r\n\r\nYour alternative allows one to say that
    what is good for deciphering or decoding or at thresholds -- a function signage
    must accommodate -- is not necessarily good for continuous reading under good
    conditions.\r\n\r\nAll I'm trying to say is that to articulate a theory of perceptual
    processing in reading that is able to correct or underwrite and deepen or extend
    our understanding of what we say or do, it is not enough to stay with what we
    are prone to say in our ordinary everyday engagement with these things using words
    and metaphors that are ready to hand and modally non-specific. Yet what we are
    prone to say can be an excellent place to start.\r\n\r\nFundamental principles
    don't always provide us with conjectures that support effective refutation in
    their native forms, as Kevin insists"
  created: '2009-09-10 21:06:09'
- author:
    name: William Berkson
    picture: 110306
  body: "Peter, the specific hypotheses I discussed with Kevin are refutable, as I
    said. And I explained the experiments to test readability. \r\n\r\nI think the
    demarcation between identifying letters and reading words in text is useful, but
    I'm ready to drop it in an instant if it's not helpful. It's not important. If
    you want to separate different aspects of readability, such as speed, comprehension,
    comfort--or different aspects of comfort--that is fine. There is no need to have
    a precise definition of readability, or legibility. There is a need for better
    theories of how all these factors work in reading. \r\n\r\nI think my disagreement
    with you about scientific method is over how much should be stuffed into terminology,
    and how much should be put in theory. I am saying that the ideas should should
    be put into theories. Theories are statements, and can be testable. Terminology
    is never testable, only useful or not. \r\n\r\nTheories are statements connecting
    different terms, as in \"mass = force x acceleration.\" The sciences that have
    grown most successfully focus on testing the statements, not inventing or defining
    new terminology. I think that if physics spent its time on first getting the definitions
    of mass, force, and acceleration right, there would still be no physics. Instead
    there would be a mass of terminological disputes, with little progress.   \r\n\r\nI
    know that Popper's advice in this situation would be to focus on creating theories
    to solve the problems of how we read. His view was that new terminology should
    be something that is forced on you to express your explanatory theories, not something
    you seek as a way to the truth. Pursued directly, they are a path to the swamp,
    not to the truth. "
  created: '2009-09-10 21:35:40'
- author:
    name: enne_son
    picture: 109487
  body: "Bill, what in the process of reading as described by Kevin or Pelli or myself
    do your indicators of readability or legibility pick up on? Are they different
    for readability and legibility?\r\n\r\nYou misunderstand what impels me and how
    I proceed. In my forays into the literature I feel the terms that are often used
    to elucidate a reality I am interested in are too crude to express what I -- having
    read about the way the visual cortex and neural transmission works, and having
    been sensitized by philosophical critiques of representationalism and the rest
    -- see going in. So I import and adapt possibly exotic but -- to me at least --
    transparent terms I have found elswhere in my hunting and gathering, and think
    might be applicable. Here I am doing nothing unusual in the scientific domain."
  created: '2009-09-10 23:54:59'
- author:
    name: William Berkson
    picture: 110306
  body: "Peter, I think I do understand your frustration with existing literature
    on reading. Since you have interesting ideas, I can't say you have gone into a
    swamp, even though at times I feel your language sometimes has gone there. I don't
    want to belabor this, but I would just say two things: first, seeking precision
    in terminology can become an endless quest and a distraction from finding testable
    theories. Second, it is hard to communicate new ideas in any case, and new terminology
    can be an additional obstacle to communication. If it is possible to keep new
    terms to a minimum, it promotes communication. And communication is actually quite
    important. \r\n\r\nBecause I don't think terminology is very important to the
    content of a scientific theory, I don't want to put up a big defense of the distinction
    readability vs legibility. But to answer your question: on readability, I have
    said this involves speed, comprehension, and comfort. I think all of those are
    in the psychological literature. Legibility is different because it is, as defined
    by Lieberman and understood also by Hudson, a measure of ability to identify individual
    letters. Such tests of letter recognition are also in the literature. \r\n\r\nIn
    fact, Arditi & Cho tests began with legibility tests, and then switch to readability
    tests. To me these categories are helpful in thinking about what is going on in
    these experiments and others. \r\n\r\nAlso I would also add that because my introduction
    to type was the book Types of Typefaces I have been more ready to listen to your
    theories of how reading words differs from letter recognition. Perhaps you think
    that a benefit, and perhaps not :)"
  created: '2009-09-11 03:14:14'
- author:
    name: John Hudson
    picture: 110397
  body: "Peter: <em>I want to understand why and in what sense it makes sense to say
    legible letters are not enough to make readable text. ... Legible letters are
    enough: they make readily readable words.</em>\r\n\r\nReadability is qualitative
    (and also measurable in terms of speed, comprehension and comfort), so saying
    that something is \u2018readable\u2019 isn't saying much unless you qualify the
    observation to indicate how readable, on a continuum from minimally readable to
    optimally readable (for a specific condition). Legible letters are enough to guarantee
    that text is minimally readable. Consider the classic ransom note made up of letters
    clipped from different newspaper headlines, in different types, sizes, styles
    and colours and pasted on a page: all the letters are legible and, of course,
    the message is readable (it has to be, otherwise junior's gonna get his ear cut
    off). But we don't typeset books like this, and not only because it takes too
    long and uses too much glue.\r\n\r\nAs I wrote above, all the discussion about
    word recognition being derived directly from letter recognition <em>presupposes,</em>
    so far as I can tell, a single typeface set in a single style and size. In other
    words, the model presupposes factors that Bill has identified -- colour (what
    I prefer to call texture) and rhythm -- and, I would argue, consistent spatial
    frequency, which are characteristics of good type design. It is easy to say that
    legible letters result in readable words -- even very readable words -- if the
    other factors of typeface design are a given. If you remove those other factors
    -- mess with spacing, mess with different typefaces, mess with different weights
    and styles, transcend spatial frequency channels within a word --, reducing the
    components of words to merely legible letters, you'll pretty quickly see 'why
    and in what sense it makes sense to say legible letters are not enough to make
    readable text'.\r\n\r\n"
  created: '2009-09-11 03:34:11'
- author:
    name: dberlow
  body: ">Readability is qualitative (and also measurable in terms of speed, comprehension
    and comfort)\r\n\r\nShow me a single study of one font vs. another, believable
    after even the simplest typographic vetting. \r\n\r\n>[C]onsistent [S]patial [F]requency,
    which are characteristics of [g]ood [t]ype [d]esign\r\n\r\nCSF is now more than
    ever, a characteristic of output that can absolutely override gtd.\r\n\r\nAnd,
    since all this talk is aimed at screen readability...\r\n\r\nCheers!"
  created: '2009-09-11 13:05:46'
- author:
    name: enne_son
    picture: 109487
  body: "Bill, my issue isn't terminology, but construct validity. John, when I say
    \u201CI want to understand\u2026\u201D I mean I want to know what specific, single
    item, perceptual processing operator or primitive is at stake when questions of
    legibility or readability are raised.\r\n\r\nLet me explain. Readability and legibility
    have a specialized meaning in typographic discourse as compared with plain language.
    Ben Lieberman\u2019s definition is couched in the language of everyday ordinary
    lived experience, which depends on experientially tractable wholes like identification,
    ease, line following and message absorption. This makes the definitions palpable
    and the terms potentially useful as an evaluative category but not necessarily
    suitable as a fertile term for building greater understanding. Letter-identification,
    line-following and message-absorption are complex acts, and the task and beauty
    of science is it\u2019s ability to break these down.\r\n\r\nLet us say that letter
    identification involves feature detection, role-unit discrimination and some kind
    of combining or feature integration. When issues of legibility are on the table,
    I feel it is enriching / clarifying / disambiguating and productive to put forward
    that all or some of the items in this complex are under the loupe. And that a
    different complex of items or primitives are under the loupe when issues of readability
    are on the table. I feel this is a better strategy than just breaking down readability
    and legibility into matters of comfort, speed and comprehension, as signitors
    of ease."
  created: '2009-09-11 13:45:37'
- author:
    name: enne_son
    picture: 109487
  body: "John, following up on David's comment, it seems more informative to me with
    type to talk about narrow phase alignment, than having a consistent spatial frequency.
    You seem to associate the latter with weight. I'm not following here. I associate
    the former with distribution of role-unit level information. Weight I associate
    with salience and cue value.\r\n\r\nBill, to phrase my frustration another way:\r\nI
    ask, what is legibility about.\r\nYou say ease, which equals speed + comprehension
    + comfort.\r\nI say, ease of what?\r\nYou say, identification or deciphering.\r\nI
    say, yes, but do you mean by these the gathering, streaming and assembly of the
    criterial visual information, which I think has to be, following Pelli and others,
    assessed at the role unit or distinctive feature level? \r\nYou say, maybe, but
    let's not get into that to deeply because it gets confusing / it's a swamp / others
    will recoil / 'deciphering' or 'identification' is clear enough for me.\r\nI say,
    'deciphering' and 'identification' and 'absorbing' are the swamp. Let's jump in
    and see what new things we can turn up.\r\nYou say, go ahead, but don't shout
    back to me about micro-processes and microorganisms, because I think they're microorganisms
    are ugly and micro-processes hard to visualize.\r\nI say, sorry, but that's just
    how it is and this is why I'm here. It would be easier if you jump in which, to
    some extent you and others have begun to do."
  created: '2009-09-11 15:59:57'
- author:
    name: Kevin Larson
    picture: 109739
  body: "I find it easier to work with the definition that legibility is the ease
    with which letters can be absorbed and readability is the ease with which sentences
    (or any larger amount of text) can be absorbed.\r\n\r\nJohn proposed that there
    are effects of readability that are independent of legibility, such as consistency
    of spacing and consistency of letterform. \r\n\r\nTherefore, it is possible to
    have good legibility, but poor readability by badly spacing well designed letters,
    or by combining well designed letters of different typefaces.\r\n\r\nIs it possible
    to have the converse: poor legibility but good readability? Or is legibility a
    subset of readability, so letters with poor legibility will always also have poor
    readability?\r\n\r\nAre lowercase letters an example of poor legibility but good
    readability? Ignoring the Arditi & Cho findings, uppercase letters perform better
    in letter recognition tests, while lowercase letters perform better in sentence
    or passage reading. \r\n\r\nIf lowercase letters are an example of poor legibility
    but good readability, is it because lowercase text tends to have better spacing
    or letter design consistency than uppercase?\r\n"
  created: '2009-09-11 16:20:12'
- author:
    name: William Berkson
    picture: 110306
  body: "Peter, I have no problem with discussing and testing how sub-letter features
    operate in reading. I'm all in favor of it. I'm afraid I haven't successfully
    communicated my concerns about your approach, and the role of terminology in it.
    \r\n\r\nIn any case, the key problem is not terminology, but lack of tests. I've
    suggested some tests of your theory, and that direction is the only one that will
    advance your theory within science, IMHO. That's the bottom line. Lay out the
    tests, and your theory will be clear enough for science, however lucid or awkward
    the terminology. \r\n\r\n>John proposed.\r\n\r\nAs did I extensively at my presentation
    at your panel TypeCon, right? Here is a key slide:\r\n\r\n[img:sites/default/files/old-images/Not_legible_letters_but_readable_words_5618.gif]\r\n\r\nThe
    point is that all of the letters in the \"legible letters\" line are very readable
    when they are with their \"mates\" in style and weight, but as is the two words
    are barely readable. It was interesting to me that mixing both case and italic/regular,
    as well as mixing weights, results in such a dramatic deterioration in readability--much
    more than mixed case alone. \r\n\r\n>If lowercase letters are an example of poor
    legibility but good readability, is it because lowercase text tends to have better
    spacing or letter design consistency than uppercase?\r\n\r\nWell, it's not \"poor\"
    legibility, but sub-optimal. A threshold has to be reached, I believe, before
    reading can take place. I think you now understand the problem that Peter has
    been wrestling with, and what all we type people have been talking about. \r\n\r\nAnd
    yes, lower case has both more even color and better spacing than upper case. If
    you look at lower case, most of the letters have 'four corner' adjustment of black
    within the x-height, so that more even color is possible. Eg compare T and t.
    The cap t inevitably gets more \"holes\" that can only partly be compensated for
    by spacing. In addition ascenders and descenders I think increase ease of recognition
    of word image--a gestalt effect.  \r\n\r\nPeter in particular has argued that
    letter recognition is worse in normal spacing of lower case, because of crowding.
    But that closeness is actually better for getting the word image, the gestalt
    formed by a collection of interpreted sub-letter features across the word. Thus
    words and letter combinations read better and single letters worse. That accounts
    for the Word Superiority Effect. \r\n\r\nAnd the experiments I suggested to you
    were designed to test that in more revealing way than previous tests. The apparatus
    unfortunately did not allow you to get the short exposure times of the original
    experiments of Purcell, and so were not dispositive on the issues.\r\n\r\nIf they
    are repeated with the short times, I think they will be more revealing. I can
    discuss this at more length with you. \r\n\r\nI have also suggested an experiment
    using the WSE and missing letter parts which will be even more revealing, I think.
    This was in part of my TypeCon talk that I didn't get to because of lack of time.
    \r\n\r\nSeparating the benefits for readability of only good spacing and even
    color from the gestalt effects is something I haven't thought about yet, but that
    should be doable also. "
  created: '2009-09-11 17:47:17'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>Show me a single study of one font vs. another, believable after
    even the simplest typographic vetting.</em>\r\n\r\nSure: I sat down and read one
    book and then I sat down and read another book, and I found one easier to read
    than the other and got through it quicker. This is what I mean when I say that
    readability is qualitative and measurable in terms of speed, comprehension and
    comfort. This isn't a conclusion based on laboratory studies; it is a quotidian
    observation based on doing reading, not studying reading.\r\n\r\n<em>And, since
    all this talk is aimed at screen readability...</em>\r\n\r\nIt is? I suppose Kevin's
    engagement might be, because that's his job, but I don't see anything in what
    Bill, Peter or I have written that indicates that this talk is aimed at screen
    readability or, indeed, aimed at readability at all. I believe it is aimed at
    understanding how reading works and being able to describe that in meaningfully
    precise terms. Readability is, I argue, a set of properties of text, and hence
    largely irrelevant to understanding reading as an activity of eyes and brains.
    As Peter memorably wrote on another occasion: \u2018trying to construct a science
    of readability might be like calling physics the science of the fall-down-ability
    of falling objects\u2019. Readability is only relevant to understanding reading
    insofar as empirical testing must try to isolate and control readability properties."
  created: '2009-09-11 18:29:46'
- author:
    name: John Hudson
    picture: 110397
  body: "Kevin: <em>Is it possible to have the converse: poor legibility but good
    readability? Or is legibility a subset of readability, so letters with poor legibility
    will always also have poor readability?\r\n\r\nAre lowercase letters an example
    of poor legibility but good readability?</em>\r\n\r\nI agree with Bill: a baseline
    of legibility is necessary to readability. This baseline can probably be defined
    as the distinction between illegible and legible letters, with the caveat that
    if you have one or two illegible letters but put them in context of legible letters
    the results will be readable on the basis of context. If most or all of the letters
    are illegible, readability is defenestrated.\r\n\r\nI wouldn't characterise lowercase
    letters as having \u2018poor\u2019 legibility. Obviously they have \u2018good
    enough\u2019 legibility: writing systems don't tend to develop poorly legible
    shapes, and if letter recognition tests indicate that particular letters are <em>very</em>
    difficult to identify that would suggest to me that identification of those isolated
    letters is not very important to reading that writing system."
  created: '2009-09-11 18:45:00'
- author:
    name: John Hudson
    picture: 110397
  body: "Re. spatial frequency\r\n\r\nMy understanding is that spatial frequency involves
    both quantity of periodic changes across space and quality of the transitions
    between those changes. So yes, it relates to weight, because different weights
    of type have different spatial frequencies due to different arrangements of dark
    and light shapes within the same area. But it also relates to what I call stroke
    density, and the resulting quality of the transitions between dark and light shapes,
    and this is an area in which type on screen differs significantly from type on
    paper and, indeed, in which different kinds of rendering on screen differ significantly
    from each other, and how different monitor gammas make type in the same rendering
    differ, etc. However, insofar as within any one of these conditions the letters
    have consistent spatial frequency, spatial frequency can be isolated as a factor.\r\n\r\nI
    should also clarify that when I talk about \u2018consistent spatial frequency\u2019,
    what I mean is restrained within a single spatial frequency channel. In other
    words, the reader doesn't need to change channels in order to be able to perceive
    different letters in a word. Within this channel, there is obviously quite a lot
    of room for variation of letterforms -- enough to allow of all these typefaces
    -- so consistency in this case does not imply uniformity."
  created: '2009-09-11 19:00:14'
- author:
    name: dberlow
  body: "Kevin>What is the theory that determines that agate proportions will perform
    well at small sizes, but not at larger sizes? \r\n\r\nYour organization did a
    study where Verdana was compared to Arial. What was publicized, is that the people
    studied preferred Verdana. I encouraged you to investigate all the results, which
    showed that the Verdana preference faded as the size increased until Arial was
    preferred. \r\n\r\nFinish, and perhaps you will have a theory, if you want one.
    \r\n\r\nKL>Is it possible to have the converse: poor legibility but good readability?
    \r\n\r\nYes, the study that showed helvetica e more 'readable' than the garamond
    e 'proved' that beyond a doubt. ;)\r\n\r\nKL>Or is legibility a subset of readability,
    so letters with poor legibility will always also have poor readability?\r\n\r\nI
    think it depends on the poorness of the legibility and whether or not it can be
    hidden, (like the garamond e), in familiar ways. \r\nBut in general, poor legibility
    in letters will always yield poor readability because those who choose, or are
    condemned to fonts of poor legibility will not likely be 'super-typographers.'\r\n\r\nDB>And,
    since all this talk is aimed at screen readability...\r\n\r\nJH> It is? I suppose
    Kevin\u2019s engagement might be, because that\u2019s his job, but I don\u2019t
    see anything in what Bill, Peter or I have written that indicates that this talk
    is aimed at screen readability...\r\n\r\n>...and this is an area in which type
    on screen differs significantly from type on paper and, indeed, in which different
    kinds of rendering on screen differ significantly from each other...\r\n\r\nHow
    about now? Can I talk about crappy anti-aliasing scaling now?\r\n\r\n>...the reader
    [shouldn't] need to change channels in order to be able to perceive different
    letters in a word.\r\n\r\n... then why make them? ;-)\r\n\r\n>Sure: I sat down
    and read one book and then I sat down and read another book, and I found one easier
    to read than the other and got through it quicker. \r\n\r\nAhh, but you read two
    different books. And how can you sit down twice without standing up. Show me a
    STUDY. I can tell you tales all day of people who can't, won't or don't read their
    screens John, because of spatial frequency terror. But if that's not good enough,
    what do we care about your book reading tales?\r\n\r\nCheers! "
  created: '2009-09-11 21:10:09'
- author:
    name: John Hudson
    picture: 110397
  body: "A study that shows what, David? That readability is qualitative? That we
    can speak meaningfully about a text being more or less readable than another text?
    That we reckon readability in terms of speed, comprehension (also retention) and
    comfort? This is all I asserted, and I challenge you to show me a study that <em>doesn\u2019t</em>
    show this or, indeed, doesn't presuppose this, based on common sense and everyday
    experience. You don't need a study to prove that when we read we use our eyes
    and our brain. Some things are obvious to casual observation, and the fact that
    some things are easier or harder to read than others is one of them.\r\n\r\nStudies
    may or may not have something to tell us about <em>why</em> some things are easier
    or harder to read than others -- and I agree with you about the typical faults
    of reading studies --, but I wasn't making any comment on that question."
  created: '2009-09-11 23:15:47'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>How about now? Can I talk about crappy anti-aliasing scaling now?</em>\r\n\r\nOnly
    if you take into account what else I wrote: \u2018However, insofar as within any
    one of these conditions the letters have consistent spatial frequency, spatial
    frequency can be isolated as a factor.\u2019 In other words, the fact that spatial
    frequency varies across reading conditions is irrelevant to the impact of <em>change</em>
    in spatial frequency so long as it is consistent within a single reading condition,
    whether that condition is deemed positive or negative. Crappy anti-aliasing scaling
    is a (presumably negative) reading condition.\r\n\r\nNow, independent of the impact
    of changes in spatial frequency on reading, there is the separate question of
    whether specific spatial frequencies are better or worse for reading. And in looking
    at this question, you need to isolate different factors to determine the specific
    effect of changing spatial frequency within a particularly reading condition.
    This is where you can start talking about crappy anti-aliasing, as resulting in
    a specific spatial frequency. What can we say about it? Well, it is a relatively
    low spatial frequency, because we're losing sharp edge contrast. Is it worse for
    reading than a higher spatial frequency and sharp edge contrast? Is there a point
    at which edge contrast becomes too sharp, at which reading benefits fall away?
    Or is the sharpest edge contrast permitted by the medium always to be preferred,
    all else being equal?\r\n\r\nAnd just try getting everything else equal!"
  created: '2009-09-11 23:32:24'
- author:
    name: dberlow
  body: "> the reader doesn\u2019t need to change channels in order to be able to
    perceive different letters in a word\r\n\r\nI was reacting to this. The reader
    should not need to change channels in order to be able to perceive different letters
    in a word. It's saccadicide. \r\n\r\n>This is where you can start talking about
    crappy anti-aliasing,\r\n\r\nAnd I lump this together with misuse of extreme sized
    masters. So when one does both... and studies readability without making reference
    to these conditions, then what?\r\n\r\n>And just try getting everything else equal!\r\n\r\nThat
    is what some of us do.\r\n\r\nReaching back to the comedy of definitions, \r\n\r\n>writing
    systems don\u2019t tend to develop poorly legible shapes,\r\n\r\nThe I's have
    it. Think about those definitions relative to sans, Ills.\r\n\r\nCheers!"
  created: '2009-09-12 18:40:11'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>I was reacting to this. The reader should not need to change channels
    in order to be able to perceive different letters in a word. It\u2019s saccadicide.</em>\r\n\r\nYes.
    We are agreeing. The point I was making is this: it is not enough for individual
    letters to be legible in order for text to be readable: the letters also have
    to work together and one aspect of this is achieving consistent spatial frequency.
    This is par for the course in type design.\r\n\r\n<em>Think about those definitions
    relative to sans, Ills.</em>\r\n\r\nI have thought about it: every style of writing
    the Latin script prior to the modern sans serif typographic letter made a visual
    distinction between I and l. The writing system didn't have a problem with this:
    only some type designers did."
  created: '2009-09-12 23:55:35'
- author:
    name: dberlow
  body: ">The writing system didn\u2019t have a problem with this: only some type
    designers did.\r\n\r\nAnd today?\r\n\r\nCheers!"
  created: '2009-09-13 17:36:21'
- author:
    name: Chris Dean
    picture: 111971
  body: "I've been off the grid in the woods for the last week or so and have fallen
    behind in this thread. As I continue to read read I notice references to Tinker
    and his studies.\r\n\r\nWhich specific studies are we referring to?\r\n\r\nI am
    in the process of reviewing:\r\n\r\nTinker, Miles A. (1965). <em>Bases for effective
    reading</em>. Minneapolis: University of Minnesota press.\r\n\r\n(for fun, here's
    what I get to see what I wake up in the morning at the camp)[img:sites/default/files/old-images/cottage_5006.jpg]"
  created: '2009-09-13 18:41:18'
- author:
    name: Chris Dean
    picture: 111971
  body: "@ Moderators: Is there a formal way to re-direct conversation from a thread
    that goes somewhat off topic? For example:\r\n\r\nLet's continue this conversation
    of in another thread: [[http://typophile.com/node/61947|CAPITAL LETTERS versus
    Upper and lower case]]."
  created: '2009-09-13 20:28:08'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>And today?</em>\r\n\r\nMost recent sans serif types I've looked
    at seem to make some effort to distinguish I and l, either through height difference,
    or distinct terminals, or some combination."
  created: '2009-09-14 05:25:13'
- author:
    name: joeclark
    picture: 110605
  body: "> writing systems don\u2019t tend to develop poorly legible shapes\r\n\r\nI
    saw you at ATypI Vancouver tell us in the audience that you tweaked individual
    pixels in your Hebrew fonts to make the roughly two dozen letters that look like
    rectangles vaguely less illegible.\r\n\r\nOh, and? Chinese much?\r\n\r\nYou have
    used up your annual allotment of \u201CWhat was I thinking?\u201D statements.\r\n\r\n\u2014
    \ \r\nJoe Clark\r\nhttp://joeclark.org/"
  created: '2009-09-14 05:50:49'
- author:
    name: John Hudson
    picture: 110397
  body: "Joe, the challenges to legibility in low resolution environments, which may
    affect one script more than another, are generally not anticipated in the development
    of writing systems. Also note that in the full comment from which you quoted,
    I contrasted \u2018poorly\u2019 with \u2018good enough\u2019. I stand by the comment,
    because I do believe that writing systems are intended to be read, and are read,
    and this implies that the shapes used within those writing systems are indeed
    \u2018good enough\u2019 for reading, presuming that they are legibly made. And
    that's the kicker: legibility of forms within a writing system means something
    like \u2018ability to be made in a legible way that is good enough for reading\u2019,
    not inherently legible or illegible. This leaves the onus on writers and type
    designers to interpret the normative forms in ways that are more or less legible.
    And this is what we do: we don't invent new letters in order to be more legible,
    we interpret the existing letters. This leaves the door open to styles of writing
    that are less legible than others, some deliberately so."
  created: '2009-09-14 10:53:37'
- author:
    name: dberlow
  body: ">Most recent sans serif types [...] make some effort to distinguish I and
    l, either through height difference, or distinct terminals, or some combination.\r\n\r\nYes
    they do. But if I had to add an extra nose to be more easily recognized, I'd pass.
    \r\n\r\nThe true features of I and l that distinguish them in their character
    groups, are the slight exaggerations to stem thickness and spacing, relative to
    their nearest kin, not characters from distant groups. The writing systems can
    definitely handle this, (to prevent what MS calls, \"the BIll Hill problem\")
    \ But because of other closely related problems, they don't. So now... we've got
    simplified Latin, i.e. minimal information designed into the font for the reader,
    poor scaling and not enough pixels.\r\n\r\nAnd, the challenges to legibility in
    low resolution environments, though not specifically anticipated in the development
    of writing systems, are...in the form of grids upon which most classically love
    fonts are plotted. But even these are defeated by the one thing no writing system
    could ever anticipate, a lack of competition leading to a constraint of development
    and trade leading to what we see today on most people's screens. \r\n\r\nCheers!\r\n"
  created: '2009-09-14 13:52:33'
- author:
    name: William Berkson
    picture: 110306
  body: "Christopher, Typophile has followed the Talmudic model: if a more interesting
    topic comes up in the course of a discussion, that new topic is followed, and
    recorded. That's fine with me, because I love the Talmud. The main drawback might
    be that the topic title is misleading, but in the case of the internet, everything
    is indexed anyway, so the topic title actually has no special significance in
    search. \r\n\r\nAlso the new topic is not capital letters vs lower case, but legibility
    and readability. So why not leave well enough alone? What is gained by breaking
    the thread? I don't see it. And what is lost is something: the continuous narrative
    findable in one search. \r\n\r\n*\r\n\r\nAt any rate, I wanted to clarify that
    there are several different issues here. One question is how legibility of letters
    in difficult conditions relates to their legibility in optimal reading conditions.
    It does seem that this is different. Another issue is how the identification of
    letters under optimal conditions relates to the identification of words. Neither
    Lieberman's definition nor my earlier one above--not so good--really captures
    that there are two issues here. \r\n\r\nOn the issue of what more there is to
    reading than identifying letters, I mentioned in my TypeCon talk three things:
    good rhythm, even color, and the formation of a word image or \"gestalt\" or \"bouma\".
    I do think it should be pretty easy to show that uneven spacing eg destroys the
    Word Superiority Effect. But this does not yet prove that \"gestalt\" effects
    are happening. This is because what may be critical is just that the letters fit
    into a grid. The brain may impose a grid, and look for letters within it. So the
    disrupted spacing may just affect our ability to identify letters. \r\n\r\nStill,
    is might be possible to separate the two effects by seeing whether it is significantly
    more difficult to identify letters in unevenly spaced non-words vs evenly spaced
    non-words. When testing is done in all variations for both words and non-words,
    I think the result would be interesting. \r\n\r\nI am also struck by how deadly
    mixing italic and roman is to readability. Testing the effects with words and
    non-words would also be interesting as to what it says about our mental grid or
    matrix.  "
  created: '2009-09-14 14:38:15'
- author:
    name: russellm
    picture: 111614
  body: "<cite>Most recent sans serif types [...] make some effort to distinguish
    I and l, either through height difference, or distinct terminals, or some combination.</cite>\r\n\r\nfunnily
    enough, I recently came across a sign where the font in use had \"l\" with a curved
    tail to disambiguate lc \"l\" from uc \"I\", where a double \"ll\" could be confused
    with lowercase \"tt\". (And was by me) Admittedly when when set too tight and
    viewed in poor light while in a hurry\u2026 and before a first cup of coffee.
    \r\n\r\n\r\n-=\xAE=-"
  created: '2009-09-14 18:48:29'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> I do think it should be pretty easy to show that uneven spacing eg destroys
    the Word Superiority Effect.\r\n\r\nBill, in the study that you and Peter proposed,
    but decided to not discuss at TypeCon, the data showed that there was a statistically
    reliable Word Superiority Effect for alternating case words. That data doesn\u2019t
    directly falsify your above statement, but does falsify any claim that lack of
    rhythm destroys the Word Superiority Effect.\r\n\r\nIf someone found that a Word
    Superiority Effect was still there with uneven spacing, would that falsify your
    above claim?\r\n"
  created: '2009-09-14 22:10:30'
- author:
    name: William Berkson
    picture: 110306
  body: "Kevin, in the experiments graciously you did, the times of exposure were
    too large to replicate Purcell's findings. In our communication with Purcell,
    he anticipated problems with the experimental set up you were using, as we related
    to you. In your experimental set up, with the longer stimulus times, you could
    not get a normal WSE except with letters as masks, rather than the overlaid Xs
    and Os of Purcell.  \r\n\r\nOur hypothesis concerned two levels of WSE, one at
    shorter times primarily due to visual effects and the second cognitive, based
    on an influence of word memory. The fact that the exposure times were longer,
    and that letter masks interfered more with stimulus identification made it plausible
    that memory was involved. Since no shorter times were involved, our hypothesis
    wasn't really tested.  \r\n\r\nSince our predictions involved longer and shorter
    exposure times for the exposure of stimulus, and your experimental set up did
    not get those, I felt it wasn't a valid test of our hypothesis. If you replicate
    this with a set up that can get the longer and shorter times, and careful control
    of the SOAs (time gap between stimulus and mask),it would be valid, and either
    refute or corroborate our hypothesis. Because your experimental set up did not
    really test what we looking for--the set-up first needed to replicate Purcell,
    and didn't--I felt it wasn't worth explaining the whole thing at TypeCon. \r\n\r\nPresence
    of a WSE with mixed case that you found under your conditions has as you know
    been been found before. --In fact our hypothesis is an alternative explanation
    for that effect. And it does not in itself refute \"any claim that lack of rhythm
    destroys the Word Superiority Effect.\" We were only using three letter stimuli,
    and no disrupted spacing, which still gives a pretty even look. If the s pa ci
    n g  were like this, with longer words, I do expect there would be a destruction
    of the WSE, such as Purcell found a destruction of the WSE with very wide spacing
    of letters. \r\n\r\nFurther, with timed tests with comprehension, rather than
    a WSE test, I think it will be possible to show that disrupted spacing slows down
    reading--ie will hurt readability.\r\n\r\nI should add that I don't think that
    reading test by itself it would test Peter's theory of gestalt effects. It would,
    though, test the idea that letters falling near a regular rhythm is important
    to readability. "
  created: '2009-09-14 22:56:13'
- author:
    name: dberlow
  body: ">Because your experimental set up did not really test what we looking for...\r\n\r\nBill,
    maybe it'll be better if I ask you: did that study include any actual reading
    conditions? Did it contain any systematic study of real world word-shape destruction,
    along the lines of Quart or ClearType? \r\n\r\nCheers!"
  created: '2009-09-15 13:19:00'
- author:
    name: William Berkson
    picture: 110306
  body: ">did that study include any actual reading conditions? \r\n\r\nThe tests
    involved regular and widely spaced three letter combination, in Minion, at pretty
    big size, but distant, so probably low resolution screens were not an issue. There
    were both words and non-words. \r\n\r\nThe complication was that Purcell and colleagues
    originally used a Tachistoscope, which can expose a stimulus down to as short
    as 1 millisecond intervals, to get their finding that the Word Superiority Effect
    disappears with wide spacing. Kevin was using a computer screen, whose refresh
    rate, if I remember correctly, is 17 milliseconds. As a result, I think, Purcell's
    results couldn't be duplicated with his mask of overlaid Xs and Os.\r\n\r\nThe
    idea behind the experiment:\r\n\r\nPeter Enneson had argued that the finding of
    a word superiority effect for mixed case--which seems to refute the existence
    of any gestalt or global \"word image\" effects--was flawed. The experimenters
    had not controlled for what is called the \"Stimulus Onset Asynchrony.\" The SOA
    is an awkward name for the time interval between exposure of the stimulus (the
    word or non-word) and the exposure of the mask. After the exposure of the mask,
    subjects identify a letter in the word or non-word. If they are better at identifying
    letters in words, that is a 'word superiority effect'.\r\n\r\nBecause we read
    mixed case more slowly--at 80% speed according to Frank Smith--Peter felt that
    a different reading process was going on, and this confounded the results. And
    Marilyn Jager Adams had mentioned a longer SOA.\r\n\r\nFollowing Peter's analysis,
    I hypothesized that there are two different Word Superiority Effects, one that
    works at very short times, which involves word image or gestalt, and one that
    works at longer times, when the word already gets into the brain's memory banks,
    and involves memory of spelling. \r\n\r\nSince the experimental set up Kevin used
    had longer time intervals, and didn't have any difference in SOA for lower case
    and mixed case--unlike Marilyn Jager Adams--I figure that what I was looking for
    is not really being tested. \r\n\r\nI also suggested other tests, involving disrupted
    spacing--as mentioned above--and also using missing letter parts, which I think
    would be the best test of all. However the one Kevin started with involved words
    vs nonwords, at regular and wide spacing, both with all lower case and mixed case.
    And, as I said, I don't think the results were as revealing as I had hoped, because
    of the lack of fine control over the SOA.    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"
  created: '2009-09-15 16:22:19'
- author:
    name: Chris Dean
    picture: 111971
  body: "Idea to assist in following a threads of this academic nature:\r\n\r\nThe
    first time you mention a study, provide a full reference (APA or otherwise):\r\n\r\nMajaj,
    J., Pelli, D., Kurshan1, P. and Palomares, M. (2002). The role of spatial frequency
    channels in letter identification. <em>Vision Research, 42(9)</em>. 1165-1184\r\n\r\nThereafter,
    provide a name and date:\r\n\r\nAs seen in Majaj et al. (2002), it is obvious
    that\u2026\r\n\r\nI suggest this as several pages in, it becomes a bit confusing
    to keep track, and if it's an exceptionally long thread, without dates (2002),
    it's very difficult to track unless you start reading the entire thread from the
    beginning.\r\n\r\n\r\n@ Berkson: which Purcell study are you referencing?\r\n\r\n\r\n"
  created: '2009-09-15 18:35:05'
- author:
    name: William Berkson
    picture: 110306
  body: "The Purcell papers I am referring to are:\r\n\r\nVisual angle and the word
    superiority effect, by Dean G. Purcell, Keith E. Stanovich and Amos Spector, Memory
    and Cognition, 1978, vol 6(1), p 3-8.\r\n\r\nSome Boundary Conditions for a Word
    Superiority Effect, by Dean G. Purcell and Keith E. Stanovich, Quarterly Journal
    of Experimental Psychology (1982) 34a, p 117-134.\r\n\r\nOriginally I predicted
    the vanishing of the WSE based on Peter's theory. In a literature search, Peter
    found that the experiment I suggested I had suggested had already been done, with
    the results I predicted, in these two papers. \r\n\r\nHowever, why the WSE vanishes
    has never been explained, as Purcell was mainly concerned to remove spacing as
    a confounding factor in other experiments, not to investigate it. \r\n\r\nWe want
    to investigate it and other effects I have mentioned systematically, as we think
    they are a clue to a deeper understanding of reading. We think it will also refute
    the current notion that reading is all a matter of legibility of individual letters,
    and establish the importance of other factors, including gestalt effects.   \r\n\r\n"
  created: '2009-09-15 19:54:23'
- author:
    name: dberlow
  body: ">The tests involved ...\r\n\r\n..no actual reading. :(\r\n\r\nCheers!"
  created: '2009-09-16 12:27:14'
- author:
    name: Chris Dean
    picture: 111971
  body: "This is a great thread. A lot of good material.\r\n\r\n@ Berkson: Thanks
    for the references. Re your M<em>i</em>x<em>Ed</em> C<em>aS</em>e a<em>N</em>D
    ST<em>yl</em>E slide, have you conducted/published an experiment using these IV's?"
  created: '2009-09-16 14:32:52'
- author:
    name: William Berkson
    picture: 110306
  body: ">..no actual reading. :(\r\n\r\nI don't have access to a lab, or the financial
    backing to do psychological research. \r\n\r\nI would love someone to do the timed
    SAT reading tests with different fonts and layouts, such as I mentioned above.
    These would be real reading tests. \r\n\r\nHowever, the tests with flashed words
    and masks may help reveal some things about the reading process that we can't
    easily find out other ways. And the new insights may be later confirmed by real
    reading tests. So I don't think such tests are in principle useless.  \r\n\r\nWhat
    happens in the time interval between flashing a word very briefly, and flashing
    a mask? Answering that question may give us insight into how the brain--both visual
    cortex and language areas--processes words. Peter's view now is that we need to
    study this in more depth, by seeing how step-by-step small increases in exposure
    times and SOAs affect the Word Superiority Effect.\r\n\r\nKevin was generous enough
    to do these experiments, even though he was very skeptical about our hypothesis
    of the two levels of Word Superiority Effect. That is really a tribute to his
    open-mindedness and good will. Thank you Kevin!\r\n\r\nUnfortunately, the experimental
    apparatus wasn't adequate to get the base result: the difference between lower
    case and mixed case words in the SOA needed for word recognition. Thus unfortunately
    the set up was not able to test what we were looking for.  \r\n\r\nChristopher,
    no, as I do not have access to a lab, I haven't done any experiments with the
    mixed case and style. I do think it is pretty obvious even from your example that
    this is going to very significantly slow down reading, and probably even more
    than mixed case. And this I think shows at the very least that the approximate
    \"grid fitting\" of letters is important to readability. \r\n\r\nThe shifting
    of the angle of the grid seems to have a particularly damaging effect on reading.
    I also have noticed that after working on an italic design for hours, when I switch
    to Roman, it appears slanted, even though it is actually upright. I think that
    shows that the brain has a \"switch\" for what grid it imposes, to look for letter
    features on and departing from the grid. \r\n\r\n"
  created: '2009-09-16 15:35:38'
- author:
    name: Chris Dean
    picture: 111971
  body: '@ Larson: Have you written/published this work? I would love to see the paper.'
  created: '2009-09-16 15:49:17'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> Have you written/published this work?\r\n\r\nThe plan was for Bill and
    Peter to write this paper, but the paper frequently doesn\u2019t get written when
    data doesn\u2019t turn out conclusive one way or the other. No one is willing
    to publish (or read) papers that don't have strong conclusions.\r\n\r\n> I don\u2019t
    have access to a lab, or the financial backing to do psychological research.\r\n\r\nI
    would like to emphasize here that reading tests don\u2019t have large out-of-pocket
    costs. The only equipment that you need is a room with adequate light. I use a
    software program that costs a few hundred dollars (E-Prime), but that\u2019s not
    even necessary for most studies. The only other cost is recruiting people to come
    and participate in your study. Friends or students on a college campus can be
    recruited cheaply.\r\n"
  created: '2009-09-16 16:32:27'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> ..no actual reading. :(\r\n\r\nReading a single word is reading.\r\n\r\nFor
    many questions it makes more sense to look at reading single words than reading
    sentences or pages. Earlier in this thread I described decoding and comprehension
    as two separate components of reading. Typography has a clear impact on decoding,
    but comprehension is impacted by the quality of the writing and the readers\u2019
    background knowledge.\r\n\r\nReading single words is a good task because it measures
    the ease of decoding separate from the quality of the writing or readers\u2019
    background knowledge.\r\n\r\nThere are typographic variables that extend beyond
    single words, and longer reading tasks are needed to investigate these variables,
    but these are more difficult to measure because of the impact of comprehension.\r\n"
  created: '2009-09-16 16:57:45'
- author:
    name: dberlow
  body: ">The only equipment that you need is a room with adequate light. \r\n\r\nCouldn't
    each participant just stay at home? You could save a bundle and have more diversity
    in readers than just the unusual suspects. Can't you do this online yet?\r\n\r\n>Reading
    single words is a good task because it measures the ease of decoding separate
    from the quality of the writing or readers\u2019 background knowledge.\r\n\r\nWell,
    then! you now have ideal conditions for studying readability (of Chinese). Not
    to mention reading single words, for the most part, loses those logically pesky
    saccades. Let's say, more than 7 saccades is reading, and less is leging.\r\n\r\nIs
    seems eager enough to lump our interaction with long passages of text & our interaction
    with the single word, into the general meaning of 'reading' in the context of
    these 'conversations'?\r\n\r\nDescribing decoding and comprehension as two separate
    components of reading can't be proven to be study-able one at a time.\r\n\r\nDecoding
    and comprehension break down into topics that cross your definitions. This was
    proven in one such study that showed the Helvetica e more 'readable' than the
    old style dutch e.. That is false in terms of 500 years of readability, true from
    50 years of legibility (and eye doctor visits). \r\n\r\nI would always say you
    are studying signage, or to be more technical, legibility. Whenever you get to
    readability, you'll know what to do. \r\n\r\nCheers!\r\n"
  created: '2009-09-17 22:23:16'
- author:
    name: Chris Dean
    picture: 111971
  body: "\"Couldn\u2019t each participant just stay at home? You could save a bundle
    and have more diversity in readers than just the unusual suspects. Can\u2019t
    you do this online yet?\"\r\n\r\nYes, but that's an [[http://en.wikipedia.org/wiki/Internal_validity|internal]]
    vs [[http://en.wikipedia.org/wiki/External_validity|external]] validity trade
    off. Both have their benefits.\r\n"
  created: '2009-09-18 17:48:21'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>Let\u2019s say, more than 7 saccades is reading, and less is leging.</em>\r\n\r\nWhy
    not 6? or 8? or any other arbitrary number?\r\n\r\nWe can, of course, assign names
    to any arbitrary phenomenon we want, even deciding to call reading a sentence
    in isolation different from reading a sentence embedded in a longer text, even
    if the same number of saccades are employed. But what we call things is not the
    question. The question is what is actually happening when we read.\r\n\r\nI'm
    very much aware that quantitative changes can result in qualitative changes, so
    maybe 7 saccades is the magic number beyond which something different happens.
    But I wouldn't assume that this is the case or, even, that there is a magic number,
    i.e. that our perceptual and cognitive functions have, in effect, more than one
    way of reading.\r\n\r\nI also think that we can become subjectively aware of experiential
    changes in consciousness that are independent of unconscious functions. In other
    words, how we experience reading a page of text might be consciously different
    to us from how we experience reading a head word at the top of a dictionary page,
    but that does not imply that we are using different perceptual and cognitive functions."
  created: '2009-09-18 23:56:57'
- author:
    name: Chris Dean
    picture: 111971
  body: "\"<em>\u2026maybe 7 saccades is the magic number\u2026</em>\"\r\n\r\nMiller,
    G. A. (1956). [[http://www.musanim.com/miller1956/|The magical number seven, plus
    or minus two: some limits on our capacity for processing information]]. <em>Psychological
    Review, 63</em>. 81-97."
  created: '2009-09-19 16:54:33'
- author:
    name: enne_son
    picture: 109487
  body: "Nice!\r\n\r\n\"The input is given in a code that contains many chunks with
    few bits per chunk. The operator recodes the input into another code that contains
    fewer chunks with more bits per chunk.\" \r\n\r\nIsn't this what happens in learning
    to read, where letters make up a word?"
  created: '2009-09-19 18:25:34'
- author:
    name: dberlow
  body: "Enne>Isn\u2019t this what happens in learning to read, where letters make
    up a word?\r\n\r\nAnd aren't we learning 'till the day we stop reading? It would
    be na\xEFve, in my opinion, to put any other fa\xE7ade on it.\r\n\r\nJohn>But
    what we call things is not the question.\r\n\r\nGood, then I'll do a study where
    the definition of dressed is a toe ring, monitor the vital signs of my subjects
    observing a dressed and undressed model, and not understand why there is no vital
    sign delta in my subjects. \r\n\r\nAt least we can all have a good time.\r\n\r\n>But
    I wouldn\u2019t assume that this is the case or...\r\n\r\nOn normal adrenaline
    it is seven. Why do CAPITAL LETTERS so annoy us?\r\n\r\nWe have a preprogram,
    a font program, and a glyph program (which only runs when the decomposer fails),
    and a decomposer. \r\n\r\nSo, all caps bother us here, because the preprogram
    determines what here is, and thinks we're reading shouting. \r\n\r\nThey don't
    bother us in signage because the preprogram recognizes them as normal, the font
    program makes them useful and as there are never too many for us to decompose
    with ease, the glyph program rarely runs.\r\n\r\nThey bother us in long passages
    of text because, after a while they disturb the decomposer which is 'used' to
    more different tops and bottoms in the letterforms, than all caps provide. I think
    we can read more caps in a heightened state, and fewer in a depressed state, but
    that'll have to wait 'till I combine my reading experiment with my dressing experiment.\r\n\r\nWe
    are using different perceptual and cognitive functions because type, (and dressed)
    is not one thing. But I don't think 'people' have much trouble with anything but
    the most generally imagined use of that word \u2014 Do They? Do we need to improve
    the way people can read eye charts? mall signs? Headlines? James & Co. have taken
    care of road signs. \r\n\r\nThe last frontier seems to be ye olde arbitrary computer
    screen and long small stuff. ;)\r\n\r\nCheers!\r\n"
  created: '2009-09-20 13:47:33'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>They don\u2019t bother us in signage because the preprogram recognizes
    them as normal, the font program makes them useful and as there are never too
    many for us to decompose with ease, the glyph program rarely runs.</em>\r\n\r\nBut
    Kevin would say that the glyph program is running all the time, that the glyph
    program is, in fact, the decoder, that there is no word recognition without letter
    recognition. And he'll cite the studies that back up this position. And you'll
    say that none of those studies involve \u2018real\u2019 reading. And then we'll
    go round again and everyone remember to wave at Mummy and Daddy."
  created: '2009-09-20 22:45:29'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>We are using different perceptual and cognitive functions because
    type, is not one thing.</em>\r\n\r\nOr are we using the same perceptual and cognitive
    functions that happen to be highly adaptive? The latter seems much more likely
    to me."
  created: '2009-09-20 22:49:06'
- author:
    name: enne_son
    picture: 109487
  body: "I'll be cryptic: local combination detection (laurent Cohen and Stanislas
    Dehaene) for role-unit level features (i.e., aspects of the glyph program) is
    running all the time, but so is the <em>global positioning device</em> for these
    features. This allows a single-tiered integrative gathering in which incipient
    recognititions for letters is impeded. Matrix resonance does the rest. \r\n\r\nKevin's
    boundary and moving window studies imply, under a more circumspect interpretation,
    that outside the uncrowded window (Denis Pelli) where crowding destroys letter
    identification at normal typographic spacing, accurate ensemble statistics (Patrick
    Cavanaugh) are being compiled."
  created: '2009-09-21 00:16:21'
- author:
    name: dberlow
  body: ">Kevin would say that the glyph program is running all the tim\r\n\r\nWas
    it running all the time when Gutenberg was composing with more than 250 l.c. glyphs?\r\n\r\nThen
    when did it start?\r\n\r\nCheers!"
  created: '2009-09-22 12:54:04'
- author:
    name: Kevin Larson
    picture: 109739
  body: "> Was it running all the time when Gutenberg was composing with more than
    250 l.c. glyphs?\r\n\r\nYes. Our visual system developed long before Gutenberg.
    Our visual system simplifies the task of recognizing complex objects by recognizing
    simpler parts and building those parts up into a whole. When we look at a human
    face, we don\u2019t look at a whole Gestalt, but look separately at eyes, nose,
    mouth, and other contours, and use those parts to recognize a face.\r\n\r\nIt
    is whole lot easier for the visual system to identify 250 glyphs than a whole
    Gestalt for the 50,000 words that the average college educated adult knows.\r\n"
  created: '2009-09-22 15:20:47'
- author:
    name: William Berkson
    picture: 110306
  body: "Just a word on the reading words vs reading lines--and multiple lines--question.
    It seems to me quite possible that the preview of upcoming letters in the parafovea
    helps first in planning the next saccade, and even sets up a template for further
    interpretation when the eye moves, and the the word comes into the area of the
    fovea. If either of these is operating, then other factors than simply what makes
    a word readable will be operating in reading lines. For sure word spacing is important,
    and maybe extenders enable better pre-identification in the parafovea, speeding
    up interpretation when we look directly at the word. And in reading multiple lines,
    for sure leading is important.  \r\n\r\nMethodologically, the key thing is not
    to assume that one theory is right when conflicting theories are consistent with
    evidence. Good scientific method would involve inventing tests to see which of
    the conflicting theories holds up to observation. "
  created: '2009-09-22 15:42:34'
- author:
    name: enne_son
    picture: 109487
  body: I haven't been able / it hasn't been possible so far to give my intuitions
    about processing -- or the proposals of Edmund Burke Huey, the early pre-goodmanian
    Frank Smith, and the early Neal F. Johnson -- the elaboration that will allow
    them to be perceived as consistent with the bulk of evidence.
  created: '2009-09-22 16:35:17'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>Was it running all the time when Gutenberg was composing with
    more than 250 l.c. glyphs?</em>\r\n\r\nOf course. It's been running ever since
    the first marks associated with language were scratched in clay or daubed on a
    wall. This is what we do: recognise variable forms of letters as letters. Where
    we run into trouble isn't when the glyphs vary -- as the entire history of writing
    and most of the history of typography clearly demonstrates -- but when spacing
    and texture are messed up, i.e. when we have difficulty making the step up from
    letters to words. This is why I am unimpressed when people squawk about sub-pixel
    positioning resulting in different renderings of the same letter; <a href=\"http://www.tiro.com/John/Baskerville-a.jpg\">yeah,
    so what</a>?"
  created: '2009-09-22 19:24:44'
- author:
    name: enne_son
    picture: 109487
  body: Don't different renderings mess feature or role-unit spacing and texture up
    above all?
  created: '2009-09-22 19:42:39'
- author:
    name: John Hudson
    picture: 110397
  body: "Spacing no -- the whole point of sub-pixel positioning is to improve spacing
    --, but texture sometimes, <strong>if</strong> the rendering mechanism can't maintain
    reasonably consistent stroke density. This is the key difference between ClearType's
    colour filtering, which seeks to retain as high a stroke density as possible for
    better shape/ground contrast, and full fuzz rendering which allows thin strokes
    to grey-out. But stroke density is an issue in all antialiasing, regardless of
    subpixel positioning or the consistency of the rendering of glyph: glyphs antialiased
    on full pixel widths may be consistently rendered badly.\r\n\r\nMy point is that
    reproduction of identical letter shapes has never, ever been a requirement of
    reading. If it had been, no pre-typographic writing would have been readable,
    none of our handwriting would be readable, and the vast majority of typography
    itself would be unreadable. The exact reproduction of identical shapes that briefly
    became possible with full-pixel width aliased and antialiased text on screen is,
    in the history of writing and reading, <em>freakish.</em>\r\n\r\nI reckon a certain
    amount of biodiversity in letterforms is probably a very good thing, so long as
    that diversity does not disrupt spatial frequency consistency and spacing. As
    with other kinds of diversity, it makes us adaptable. Imagine a person who has
    reached maturity only ever having read a single typeface and always with each
    letter perfectly consistently reproduced. Would he be able to read anything else?
    Would he have developed the kind of adaptability that allows us to read so widely
    across to many different conditions?"
  created: '2009-09-23 05:32:37'
- author:
    name: dberlow
  body: ">...the whole point of sub-pixel positioning is to improve spacing...\r\n\r\n...relative
    to the print metrics, not the screen metrics. \r\n\r\n>... reproduction of identical
    letter shapes has never, ever been a requirement of reading...\r\n\r\nWe are so
    different, I doubt you will ever get it. Styles of writing developed so strictly
    people were flayed alive once for departing from the exactitude of each letter.
    \r\n\r\n>The exact reproduction of identical shapes that briefly became possible
    with full-pixel width aliased and antialiased text on screen is, in the history
    of writing and reading, freakish.\r\n\r\nAnd is that true of all resolution satisfactory
    print, freakish? You're going to say letters there are not identical. I am going
    to say the intent is identical.\r\n\r\n>When we look at a human face, we don\u2019t
    look at a whole Gestalt,\r\n\r\nNot even our parents?\r\n\r\nCheers!\r\n"
  created: '2009-09-23 12:50:52'
- author:
    name: enne_son
    picture: 109487
  body: "Yes, the visual system abstracts, but to abstract efficiently requires that
    information is properly phase-aligned, the criterial features have properly coordinated
    salience and a weight appropriate to their relative cue-value.\r\n\r\nAlso, reduction
    in resolution (or a reinterpretation on a differently calibrated monitor) removes
    the specifics that contribute to the gestural-atmospheric individuality -- the
    distinctiveness of the personality -- of the font.\r\n\r\nI sympathize with David's
    luminous non-alignment."
  created: '2009-09-23 18:22:33'
- author:
    name: Chris Dean
    picture: 111971
  body: "@ Enneson: \"\u2026the proposals of Edmund Burke Huey, the early pre-goodmanian
    Frank Smith, and the early Neal F. Johnson\u2026\"\r\n\r\nTo which proposals are
    you referring?\r\n\r\nFor the thread, I came across [[http://www.reading.org/Publish.aspx?page=bk598-7-Israel.pdf&mode=retrieve&D=10.1598/0872075986.7&F=bk598-7-Israel.pdf&key=404A4811-A11A-412E-9B70-DBEDB6A7825D|an
    interesting biography on Edmund Burke Huey]]."
  created: '2009-09-23 22:21:56'
- author:
    name: enne_son
    picture: 109487
  body: "Edmund Burke Huey [1908] proposed that \u2018simultaneous co-activation of
    determining letter parts\u2019 sparked recognition. He further hypothesized an
    \u2018inhibition of incipient recognitions for letters\u2019 during normal word
    reading by skilled readers of continuous text.\r\n\r\nFrank Smith [PhD. dissertation
    / 1967] proposed that a word is identified by the distribution of features across
    its entire configuration. This is an ongoing theme in his articles and books.\r\n\r\nNeal
    F. Johnson [mid to late 1970s and 80s on into the 1990s] proposed words are single
    unit patterns; the functional components of word patterns are features rather
    than letters. He echoes Huey's hypothesis of an \u2018inhibition of incipient
    recognitions for letters.\u2019"
  created: '2009-09-24 01:44:09'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>Styles of writing developed so strictly people were flayed alive
    once for departing from the exactitude of each letter.</em>\r\n\r\nSure, precise
    formal styles of writing in some cultures were based on exactitude and the writing
    manuals and exemplars of those cultures are endlessly reproduced in books on calligraphy.
    But that neither implies that all the writing in those cultures was so exact or
    that the exactitude was a <em>requirement</em> of reading. Nor does it imply that
    reading was more difficult in less exact styles of writing, or that cultures that
    were less obsessive were non-literate or even less literate that those with a
    highly exact calligraphic aesthetic. And aesthetic is the key word here: exactitude
    in the reproduction of letters is a stylistic decision, not a functional requirement.\r\n\r\nFurther,
    Ottoman writing of Arabic script was among the most obsessively exact of all scribal
    traditions, yet the styles in which these scribes worked involve extra variant
    forms of almost every letter, such that the same text written in the same style
    by a dozen different scribes will look very different, despite the correctness
    of the form of individual letters within the bounds of that style. Exactitude
    does not imply uniformity and, again, nowhere is uniformity a requirement for
    reading.\r\n\r\n<em>You\u2019re going to say letters there are not identical.
    I am going to say the intent is identical.</em>\r\n\r\nWho cares about intent?
    What we're talking about is what is necessary or not necessary for reading. The
    fact that some people would like to make every instance of a letter identical
    does not mean that this is a requirement for reading."
  created: '2009-09-24 17:09:39'
- author:
    name: John Hudson
    picture: 110397
  body: "Peter: <em>Yes, the visual system abstracts, but to abstract efficiently
    requires that information is properly phase-aligned, the criterial features have
    properly coordinated salience and a weight appropriate to their relative cue-value.</em>\r\n\r\nBut
    this is almost tautological, because the best test we have for whether \u2018information
    is properly phase-aligned, the criterial features have properly coordinated salience
    and a weight appropriate to their relative cue-value\u2019 is whether someone
    can read the result. What we don't have is a functional understanding of what
    \u2018properly\u2019 means in these contexts. We're back to \u2018in order to
    be read, text has to be good enough to be read\u2019."
  created: '2009-09-24 17:18:54'
- author:
    name: enne_son
    picture: 109487
  body: "John, the point is that different renderings disturb phase alignments, relative
    weights and the rhythmic coherence of salient whites.\r\n\r\nI can read the results,
    but I suspect these disturbances have a computational efficiency cost."
  created: '2009-09-24 21:12:58'
- author:
    name: John Hudson
    picture: 110397
  body: "Peter, just to be clear, this is the sort of thing we're talking about:\r\n\r\n[img:sites/default/files/old-images/ctvariation_5339.gif]\r\n\r\nAs
    you can see from the enlargement, the subpixel positioning does result in different
    colour values being used to render vertical stems at different positions on the
    line. But can you really say, looking at the actual size text in the image, that
    phase alignment is disturbed, weight varies or that the rhythm of the salient
    whites is incoherent?\r\n\r\nRather, I'd say that this level of rendering variation
    is much less than encountered in most of the printed typography of the past 550
    years and certainly less than encountered in most smaller manuscript writing.
    If there is a computational efficiency cost, I would be surprised if this is significant
    relative to readerability.\r\n\r\nDavid: <em>...relative to the print metrics,
    not the screen metrics.</em>\r\n\r\nIn practice, yes. Of course, it shouldn't
    need to be that way; subpixel widths <em>could</em> be addressable via hints.
    [Insert usual complaints about the fact that they are not.] But on a low typical
    96dpi screen, subpixel positioning gives you something approaching the spacing
    refinement of a 300dpi printer: far from perfect, but a heck of a lot less crude
    than whole pixel screen metrics. I guess the question is \u2018Where is the dividing
    line between metrics appropriate for print and metrics appropriate for screen?\u2019
    It is, of course, a line that shifts relative to type size, resolution and individual
    typeface, which is why I <em>don't</em> think 300dpi virtual resolution justifies
    a general move toward print metrics on screen without providing a mechanism to
    hint subpixel widths. On the other hand, for a lot of fonts at a lot of sizes
    on a lot of screens it is going to provide better spacing than rounding to full
    pixel widths."
  created: '2009-09-24 23:46:45'
- author:
    name: John Hudson
    picture: 110397
  body: "A comparison that might be helpful, Peter: top, CT rendering on whole pixel
    widths; bottom, CT rendering on subpixel widths.\r\n\r\n[img:sites/default/files/old-images/meiryoCTwp_4359.gif]\r\n[img:sites/default/files/old-images/meiryoCTsp_3455.gif]"
  created: '2009-09-24 23:57:40'
- author:
    name: dberlow
  body: "John, \r\n\r\nIf you want to compare the quality of the last 500 years, and
    not the intent, or compare between quality in aliased vs a-aliased, I'll have
    nothing to do with it. \r\n\r\nOn your excellent illustrations;\r\n\r\nthe difference
    in Gamma is startling. My Mac, uses the additional size-on-em of Verdana, the
    increased resolution to 96, and the rendering of AA text to get to an approximation
    of the print (i.e. resolution independent), image of that font vs. your Window
    Vista (?)'s, which seems much closer to OS/9, XP pre-CT, i.e. aliased of the past
    decades.\r\n[img:sites/default/files/old-images/Spec1_3949.2.445.09.25.09.gif]\r\n\r\n...
    and in the sub-pixel vs. pixel spacing example, I 'held' to be self evident, did
    you make that yourself, or did a computer do it?\r\n\r\n>But can you really say,
    \r\n\r\nWe'll see. \r\n\r\n>... looking at the actual size text in the image,
    \r\n\r\n16-17 px?\r\n\r\n>...that phase alignment is disturbed, \r\n\r\nOnly very
    slightly though in these highly specialized fonts you show at the size you show...\r\n
    (Others: be sure to try and Read the big l.c. glyphs down, not across, to See
    what he means, a little).\r\n\r\n>...weight varies or that the rhythm of the salient
    whites is incoherent?\r\n\r\nDid anyone say incoherent? With all due respect,
    and to credit all aliased-to-antialiased OS leapers, saccade hiccups are not causing
    incoherence. Users are by-and-large using specialized fonts, like the ones you
    show, for everything, except long reads.\r\n\r\nMore sizes, more fonts, show cross-platform,
    and it's not so neat, before the long reads. Not that what you show is neat. The
    heart of the little web letter is, in my opinion, no longer displayable or testable
    via an instance. It's barely even discussable. \r\n\r\nCheers!\r\n"
  created: '2009-09-25 17:39:16'
- author:
    name: John Hudson
    picture: 110397
  body: "David, your description of the difference between the Mac and Vista renderings
    seems to me fair, but I'm not sure what your opinion is, or if you implied one.
    What seems remarkable to me about the Mac rendering is the fuzziness of the horizontals
    and the inconsistency of the stroke density. When I see sequences like the 'eme'
    in elementary, I have to wonder what affect this kind of stroke inconsistency
    has on spatial frequency tuning.\r\n\r\nThe illustrations show Meiryo, not Verdana.
    I specifically chose this because Matthew took the Meiryo Latin off the pixel
    grid of Verdana, making it a good candidate to demonstrate subpixel rendering
    and spacing as applied to a font that was not specifically designed to a whole
    pixel grid but which has many good features of a type for screen. The comparison
    was prepared in a test tool from MS that allows me to simulate different versions
    and settings of the CT renderer. The whole pixel positioning rendering is, I believe,
    the same as the Vista rendering; the subpixel positioning rendering is akin to
    WPF minus y-direction AA.\r\n\r\n<em>Did anyone say incoherent?</em>\r\n\r\nPeter
    suggested that variant renderings, among other things, \u2018disturb ... the rhythmic
    coherence of salient whites\u2019.\r\n\r\n<em>The heart of the little web letter
    is, in my opinion, no longer displayable or testable via an instance. It\u2019s
    barely even discussable.</em>\r\n\r\nI agree. But I wasn't testing or discussing
    \u2018the heart of the little web letter\u2019; I was demonstrating for Peter
    that the level of rendering variation produced by subpixel positioning does not
    -- not necessarily at any rate -- result in the kind of disturbance with which
    he is concerned. I demonstrate this by comparing two settings of the same font
    that differ <em>only</em> in whether they are whole or subpixel positioned, i.e.
    I isolate this difference for comparative purposes.\r\n\r\nWhere comparison with
    other platforms would now be of interest is in determining what features of a
    rendering system are necessary in order to maintain good phase alignments, relative
    weights and rhythmic coherence of salient whites, to adopt Peter's criteria. I'm
    quite sure that subpixel positioning can result in rendering variations that disturb
    all these things <em>in a system that fails in these other features;</em> the
    trick would be to isolate this effect from other problems in the rendering system.
    Take the Mac rendering you show above, for example, I would argue that despite
    the consistency of the rendering of the individual glyphs the inherent inconsistency
    between the letters due to the full fuzz rendering, which results in stroke density
    degradation, is already disturbing all the things about which Peter is concerned,
    and trying to isolate the impact of subpixel positioning on top of such rendering
    would be more difficult than testing on top of a system that sucks less."
  created: '2009-09-25 19:11:58'
- author:
    name: dberlow
  body: ">I specifically chose this because Matthew took the Meiryo Latin off the
    pixel grid of Verdana...applied to a font that was not specifically designed to
    a whole pixel grid...\r\n\r\nI rendered Verdana at 12.6 point on the Mac, and
    it looked size-wise pretty close to whatever you rendered, but I'm flattened by
    my error. Nevertheless,  though it does round easily to 11 ppm, Verdana is not
    designed to any whole pixel grid except 2048, and that's a fact. I'm pretty sure
    going to another version of Verdana will demonstrate nothing, unless one looks
    at a range of sizes to see the problem web designers and users face on this issue.
    A size of a font made for the purpose is not what's about to be unleashed now
    is it?\r\n\r\nI completely agree that building readable web fonts on top of a
    web system that sucks is a problem. If you look at the whole web system problem
    however, and what's ever likely to be solved, making fonts, good phase alignments,
    relative weights and rhythmic coherence of salient whites for web sites on the
    Mac sucks way considerably less than making these things on Windows. You can ask
    anyone, but that's my opinion having done it several times. In fact, the opinion
    popped up that MS should be embarrassed to the gamma.\r\n\r\nI don't agree and
    I tell them why, but again, the unleashing is here and the performance of Verdana/Meiryo
    is not enough to counteract the onrushing epidemic of saccade hiccups \u2014 no
    more than twiddling half pixels randomly as you show is going to make words according
    to St. Adrian. ;)\r\n\r\nCheers!\r\n"
  created: '2009-09-28 14:20:49'
- author:
    name: John Hudson
    picture: 110397
  body: "David: <em>...making fonts, good phase alignments, relative weights and rhythmic
    coherence of salient whites for web sites on the Mac sucks way considerably less
    than making these things on Windows.</em>\r\n\r\nEven considering this?\r\n\r\n[img:sites/default/files/old-images/crossbar_6706.gif]\r\n\r\nWe're
    talking here about a font that was designed and produced specifically for on screen
    reading. And this is what the Mac does to it. Where's the crossbar?\r\n\r\nWhat
    I do see in your comparison is that the <em>spacing</em> of the Mac example is
    very similar to the spacing of the CT with sub-pixel positioning, and that both
    these are superior to the spacing of the CT on whole pixel widths. Look especially
    at left-side bowls following tall verticals as in the <em>le</em> in \u2018schooled\u2019
    and elsewhere. In the CT on whole pixel widths example the spacing of these is
    always too tight and out of rhythm with the other spacing (so much for salient
    whites). In the CT with sub-pixel positioning example, the spacing of these shapes
    is fractionally wider, and is consistent with the rest of the spacing. This is
    also the case in your Mac example, but this is where comparing Verdana with Meiryo
    is misleading, since the spacing of Verdana rounds better to the whole pixel width;
    I'd be intrigued to see Meiryo rendered on the Mac."
  created: '2009-09-28 18:54:37'
- author:
    name: Chris Dean
    picture: 111971
  body: "Mewhort, D. J. K. and Johns, E. E. (1988). Some tests of the interactive-activation
    model for word identification. <em>Psychological Research, 50(3)</em>. 135\u2013147.
    doi:10.1007/BF00310174"
  created: '2009-09-28 19:02:00'
- author:
    name: mike_duggan
    picture: 109519
  body: "john: I\u2019d be intrigued to see Meiryo rendered on the Mac.\r\n\r\nif
    you are running Windows and have Meiryo, you can install, Safari, and get the
    same rendering as if you were on a mac "
  created: '2009-09-28 19:50:25'
- author:
    name: stormbind
    picture: 118121
  body: "[img:sites/default/files/old-images/screen_5601.gif]\r\n\r\nI would like
    to point out that, not so long ago, capital letters were the staple of electronic
    communication. Furthermore, snapshots of the past still appear friendly.\r\n\r\nDrawing
    on this historical evidence, I tentatively suggest that word shape is not responsible
    for the aggressive tone discussed in the opening article - or at the very least,
    not entirely responsible.\r\n\r\nI am not the expert, but do you think its the
    spacing between block of text that makes a difference? For example, the attached
    image shows numerous shades of colour that are fairly evenly distributed on the
    page. In contrast, modern day capital letter 'shouting' is not carefully arranged
    on a screen.\r\n\r\nIn other words, perhaps it is the total screen composition
    that offends some people? :)"
  created: '2009-09-28 23:21:33'
- author:
    name: dberlow
  body: "John quoting David: ...making fonts, good phase alignments, relative weights
    and rhythmic coherence of salient whites for web sites on the Mac sucks way considerably
    less than making these things on Windows.\r\n\r\nJohn> Even considering this?\r\n\r\nYes,
    even considering that e John. I was showing you rendering, not scaling. \r\n\r\nMaybe....
    you should do some work in this area, instead of not thinking with your eyes.
    \r\n\r\nBelow, we selected a font nearly randomly, ( a client chose it ), and
    did the easiest thing possible to prepare it for use as large text, small display
    and large display on the web ( we did no hinting ). We linked to that same font
    in its two too required formats from IE on Vista (left side of page), and Safari
    on the Mac (right), on the same hardware. \r\n\r\n[img:sites/default/files/old-images/4John_4070.gif]\r\n\r\nTake
    a stroll beyond the fonts that don't even matter. Making unique readable identities
    online, with good phase alignments, accurate weights and rhythmic coherence of
    salient whites for web sites on the Mac sucks way considerably less than making
    these things on Windows. \r\n\r\nIf both platforms gave me the option of controlling
    both dimensions with hints, I'd have another opinion for you. But since they don't,
    and phase alignment, accurate weight and rhythmic coherence of salient whites
    is denied in the x dimension on both, then gimme good gamma on both and let it
    be. John, we're talkin' billions of users and thousands of fonts. If the scaling
    wars have ended with the trenches where they'll always be, I give up, you can
    blow the whistle on some detail of scaling some more if you like, but I think
    we are all still sitting in the middle of a font tech war zone, moving on to rendering,
    with no benefit to us, the reader or... the commerce that it now constrains. \r\n\r\nCheers."
  created: '2009-09-30 13:10:27'
- author:
    name: John Hudson
    picture: 110397
  body: "Can I see the real-size version of that comparison, David?\r\n\r\nFonts with
    no hinting... yeah, they look better on Mac than on Windows. But fonts <em>with</em>
    hinting are going to look just the same on the Mac, but have the potential to
    look better on Windows. So what you appear to be saying is that making fonts look
    good on the Mac is easier and cheaper because you don't have to hint them. I guess
    that's one definition of \u2018sucks less\u2019. Sure, if a system ignores all
    hints, shipping fonts without hints is easier and cheaper. The quality issue in
    this case -- as distinct from the ease and cost issue -- is what Windows does
    when it encounters a font without any hints. What it does at the moment sucks.
    What it should do is recognise the absence of hints and apply a Mac-type rendering.
    Karsten and I were giving Greg Hitchcock grief about this recently, and he agreed
    that something like this would be the better approach.\r\n\r\nAs you say, we're
    in the middle of it. Which is why talking is worthwhile."
  created: '2009-09-30 23:34:53'
- author:
    name: dberlow
  body: ">As you say, we\u2019re in the middle of it. Which is why talking is worthwhile.\r\n\r\nI
    was going to say, we are not going in circles, as you suggested. Many many people
    are gathering and a circle is forming around these issues. \r\nUNHINTED ITC FRANKLIN
    BOLD ON WINDOWS\r\n[img:sites/default/files/old-images/Windows_5046.gif]\r\nUNHINTED
    ITC FRANKLIN BOLD ON MAC\r\n[img:sites/default/files/old-images/Mac1_3538.gif]\r\n\r\nFeast
    your eyes.\r\n\r\nCheers!"
  created: '2009-10-01 12:49:42'
- author:
    name: dberlow
  body: "P.S. I should add that I tried very hard to get Ms to move off this spot.
    \r\n\r\n>what Window[s]... should do is recognise the absence of hints and apply
    a Mac-type rendering.\r\n\r\nIt was my hope to move MS out of  thier rabbit hole
    of quality, so they would <em>not</em> have to keep following Apple. This might
    jolt Apple when they see the quality firms like ours produce on Windows. Remember,
    I like Windows rendering, with hints, better than the Mac 'with hints'. I like
    FreeType most of all, regardless of rendering. Make a instctrl setting for CT
    that behaves well with ALL HINTS, that is my five year-old advice.\r\n\r\nCheers!\r\n"
  created: '2009-10-01 13:02:17'
- author:
    name: John Hudson
    picture: 110397
  body: David, is that Windows rendering example ClearType? The colouring doesn't
    look at all typical.
  created: '2009-10-02 03:59:46'
- author:
    name: dberlow
  body: "ClearType. When security improves, I'll give you the url, you can color for
    yourself. \r\n\r\nCheers!"
  created: '2009-10-02 12:54:31'
- author:
    name: John Hudson
    picture: 110397
  body: "So there are two problems with the rendering of the unhinted font on Windows,
    as shown in your comparison.\r\n\r\nOne problem is specific to the absence of
    hints: inconsistent y-direction distances at smaller sizes and drop-out at the
    smallest size; also nicely <a href=\"http://kltf.de/kltf_notes_raster.htm\">documented
    by Karsten</a> and the reason he and I were pestering Greg about this. [I have
    to admit that fonts completely without hints came as a surprise to me: as long
    as some rasterisers continue to observe and apply some hints in some way, I can't
    really imagine shipping a font without any hints at all. That would seem to be
    asking for trouble, but we'll take it as read for now that such fonts exist and
    Windows could do a better job when it encounters them.]\r\n\r\nThe second problem
    is specific to the GDI ClearType rasteriser: absence of any y-direction antialiasing.
    The obvious answer to that is to replace the GID rasteriser with the WPF rasteriser,
    which applied greyscale y-direction AA in combination with x-direction CT, for
    what I genuinely think is the best rendering for larger type I have seen anywhere.
    Unfortunately, Microsoft didn't take the obvious answer, and instead suggest the
    less obvious 'Re-write GDI applications for WPF'.\r\n\r\nDavid, if you are willing
    to send me the unhinted ITC Franklin Bold, I can provide a screen shot of the
    rendering with y-direction AA enabled. I think this would be a useful comparison
    with the images above."
  created: '2009-10-02 19:20:13'
- author:
    name: fatjellypenguin
    picture: 118185
  body: "BECUASE THEY SOUND ANGRYYY!!!\r\n\r\ngives me a headache just looking at
    them on the page\r\n\r\n\r\n...ever wonder if illiterate people get thefull effects
    of alphabet soup???"
  created: '2009-10-07 20:11:03'
- author:
    name: dberlow
  body: ">... I can provide a screen shot of the rendering with y-direction AA enabled.\r\n\r\nThanks,
    but we've already established this does not work in 'the wild'. When y direction
    AA works on a majority of Windows machines, let me know. We have a full deck,
    and we're launching to make room for more. \r\n\r\nCheers!"
  created: '2009-10-08 12:29:23'
date: '2009-09-03 10:58:43'
node_type: forum
title: Why do CAPITAL LETTERS so annoy us?

---
