---
author:
  name: enne_son
  picture: 109487
body: "Hrant wrote: <em>Painting involves making filled marks; drawing is defining\r\nnotan\u2019s
  edge. </em> See http://typophile.com/node/88004?page=2#comment-488377\r\n\r\nI think
  this is too black and white.\r\n\r\nIn \u201Cnotan drawing\u201D filling in with
  a marker defines notan\u2019s edge. See: http://emptyeasel.com/2008/08/12/seeing-notan-how-to-make-stronger-compositions-using-lights-and-darks/
  \ Here notan drawing is a reductive operation that resolves a gradated scene or
  manifold into a light / dark composition.\r\n\r\nIn writing no such reduction is
  required. If the paper is white and the ink is black there is only the binary light
  / dark. In writing, notan\u2019s edge is directly defined by the moving front.\r\n\r\nIn
  punch-cutting notan\u2019s edge is defined by the subtractive process of cutting
  away.\r\n\r\nNotan\u2019s edge can be sharpened or recalibrated in digital technologies,
  but notan doesn\u2019t have an edge until an area has been filled in or part of
  it cut away. Until an area is filled in the only thing that can be controlled is
  the trueness and action of the curve or line.\r\n\r\nAccording to Kevin Larson,
  ganglion cells (that project from the rods and cones in the human eye to neural
  dendrites and axons in the visual cortex) look for edges. As far as I can find,
  they are also sensitive to surface polarity.\r\n\r\nDoes writing with a hand-held
  tool misinform?\r\n\r\nOur internal representations of bounded maps of letters are
  role-unit based and feature-tolerant. That is, they are highly tolerant of variability
  in contrast styling and somewhat tolerant of role-architectural drift. These tolerances
  are enhanced by the cortical dynamics of font-tuning.\r\n\r\nWhat we don\u2019t
  know for sure, is if writing with the hand-held tool <em>optimally calibrates stress.
  </em>\r\n\r\nHere is a non-ideological but hypothetical context for assessing this.\r\n\r\nMy
  sense is that the sub-attentive parafoveal pre-processing that occurs in immersive
  reading responds to coarse-grained notanic composition, not fine-grained notanic
  equilibrium. It responds to this in deciding what words to skip and where to land
  when it makes it\u2019s next saccade. It responds to salient areas of disturbed
  or undisturbed expressedness, or divergent aspect, or projection beyond the x-height
  range.\r\n\r\nAnd my sense is that effortless, effective and automatic fovea-based
  processing relies on fine-grained rhythmic co-ordination of the blacks and whites.
  Fine-grained rhythmic co-ordination of the blacks and whites according to their
  relative saliencies and their allocation of weight in the cue-value domain optimizes
  the efficiency of cortical integrational routines within the visual cortex.\r\n\r\nThis
  imposes countervailing pressures on the sharpening and calibration or recalibration
  of notan\u2019s edge. \r\n\r\nPeter Enneson\r\n"
comments:
- author:
    name: dezcom
    picture: 109959
  body: "Just as the mechanics of the human eye react to such things as size, distance,
    color, difference ratio, and proximity to neighbors, I would think that the whole
    system reacts to and accommodates for whatever basis the form follows--if it be
    tool based or otherwise.   The human brain is an amazing tool.  It can \"read\"
    very well far, far, beyond optimum and trains itself to adapt to whatever it finds.
    \ The magic is in the ability to adapt.  All life forms have survived by their
    ability to adapt.  Humans are the most adaptable creatures except for viruses.
    \ I feel as though the search for the holy grail of \"optimal\" is not going to
    make reading much more possible or faster to comprehend than several of the typefaces
    already out there.\r\n\r\nA few years ago, I designed a very strict 90 degree
    only bauhaus typeface.  At first, I thought it would be impossible to read.  I
    was amazed how quickly I adapted to the limited forms complete with picket fence
    effect and very minor differentiation.  The mind is a beautiful thing.  If that
    same mind is given free reign to design a typeface, I am sure that some very readable
    ones will come out.  The problem with awaiting the optimal research is that there
    is the danger of staying away from innovation for fear of missing the optimal.
    \ Type designers are type designers and research scientists are research scientists.
    \ We each have our role.  Waiting for one or the other to get there is of no use.
    \ Scientists measure what is available to measure. If we stop trying things and
    stay with historic conventions, we limit what scientists will have to measure.
    \ If a form is tool based or not is not the issue as much is making many different
    forms to see if there is a logic not yet discovered.\r\n\r\nI would say, just
    keep working in whatever way your own mind leads you.  At some point,scientists
    may be more capable of making sense of it but giving them more options to test
    gives them more tools to work with.\r\n\r\nJust do it."
  created: '2011-12-24 19:20:10'
- author:
    name: hrant
    picture: 110403
  body: "> just keep working in whatever way your own mind leads you.\r\n\r\nThat's
    not Design, that's Art.\r\n\r\nPeter: Something eventually.\r\n\r\nhhp\r\n"
  created: '2011-12-24 19:27:32'
- author:
    name: dezcom
    picture: 109959
  body: That is not true in the least, Hrant. Some minds will design better than others
    but that has no bearing on Art.  It just has a bearing on the probabilities in
    the distribution of skills and abilities among those who attempt the task.  Total
    failure is equally possible as total success. Ad nauseum blandness has the greatest
    chance of happening but the mediocre is soon forgotten and the complete failure
    is a great teacher for others.  The point is that there is no chance for progress
    without enough attempts.  Let there be failures and boring nothingness to be forgotten.  Out
    of all of the collective effort, there will be also some degree of success.
  created: '2011-12-24 19:41:59'
- author:
    name: William Berkson
    picture: 110306
  body: ">What we don\u2019t know for sure, is if writing with the hand-held tool
    optimally calibrates stress. \r\n\r\nI think when you say \"hand-held tool\" that
    is too wide. There are a lot of different tools. For example the pointed Chinese
    brush works a lot differently from the pen. But interestingly they do the similar
    sorts of thing with thick and thin, even color, and so on. The thing is, the mind
    is guiding the tool, and trying to make it work for the eye. \r\n\r\nIf the question
    is whether the broad-pen drawn Carolingian miniscule optimally calibrates stress,
    I would say that evidence of history is that it handles stress very well for the
    eye, but not ideally. The Jenson, Griffo, Garamond line of type makers systematically
    changed the stress of the letters, and I think made them more readable. And publishers
    and readers certainly followed. For example, the top left to bottom right diagonals
    are lighter than they would be pen drawn. There's a lot of other subtle modulation
    that's different also, but the diagonal thing will do for a start. \r\n"
  created: '2011-12-25 03:00:03'
- author:
    name: John Hudson
    picture: 110397
  body: "<em>What we don\u2019t know for sure, is if writing with the hand-held tool
    optimally calibrates stress.</em>\r\n\r\nOr if there is an optimally calibrated
    stress. We should consider the very real possibility that our reading ability
    is evolutionarily grounded in perceptual skills that by their nature are non-specialised
    and do not require particular input; indeed, they need to be able to handle a
    great variety of input with little performance variation. Presuming, reasonably
    I think, that reading is a free rider on shape recognition abilities that evolved
    in the context of negotiating the natural world, why should we think that it requires
    optimisation of particular kinds of shapes, when what we're confronted with in
    nature is phenomenal diversity."
  created: '2011-12-25 08:52:41'
- author:
    name: enne_son
    picture: 109487
  body: "[editorial comment: cross-posted with Bill's comment just above.]\r\n\r\nJohn,
    the term feature-tolerant accounts for the performance variation part of what
    you have to say. I adapted the term from a 2011 paper by Andreas M. Rauschecker,
    Reno F. Bowen, Lee M. Perry, Alison M. Kevan, Robert F. Dougherty, and Brian A.
    Wandell called \u201CVisual Feature-Tolerance in the Reading Network\u201D [Neuron
    71, 941\u2013953 / available online]. Another term that\u2019s used is invariant
    recognition.\r\n\r\nOne of the areas of current debate is to what extent reading
    is a free-rider on recognition abilities \u201Cevolved in the context of negotiating
    the natural world.\u201D The debate centers around the question of specialization
    for words in the ventral occipital-temporal circuitry, sometimes referred to as
    the Visual Word Form Area (VWFA). Laurent Cohen and Stanislas Dehaene (author
    of Reading in the Brian) are prominent names on one side: Cathy Price and Joseph
    Devlin on the other.\r\n\r\nI tried to place the <em>defining notan\u2019s edge</em>
    question into a more inclusive framework that the one Hrant uses, but this probably
    needs to be further developed to become clear.\r\n\r\nThe <em>stress-factor</em>
    probably has more to do with \u2018perceptual psychophysical costs\u2019, the
    term that came up around the discussion of the Luckiesh / Tinker divide.\r\n\r\nOptimal
    is probably the wrong word to use when talking about contrast styling. I think
    there is no visual-circuitry related reason why the allocation of stress in western
    scripts typical of at least the best broad-pen variants of writing exacts undue
    perceptual psychophysical costs. I think this is where the debate about type of
    stress can most profitably touch done.\r\n\r\nIn my mind, I\u2019ve begun to relate
    the notan part of these discussions to Luckiesh and Moss\u2019s blink rate results
    in assessing relative boldness, a result that Dwiggins embraced. Is there a better
    notanic balance or distribution in the somewhat bolder range than the typical
    regular weight? Does this have to do with the better visability of both the black
    and white? and how does this relate to perceptual psychophysical costs? Perceptual
    pschophysical costs have to do, as far as I can see, with the efficiency of corticl
    integrational processing routines inside the visual cortex.\r\n\r\n"
  created: '2011-12-25 14:40:22'
- author:
    name: William Berkson
    picture: 110306
  body: ">why should we think that it requires optimisation of particular kinds of
    shapes, when what we're confronted with in nature is phenomenal diversity.\r\n\r\nWe
    know we can compromise speed and comfort of decoding letters by too tight or irregular
    spacing, for example. There is no question we can still decode with too tight
    spacing. The question is, how fast we can do it, and at what psycho-physical cost.
    The slow down in reading speed is well documented with markedly sub-optimal type.
    So is fatigue or discomfort in reading, if Luckiesh's work with blink rate is
    sound. So I think there is reason to believe, as Dwiggins and Frutiger have said
    in the past, there there is some kind of ideal. And if Luckiesh is right, it does
    involve weight. He didn't test modulation of stroke, which Dwiggins thought an
    important question, or evenness of color, which I would like to see tested. \r\n\r\nI
    would concede that it's not a matter of shape as such, as different scripts have
    greatly different shapes. But I do think such issues as spacing, evenness of color,
    and even modulation of stroke may make a difference. I think there is no doubt
    that even an \"ideal\" for text type (lengthy passages at 8-12 point printed)
    will have a range, not a pinpoint, and allow for expressive and aesthetic variation.
    But I do think there is reason to suspect that such an ideal range exists. The
    recent article by Legge and Bigelow put a fluent reading range from 4-40 points,
    but I think a lot more can be done to narrow that in a number of ways. "
  created: '2011-12-25 14:57:56'
- author:
    name: dezcom
    picture: 109959
  body: "\"We should consider the very real possibility that our reading ability is
    evolutionarily grounded in perceptual skills that by their nature are non-specialised
    and do not require particular input;\"\r\n\r\nBRAVO, John!!!"
  created: '2011-12-25 19:29:51'
- author:
    name: William Berkson
    picture: 110306
  body: "As far as relative boldness, Peter, my hypothesis is that what is working
    here is the interplay of two things: the figure/ground distinction, and visibility.
    To \"read\" the figure it need to be clearly differentiated from the ground. So
    the ground need to have clearly more of its color than the figure. This would
    argue that lighter strokes would be better. Bolder strokes are, however, more
    visible. Yet they may crowd out \"ground\", so that the figure/ground relationships
    is upset. So somewhere between very bold and very light is best. Frutiger thought
    it was, in the x-height area, having the black strokes about 30% of the white
    space. \r\n\r\nAs far as modulation, one thing I can think of is that keeping
    the joins of relatively even color with the strokes requires thinning of one or
    the other of the strokes, or both. If I got it right, Chinese also follows this
    rule, as well as Hebrew. I don't know about other scripts. Broad pen does some
    of this automatically, which is an advantage. So that would explain why modulation
    is better.   "
  created: '2011-12-25 22:46:20'
- author:
    name: dezcom
    picture: 109959
  body: "\" So the ground need to have clearly more of its color than the figure.
    This would argue that lighter strokes would be better\"\r\n\r\nWhy?  I know it
    is your \"theory\" but what prompts you to hypothesize this?"
  created: '2011-12-26 01:55:37'
- author:
    name: hrant
    picture: 110403
  body: "William, don't forget leading!\r\n\r\nhhp\r\n"
  created: '2011-12-26 02:02:11'
- author:
    name: William Berkson
    picture: 110306
  body: "Chris, to me what makes it easy recognize as the \"ground\" is that there
    is more of it, and it's an even color. So when the ground is less than 50% locally,
    there is more possibility of the eye taking it for figure. That's why I think
    that it's reasonable that less than very bold weights are less taxing to read
    in extended text. But how much isn't clear, at least to me. The countervailing
    force is the need for visibility. According to Luckiesh bolder is more visible.\r\n\r\nHrant,
    you are right to note leading. That's one of the indications that there's a range
    as far as weight, not one ideal. There's a very interesting comparison in Mitchell
    & Wightman's Book Typography. There they show that a light type, Spectrum, works
    well with less leading, but a dark type, Quadraat, works better with more leading.
    So the interlinear space does affect what the eye takes as \"normal\" or comfortable
    text weight. Of course, extenders are another factor affecting what works best
    as far as leading. So when designing a text type, what leading it can take well
    or not take is a consideration, and as both the darkness and the extenders will
    affect it...     "
  created: '2011-12-26 04:45:34'
- author:
    name: "T\xE9 Rowan"
    picture: 121227
  body: When you have less 'ground' than 'figure', you have entered the Realms of
    Blackletter, incidentally independent of the Realms of Blackadder.
  created: '2011-12-26 14:49:26'
- author:
    name: enne_son
    picture: 109487
  body: "I am still stuck on the idea that the entire word is figure. Both the black
    and the white shapes inside the word, that is both the stroke-units and the counters,
    are information for vision in a real and active way. Both contribute actively
    to visual word-form resolution.\r\n\r\nDesigning letters so that the entire word
    can pop out as if it were an internally cohesive figure against a ground is to
    me part of the challenge facing type designers. Designing the whites recognizes
    that both the stroke-units and the counters, are information for vision in a real
    and active way.\r\n\r\nI think there is a hierarchy of figure / ground relationships
    in text, one centered on the stroke, another on the letter, a third on the word,
    another on the line, a fifth centered on the column, a fourth centered on the
    page. All require attention. The word-related one I think is central.\r\n\r\n"
  created: '2011-12-26 15:46:51'
- author:
    name: hrant
    picture: 110403
  body: "It makes a lot of sense that parts of letters take part in reading.\r\nBut
    since they can only exist in relation to the white, even parts\r\nof letters suffer
    from chirographic constraints.\r\n\r\nhhp\r\n"
  created: '2011-12-26 16:06:01'
- author:
    name: William Berkson
    picture: 110306
  body: "Peter, I think that the figure and the ground operate differently as far
    a psychological processing. One of the most basic perceptual functions is recognizing
    a \"object.\" That involved identifying edges, as you say, but also putting these
    together to form an object, or in this case letter, that is distinctive from its
    background. The distinction between figure and ground is thus critical for recognition.
    \r\n\r\nI don't have a clear theory of how white is handled, but I am pretty sure
    it must be different. My feeling is that handling the whites well for text is
    mainly a matter of getting the black to be detected easily. There evenness of
    color and consistency of form are important. I have the feeling that only in the
    case of issues as whether a form is closed or open does white play a direct role
    in character recognition. "
  created: '2011-12-26 17:28:13'
- author:
    name: dezcom
    picture: 109959
  body: The whites [negatives] play a very strong role in defining the blacks [positive].  I
    don't see the value in pulling them apart.
  created: '2011-12-26 17:38:31'
- author:
    name: William Berkson
    picture: 110306
  body: "Chris, I think they may function differently in reading, so that to understand
    brain processing in reading, the distinction my be important. For example, it
    may be that a slight variation in width of the black stems, or positive, has a
    bigger impact on recognition or ease of reading than a slight variation in negative,
    such as space between letters. \r\n\r\nWhat exactly an understanding of the differences
    will tell us I don't know, but I'm pretty sure it would turn up something of interest
    to designers. \r\n\r\nFor example, what makes the white seem more vivid in some
    counters of bold letters? Is it figure/ground ambiguity, or something else? And
    what does that tell us about when this is a good or bad thing?"
  created: '2011-12-26 18:18:02'
- author:
    name: enne_son
    picture: 109487
  body: "Bill, to my mind reading involves edge detection as well as detection of
    surface polarity, in this case black and white. As well, to my mind, neither the
    visual cortex nor any other part of the brain <em>puts these edged shapes together</em>
    to form an object. They are already together. To my way of seeing it, all the
    visual system has to do is resolve, by eye-fixations inside a word, what stroke-units
    are connected to what other stroke units and counter units (local combination
    detection), and how the stroke-units in their combinations are distributed across
    the figure or word-object as a whole.\r\n\r\nThe problem as I see it is not just
    to get the black and / or white to be detected easily, but to have the entire
    word be seen and processed as one cohesive, weight, contrast and spatial frequency
    co-ordinated thing. Unless they are meaningful markers, eveness of colour and
    inconsistency of formal logic created a signal / versus noise confound for the
    visual cortex, which it has to neutralize. They present roadblocks to efficient
    processing in the visual cortex."
  created: '2011-12-26 18:44:33'
- author:
    name: hrant
    picture: 110403
  body: "I think much of what you say (or at least the way you're saying it)\r\nis
    in the realm of consciousness, so outside of immersive reading.\r\nFor example,
    there's no time/need to do edge detection. All that is\r\ndetected during immersive
    reading is black and white shapes (which\r\nare in fact inescapably one thing).
    Also, uneven color is nothing\r\nmore than contrast, which is the meat-and-potatoes
    of information.\r\nThere's only too much of it if it causes errant fixations.\r\n\r\nhhp\r\n"
  created: '2011-12-26 18:53:58'
- author:
    name: William Berkson
    picture: 110306
  body: "Peter, I didn't mean to imply that letter recognition has to precede word
    recognition. I agree with you that aspects of different letters being identified,
    and response to the whole pattern of these across the word, may well be what is
    going on. But even in identifying the aspects, I suspect that the black has priority.
    For example, the brain is looking for joins, or branches in the black. I thing
    there is putting together the glyph or word in the way that an object is put together.
    \r\n\r\nThere may be differences from object recognition because you are dealing
    with decoding to reach meaning, as in listening to language, but still I see a
    priority on the structure of the blacks. For example, I don't think that the shape
    of whites between has the same *salience* or impact as the shape of blacks in
    glyphs. And I think this could be shown, as I suggested to Chris, by a greater
    sensitivity to blacks than whites, except for identifying open and closed structures.
    \r\n\r\nFor example, if you show me a word in a new typeface, then hide it, I
    and other type designers might be able to reproduce the distinctive features of
    the letters fairly quickly and well. But if you ask us to reproduce the shapes
    of whites between the letters, without drawing the glyphs, I think the result
    would be much slower, and worse.  \r\n"
  created: '2011-12-26 18:54:12'
- author:
    name: enne_son
    picture: 109487
  body: "Bill, probably at least three things are going on simultaneously, quantization
    into role-units from edge and surface polarity information which draws on both
    the black and white; local combination detection which relies on alertness to
    joins and branching behaviours in the blacks, and global distribution detection,
    which has to do with the design's spatial frequency modulated use of cartesian
    space in both the black and white.\r\n\r\n"
  created: '2011-12-26 19:15:57'
- author:
    name: hrant
    picture: 110403
  body: "1) A reader noticing something means little, and can in fact be misleading.\r\n2)
    Whites simply have more open forms; that doesn't mean they're less\r\nimportant,
    it just means there's a different skew (but no qualitative\r\ndifference). Legato
    BTW is a great example of the whites being linked\r\nin the way you ascribe to
    the blacks.\r\n3) Maybe this is happening because fonts are poorly designed, ignoring
    notan?\r\n4) Since the black and white cannot exist independently, this is an
    illusion.\r\n\r\nhhp\r\n"
  created: '2011-12-26 20:26:55'
- author:
    name: William Berkson
    picture: 110306
  body: 'Peter, you''re not addressing my point about the salience of the blacks.
    I think that if you track one line out by 10% compared to those above and below,
    the readers might well not notice it. If you increased all the stem widths by
    10%, I think readers would notice it. If I am right, how would you explain that
    without ascribing a different role to whites and blacks, and greater salience
    of blacks? '
  created: '2011-12-26 21:08:12'
- author:
    name: hrant
    picture: 110403
  body: "Concerning readers noticing things:\r\nhttp://www.flickr.com/photos/petervanlancker/5919651040\r\nhttp://www.flickr.com/photos/petervanlancker/5959452821\r\nhttp://www.flickr.com/photos/petervanlancker/5988105567\r\n\r\nhhp\r\n"
  created: '2011-12-26 21:17:18'
- author:
    name: enne_son
    picture: 109487
  body: "Bill, along the same lines as the skew issue mentioned by Hrant, I would
    think the blacks and whites occupy different bandwidths within the same basic
    frequency channel. A 10 percent change to material attended to in a lower spatial
    frequency band would have a smaller optical effect compared to a 10 percent change
    to material attended to in a higher spatial frequenct band.\r\n\r\nI would ascribe
    salience to features, such as <em>expressedness</em> which can be circular or
    n shaped, disturbed as in the e and s, or undesturbed as in the o and the dpqb
    group. Other examples of features are <em>extension</em> beyond the x-height range;
    or <em>aspect</em>, which is oblique in the x; or </em>closure</em> and the lack
    of it. Things like expressedness and lack of closure are co-defined by the black
    and the white."
  created: '2011-12-26 22:55:59'
- author:
    name: enne_son
    picture: 109487
  body: "Bill <em>I don't have a clear theory of how white is handled, but I am pretty
    sure it must be different.</em>\r\n\r\nWorking further on the idea that the entire
    word is figure, and that both the black and the white shapes inside the word are
    information for vision in a real and active way, here a something about the white
    that occurs to me:\r\n\r\nNot all the white are quantizable into fully realized
    role units. Closed counters seem to be (o, bpqd); those in the m and n and u as
    well. But some open counters like in the lower part of the a and the s are perhaps
    only quantizable into what might be called demi role-units. Between-letter whites
    aren't quantizable into role units at all. Probably they are used as word-integral
    reference points for compiling distributional statistics.\r\n\r\nIt seems to be
    that case that information of different orders and polarities existing in at least
    two spatial frequency bands is compiled in a single feed-forward cascade."
  created: '2011-12-27 02:06:43'
- author:
    name: William Berkson
    picture: 110306
  body: 'Peter, I agree with you that some whites, such as those in opbdq, might well
    be "read" while spaces between letters are not. The spaces would sets the scale
    of the "grid" that the brain lays over the word, and keep the blacks in the rhythm
    (periodicity) expected by the eye. Still my point would stand, following what
    you theorize, that blacks are likely treated by the brain differently than background
    whites.   '
  created: '2011-12-27 03:02:12'
- author:
    name: hrant
    picture: 110403
  body: "Why would the eye expect any such thing?\r\n\r\nAnd why would <em>any</em>
    information be ignored?\r\nThe mind is like Chinese cuisine - even the chicken's
    feet are used.\r\n\r\nhhp\r\n"
  created: '2011-12-27 03:34:43'
- author:
    name: William Berkson
    picture: 110306
  body: ">Why would the eye expect any such thing?\r\nThe eye would expect periodicity
    (partial) because it is a feature of our of good text fonts, as confirmed by Fourier
    analysis of text blocks. (And even built into our scripts.) And the periodicity
    helps the brain where to look for salient letter features that will help identify
    the word. \r\n\r\n>And why would any information be ignored?\r\nThe brain has
    to pick out of the visual field the salient information. I don't think \"ignore\"
    is exactly the right word, but \"winnowing,\"\u2014which is essential to isolate
    and decode text in the visual field. What I'm saying is that the winnowing of
    much of the white space is different from the black. The spacing around the letters
    and lines helps us set the grid, but the shapes of the white around words and
    between lines is not, I suspect, generally registered as *shapes.*  "
  created: '2011-12-27 03:56:49'
- author:
    name: enne_son
    picture: 109487
  body: "Bill, I think we disagree. I think everything is \u2018read\u2019 in the
    sense that everything is information for vision in a real and active way. Not
    everything is \u2018read\u2019 in the sense of being quantized into role units
    though. The black is only special in the sense that it has a different polarity
    than the white, works within it's own spatial frequency band and allows for exhaustive
    quantization at the role-unit level. From the point of view of the visual cortex,
    the whites between letters aren't background, though they flow into the ground
    against which the word is figure."
  created: '2011-12-27 04:12:50'
- author:
    name: hrant
    picture: 110403
  body: "I think those Fourier images show people what they want to see...\r\n\"Our
    good text fonts\"? How do you know they're good? Is \"good\"\r\ngood enough, for
    a type designer? And Bill, why is this periodicity\r\nabsent in Williams Caslon?\r\n\r\nThis
    \"rhythm\" business simply doesn't make any sense.\r\nIt's a romantic construct
    of our self-important consciousness.\r\n\r\n> the winnowing of much of the white
    space is different from the black.\r\n\r\nYou might not be under-estimating the
    relevance of the white,\r\nbut you might very well be <em>over</em>-estimating
    that of the black!\r\n\r\nhhp"
  created: '2011-12-27 05:27:21'
- author:
    name: hrant
    picture: 110403
  body: "All this talk of white versus black makes no sense when you\r\ntake into
    account that there's nothing in between, so the two\r\nare in fact one thing:
    notan. I can't imagine how one could\r\nfocus on one aspect or another of the
    black or the white and\r\ndesign with that in mind without adversely affecting
    the other.\r\nAnd that's why we should look at the border and not the bodies.\r\n\r\n>
    those fonts widely recognized as good\r\n\r\nNow <em>that</em> sounds like the
    high priests who confronted Galileo...\r\nAnd here's an opportune Galileo quote:
    \"In questions of science, the\r\nauthority of a thousand is not worth the humble
    reasoning of a single\r\nindividual.\" My whole point is that we don't really
    know what's good.\r\nAnd I feel safe in saying that this stuff isn't.\r\n\r\n>
    The Fourier images are a mathematically objective indication of periodicity.\r\n\r\nWell
    all that says is that those fonts are [somewhat] periodic!\r\nIf you could couple
    that to data -good data, not the sort of thing\r\nwe've seen so far- showing that
    the more periodic a font the greater\r\nits readability then you have a case.\r\n\r\nThe
    problem with data is that the more sophisticated it is,\r\nthe harder it is to
    interpret, and the more room is left for\r\nsubjective interpretation...\r\n\r\n>
    We need both the underlying meter, and the departure\r\n> from it, like meter
    vs rhythm in a song.\r\n\r\nThis is post-rationalization.\r\n\r\nA song that deviated
    from a rhythm at almost every note is not something\r\nmost people want to listen
    to! That's because music appreciation is a\r\nconscious activity. But a text font
    is like the sounds of the jungle. If there's\r\nany rhythm, it's like chaos theory,
    and beyond our conscious appreciation.\r\nWhich means we can't design for that,
    and we must forgo rhythm.\r\n\r\nSo to me it's not that we need some illusion
    to depart from, it's that we\r\nneed to find a new destination. The big mountain
    range that rises much\r\nhigher than our plateau, with the big body of water in
    between...\r\n\r\nhhp\r\n"
  created: '2011-12-27 15:23:49'
- author:
    name: William Berkson
    picture: 110306
  body: "Peter, I think in conceding that whites between letters are not \"quantized
    on a role unit level,\" you are conceding that whites and blacks are not treated
    the same, which is my point. [For those not familiar with Peter's terminology:
    role unit = salient sub-letter feature, such as a branch, an open counter, etc.]\r\n\r\nThe
    greater salience of the blacks compared to whites between letters and above and
    below the line is my point. The eye and brain processing starts with a bunch of
    visual information, and has to winnow it down to identify the code, and decode
    it. So it starts with both black and white, but the mechanism is after features
    of the black. That's why we don't consciously notice or remember the shape between
    the c and a in ca, but we do remember the c and a.\r\n\r\nHrant, by good text
    font, I simply meant those fonts widely recognized as good, and widely used in
    extended text, such as Garamond, Times New Roman, etc. \r\n\r\nHere, thanks to
    Peter, is a strip of a Fourier image done on a text block of Minion:\r\n  [img:sites/default/files/old-images/minion_fourier_3767.gif]\r\n\r\nObjectively,
    there is a lot of regular periodicity, indicated by the evenly spaced white bands\u2014indicating
    a concentration of black stems, as I remember. But there is also a significant
    amount of departure from strictly regular periodicity. Here there is room for
    interpretation. My interpretation is that letters define enough regularity to
    give the eye a grid to read off of, but that the letters depart from it this way
    and that, which is what we \"read\". We need both the underlying meter, and the
    departure from it, like meter vs rhythm in a song. \r\n\r\nYou can have an alternative
    theory of why Fourier transforms of text look the way they do. But if you want
    to deny significant regular periodicity, I think you have gone into the land of
    loony denial. \r\n\r\nAs to the m in Williams Caslon Text, yes I did make the
    counters slightly narrower than the n and thinned the middle vertical slightly,
    as is a common trick. I think it saves a little space and differentiates the m
    a little better. But I didn't make it much narrower than two superimposed n's,
    which is also common in many fonts. That's because I felt the departure from regularity
    hit the right balance of being close to the underlying meter (which is around
    half the width of the n), while departing slightly from it. It's probably what
    Caslon did also, but right now I don't remember. \r\n"
  created: '2011-12-27 15:24:59'
- author:
    name: William Berkson
    picture: 110306
  body: ">A song that deviated from a rhythm at almost every note is not something\r\nmost
    people want to listen to!\r\n\r\nHrant, you seem to not understand the way rhythm
    works in music, which is maybe the source of your objection to the metaphor in
    type. There are two different things going in music. One is the underlying beat,
    which is normally extremely even, in a single meter\u2014the same number of beats
    to each measure. Played against the underlying beat is the rhythm of the melodic
    line, which can vary a lot from the beat. In syncopated music, which is common
    for dance music, the rhythm of the melodic line constantly plays with going on
    and off the beat. And normally in dance music you have a steady beat of the drum,
    and so you can clearly hear both the rhythm of the melodic line and the beat,
    playing against one another.  \r\n\r\nWhat I am suggesting is that the fairly
    regular bars of the verticals are analogous to the beat in music, and the departures
    from it like the rhythm that plays against the underlying beat. \r\n "
  created: '2011-12-27 15:47:27'
- author:
    name: enne_son
    picture: 109487
  body: "Bill, going back a few steps in this thread, I make a distinction between
    features and role units. At TypeCon / Atlanta I said:\r\nthe visual system\r\n(1)
    breaks stimulus words down into oriented lines and curves, to the point where\r\n(2)
    responsiveness to aspect, closure and expressedness accumulates and\r\n(3) resolution
    or \u2018quantization\u2019 into role-units occurs.\r\n\r\n#1 needs refinement
    in relation to what I said in my opening post about ganglion cells looking for
    edges and registering surface polarity.\r\n\r\n#2 relates to features and is the
    focus of feature analytic processing. This is what Frank Smith based his ideas
    about perceptual processing in reading on. Quantization into role-units is one
    of the things that happens in feature analytic processing. Closure is a feature,
    bowls and counters are role-units. So instead of saying the mechanism is after
    features of the black, I would say the mechanism uses features of the black /
    white composite to isolate role-units, many of which are black, some of which
    are white. It doesn't only isolate role units, it reads the black and white relationally
    in parallel*.\r\n\r\n*I'm working on the idea that this is the essence of what
    Hrant means when he says we read notan. We read the black and white relationally
    in parallel. Optimizing relational processing with a focus on the black and white
    composition is it seems to me one of the key things Hrant is after.\r\n\r\nApparently
    the neurophysics of the visual cortex has an on-center / off surround structure.
    Without going into all the details \u2014 some of which I haven't been able to
    assimilate fully \u2014 I think it can be said that optimal relational processing
    across the word using both blacks and whites occurs when the on-center / off-surround
    routines in the two polarity domains intermesh.\r\n\r\nI think the intermesh issue
    underlines the relevance of Hrant's quest. It is one of the things the visual
    cortex needs for efficient processing of words."
  created: '2011-12-27 15:51:05'
- author:
    name: hrant
    picture: 110403
  body: "> the mechanism is after features of the black.\r\n\r\n1) The mechanism is
    after anything it can possibly use.\r\n2) Any feature of the black is also a feature
    of the white,\r\nalthough often on another (maybe superior :-) level.\r\n\r\n>
    That's why we don't consciously notice or remember the shape\r\n> between the
    c and a in ca, but we do remember the c and a.\r\n\r\n1) Consciousness is not
    relevant during immersion.\r\n2) We don't remember the <em>shapes</em> of \"c\"
    and \"a\", we\r\nsimply remember the lexical units.\r\n3) We remember something
    about the \"c\" and \"a\" because\r\nthat's what our consciousness was taught
    in school. And\r\nmaybe if we were taught to respect the white as children\r\nwe'd
    be over this parachirographic hump already!  :-)\r\n\r\n> Played against the underlying
    beat is the rhythm of\r\n> the melodic line, which can vary a lot from the beat.\r\n\r\nYes
    but they're both grids. I hope you're not saying we\r\nneed more grids in type!
    The first step is to take to heart\r\nthat immersive reading is not conscious
    (while music is).\r\nJungle sounds don't have beats or rhythms or anything\r\nartificial
    like that.\r\n\r\nTo me drawing a parallel between music and reading\r\nis much
    like drawing on a blackboard with a burin!\r\n\r\nhhp\r\n"
  created: '2011-12-27 15:57:04'
- author:
    name: hrant
    picture: 110403
  body: "Peter, re-reading you original post:\r\n\r\nWhen I try to define the terms
    \"painting\" and \"drawing\" it's not\r\nan ideological move - it's just to promote
    clear communication.\r\nAlso, any concept is necessarily absolute; however any
    <em>application</em>\r\nof any concept is never absolute.\r\n\r\n> In writing
    no such reduction is required.\r\n\r\nWhat I would say is that in writing (what
    I call \"painting\", to\r\nremove any ambiguity, since \"writing\" might imply
    the formation of\r\nthe skeletons - so in a way, ductus) no such <em>objective</em>
    is <em>achievable</em>.\r\n\r\n> notan doesn\u2019t have an edge until an area\r\n>
    has been filled in or part of it cut away.\r\n\r\nNo, notan is defined as soon
    as the edge is marked.\r\nIt however does not exist until the black/white is marked.\r\nType
    designers do the former. If they do (or even factor in)\r\nthe latter first (painting)
    they cannot achieve the former.\r\n\r\n> Our internal representations of bounded
    maps of letters are role-unit\r\n> based and feature-tolerant. That is, they are
    highly tolerant\r\n\r\nThe human body is highly tolerant of grapefruit. And it
    tastes great.\r\nBut if you have too much you may lose a member or get breast
    cancer.\r\nhttp://news.bbc.co.uk/2/hi/health/7978418.stm\r\nhttp://news.bbc.co.uk/2/hi/health/6900482.stm\r\n\r\n>
    [The parafovea helps decide] what words to skip and\r\n> where to land when it
    makes it\u2019s next saccade.\r\n\r\nYou know I've said this before, but it was
    a while back, so:\r\nInformation is information. If information in the parafovea\r\nis
    used to decide what word a bouma is (and that's clearly\r\nhappening because at
    the top end only 1/3 of text is foveated)\r\nthen that's reading.\r\n\r\nOh, and
    again, the only thing that's effortless is dying.\r\n\r\nhhp\r\n"
  created: '2011-12-27 16:40:40'
- author:
    name: "T\xE9 Rowan"
    picture: 121227
  body: "Oi, Hrant! You left an unfinished sentence up there...\r\n\r\n> <cite>My
    whole point is that we don't really know what's good.</cite>\r\n\r\n... but we
    always <em>know</em> what isn't."
  created: '2011-12-27 18:57:59'
- author:
    name: John Hudson
    picture: 110397
  body: "I'm with Bill on figure bias, which I think is part and parcel of recognising
    <em>things</em> as distinct from the space around or through them. The fact that
    text typically involves a radically simplified figure/ground relationship, of
    a kind that we seldom encounter in nature except when a bird is silhouetted against
    a bright sky, doesn't suggest to me a variant mechanism: we still bias the figure,
    the thing to be recognised, over the ground, the background against which the
    thing stands. This is also one of the reasons why I remain suspicious of notions
    of word recognition distinct from letter recognition, because I think 'word' is
    a conceptually fuzzier concept than letter, such that most people asked to describe
    a letter will describe its figure form, i.e. conceptualise a letter as a thing;
    whereas, in this discussion, a word is put forward as a gestalt of figure and
    ground, but also as a collection of letter things in a particular periodic relationship.\r\n\r\n[Thanks,
    by the way, Bill, for introducing the notion of periodicity, which provides the
    opportunity to talk about regularised and flexible spatial relationships without
    using the more contentious term 'rhythm'.]"
  created: '2011-12-27 19:30:48'
- author:
    name: enne_son
    picture: 109487
  body: "[hrant] <em>not on ideological move</em>\r\n\r\nI made my \u201Ca non-ideological
    but hypothetical context\u201D comment in the context of addressing the issue
    of whether or not writing with a hand-held tool informs or misinforms. In the
    ductus thread you wrote: \u201CI'd also substitute \"misinform\" for \"inform\"
    \u2014 that is an ideological issue.\r\n\r\nAbout your other comments: defining
    notan\u2019s edge and defining notan are different but related things. The two
    go hand in hand. I\u2019ll stick for now with what I said about defining notan\u2019s
    edge. If optimal notan is posed as an objective is to be achieved we have to have
    a handle on what it is in the domain of reading writing. I tried to do this with
    my intermeshing on-center / off-surround comments above.\r\n\r\nThe only way to
    gauge this intermeshing \u2018on the ground\u2019 in design is, as far as I can
    see, by optically assessing phase alignment in the blacks and optically assessing
    the rhythmic cohesion of the whites, as well as optically assessing if one pole
    drowns out the other, that is if rhythmic cohesion in the whites has come at the
    expense of phase alignment in the blacks and vice versa. Optimizing notan \u2018on
    the ground\u2019 is a highly iterative process involving working at notan\u2019s
    edge.\r\n\r\nAn other way to gauge how well the black versus white on-center /
    off-surround routines intermesh is, I suspect by using fast fourier transforms,
    though I\u2019m not sure just yet exactly how.\r\n\r\nYour commented on my feature-tolerant
    comment seems designed to suggest it\u2019s not worth mentioning.\r\n\r\nThe point
    of my mentioning this was not to encourage satisfaction with what we\u2019ve achieved
    but to contextualize over-reaching statements about dark ages and inverse relationships
    between making progress and encouraging awareness of ductal arithmetic. A criterion
    level of readability is fairly easy to achieve. Pelli\u2019s work suggests there
    is a wide plateau. Legge and Bigelow show there is an ample fluent range. The
    importance of Luckiesh and Moss is that they were able to push beyond this. Their
    work shows there are peaks and valleys on the plateau. \r\n\r\nSo we are not in
    the dark ages but there is more to do.\r\n\r\n\r\nAbout your \u201C1/3 of text
    is foveated\u201D comment. Here I think you are counting letters, not words. If
    I remember correctly you  use a low-end estimate about how many letters can sit
    in the fovea at one time at a decent viewing range, and a high-end estimate of
    how many letter spaces a typical saccade jumps over. A more useful concept for
    schematizing how much info can be picked up during a single fixation might be
    the Pelli idea of the uncrowded span. \r\n\r\nI\u2019m still searching for a good
    term to describe what kind of gathering occurs in  parafoveal preview. The closest
    I can find to something I think works is the notion of \u201Caccurate ensemble
    statistics,\u201D [Patrick Cavanagh] or \u201Csummary statistics\u201D [Benjamin
    Balas], though neither feel quite right.\r\n"
  created: '2011-12-27 19:49:25'
- author:
    name: hrant
    picture: 110403
  body: "John:\r\n1) Some things have holes in them; and the holes are part of them.\r\n2)
    The subconscious brain, being driven by efficiency, tries to eat\r\nup text in
    the largest chunks possible.\r\nHence boumas (which can actually even span word
    spaces).\r\n\r\nhhp\r\n"
  created: '2011-12-27 21:23:37'
- author:
    name: enne_son
    picture: 109487
  body: "John, isn\u2019t the thing to be recognized in reading <em>the word</em>,
    and the ground against which the word stands out during a fixation <em>the line</em>?
    My idea is that in reading, the response bias is indeed to the figure, which is
    the word. As a figure, the word has a composite structure. The letter has this
    too*. But in the word the composite structure is compounded. I think this is a
    more productive approach when thinking through the processing mechanisms occurring
    in the visual cortex.\r\n\r\n*Noordzij begins <em>The Stroke</em> by saying that
    a letter is two shapes, one light, one dark. Because the white is a shape it becomes
    figural. Noordzij uses this to talk about the history of writing, and in his hands
    it becomes more than a design conceit. To treat some instance of \u201Cword-blindness\u201D
    Noordzij ran across in in school, he provided exercises that prompted the visual
    cortex to imprint on the white shapes.\r\n\r\nNoordzij contends that educators
    focus on the black. My extension of this is that cognitive and perceptual scientists
    make this mistake too.\r\n\r\nIn this context Hrant is more Noordzijian than you.\r\n"
  created: '2011-12-27 21:44:54'
- author:
    name: dezcom
    picture: 109959
  body: It is like saying, when talking about water, which is the more important,
    the hydrogen or the oxygen.  Someone then might respond, the hydrogen of course
    because it has 2 parts to one of oxygen.  The truth is, it is the relationship
    of the bond that counts not the quantity.  That is why there can be both thin
    and thick type but the ratio for each is dependent on the desired output.
  created: '2011-12-27 21:51:47'
- author:
    name: hrant
    picture: 110403
  body: "> About your \u201C1/3 of text is foveated\u201D comment. Here I think ....\r\n\r\nPeter,
    we've done this all before...\r\nBut maybe this time you'll manage to make me
    see the flaw in my logic.\r\n\r\nI'm counting linear length, via number of letters
    (a conversion that\r\nI doubt introduces an unreasonable skew). I define the fovea
    as the\r\ncentral 3-4 letter area where individual letters can be identified\r\nafter
    many seconds of conscious evaluation, with anything beyond the\r\nfovea dropping
    quickly in acuity and being useless for <em>small things\r\nlike letters</em>*;
    if anything this is generous. As for the length of saccades,\r\nthey can easily
    go over 10, sometimes to around 15. So I have to think\r\n1/3 is conservative,
    and in fact anything less than 1/1 means the parafovea\r\nis reading boumas. And
    really, if it's good enough to determine the next\r\npoint of fixation, why would
    it be shy about how it got that determination?\r\n\r\n* But still OK for clusters
    of letters; and the more\r\ndistinctive and frequent a cluster the deeper into\r\nthe
    parafovea it can be recognized. I mean really,\r\nis that elegant or what?\r\n\r\nNot
    that Pelli's research is pointless, but I honestly don't\r\nneed to grasp it simply
    to draw the basic conclusion above.\r\n\r\nhhp\r\n"
  created: '2011-12-27 21:56:08'
- author:
    name: enne_son
    picture: 109487
  body: "[Hrant] <em>[M]aybe this time you'll manage to make me see the flaw in my
    logic.</em>\r\n\r\nLater, and probably in another thread."
  created: '2011-12-27 22:09:46'
- author:
    name: Peter Van Lancker
  body: "How about white letters on a black background, or white letters on a complicated
    and colored background like in movie subtitles?\r\nHow about hinting as the ultimate
    way of bringing rhythm into text, and kerning doing the opposite? And why does
    one often compare rhythm in typography to extremely simplistic pop or even dance
    music (I would associate this rather with \"mtv typography\"; whereas in contemporary
    classical music, rhythm often takes a different role)."
  created: '2011-12-28 10:48:03'
- author:
    name: enne_son
    picture: 109487
  body: "The flaws in Hrant\u2019s <em>parafoveal reading of boumas</em> logic.\r\n\r\nEstimates
    of acuity and saccade distance vary. The wikipedia on eye movement in language
    reading says that around the fixation point only 4 to 5 letters are seen with
    100 percent acuity. The drop-off is quite rapid. The distance the eye moves in
    each saccade is between 1 and 20 characters with the average being 7 to 9 characters.
    A new saccade places 2 to 3 of the 7 to 9 characters crossed in a saccade into
    foveal vision during the new fixation. This means that all in all, on average,
    4 to 5 of 7 to 9 characters have become available to foveal vision after a single
    saccade. 1 and 20 character saccades are highly unusual I would think.\r\n\r\nSo
    I think it\u2019s wrong to suggest that only 1/3 of text is foveated.\r\n\r\nThe
    conclusion Hrant appears to want to draw from this calculation is that the parafovea
    is or can be reading boumas at a rate of 2 out of every 3 words. The conclusion
    that should be made, is that with short words 2 out of every 3 words are available
    to parafoveal vision with each fixation, but since the resolution capabilities
    of parafoveal vision don\u2019t allow genuine visual word-form resolution, at
    least one of those two must be brought into foveal vision in a subsequent fixation.
    Typically only short, frequent connective tissue words, like <em>the</em> and
    <em>in</em> and <em>on</em> are skipped.\r\n\r\nPelli has characterized what paravoveal
    vsion delivers as jumbled percepts. What the coarse-coding capabilities do allow
    seems to be what I might want to call jumble statistics. Jumble statistics would
    than account for what is commonly referred to as the parafoveal preview benefit.
    Jumble statistics, which probably can capture where salient features like areas
    of disturbed or undisturbed expressedness lie, for instance, can undoubtedly affect
    \u201Csaccade planning.\u201D\r\n"
  created: '2011-12-28 13:51:54'
- author:
    name: hrant
    picture: 110403
  body: "> How about white letters on a black background\r\n\r\nThat would indeed
    make for an interesting test.\r\n\r\n> Later, and probably in another thread.\r\n\r\nIt's
    gonna have to be, since that didn't work at all...  :-)\r\n\r\nA text face designer
    interested in marking a non-trivial increase in\r\nreading performance isn't concerned
    with how people <em>usually</em> read;\r\nhe's concerned with how they <em>might</em>
    read under the right conditions.\r\nSo the fact that most saccades are short means
    virtually nothing;\r\nthe significant thing is that they <em>can</em> be very
    long without adversely\r\naffecting comprehension. The only way to explain this
    that I can think\r\nof is that boumas <em>can</em> be picked up in the parafovea,
    and probably at\r\na rate greater than in the fovea. And when you say \"the resolution\r\ncapabilities
    of parafoveal vision don't allow genuine visual word-\r\nform resolution\", I
    would say:\r\n- You don't know that.\r\n- How do you explain the existence of
    very long saccades?\r\n- How do you explain regressions?\r\nConcerning the last:
    to me regressions happen when the guesswork\r\n(something the brain is great at)
    based on the blurry parafovea is\r\nsimply wrong; the fovea doesn't make mistakes
    like that. And the\r\nmore experience the \"firmware\" acquires the better a balance
    it can\r\nstrike between speed and regressions; a total absence of regressions\r\nis
    actually a bad thing - it means it's not trying hard enough.\r\n\r\nAs for foveal
    acuity, I guess the number range I'm working with is fine.\r\n\r\nAs for Pelli,
    all I can say is that it seems he's been measuring low-\r\nperformance reading
    (like Larson, and pretty much everybody else).\r\nI define that as reading by
    people who are not motivated to read fast\r\nor whose \"firmware\" does not yet
    have the experience to leverage the\r\nparafovea; it is known for example that
    people's reading improves\r\nwell into middle age and beyond. And the little bouma-hunting
    fairies\r\nknow better than to come out for casual reading tasks.\r\n\r\nLastly,
    if you don't think the parafovea is active in actual reading\r\nof boumas, your
    case for boumas is... poof! As Larson has convinced\r\nme at least, the fovea
    does not need more than individual letters.\r\n\r\nhhp\r\n"
  created: '2011-12-28 15:54:12'
- author:
    name: hrant
    picture: 110403
  body: "> boumas <em>can</em> be picked up in the parafovea and\r\n> probably at
    a rate greater than in the fovea.\r\n\r\nSo the question becomes: how do we make
    boumas more distinctive?\r\n\r\nMaybe by mapping a language and diverging the
    boumas of\r\nword pairs* that are close; for example in the \"quest\"/\"guest\"\r\npair,
    one (probably the former) could be given an \"st\" ligature.\r\nBut of course
    this has to be done consistently**, and we might\r\neven develop common standards.\r\n\r\n*
    Or actually, groups.\r\n\r\n** Although if familiarity is picked up\r\nquickly
    enough the consistency could\r\nbe limited to one font in a long book.\r\n\r\nhhp\r\n"
  created: '2011-12-28 16:02:12'
- author:
    name: enne_son
    picture: 109487
  body: "Hrant, your diverging boumas idea is perhaps worth pursuing. Diverging boumas,
    if you will, is one of the forces driving script evolution. The other pole is
    optimizing phase alignment and rhythmic cohesion to get consolidation of the word
    image. The latter reaches a high point in terxtura, but at the cost of divergent
    boumas. I believe this dynamic is described somewhere in Noordzij's writing.\r\n\r\nEarlier
    you said: \u201CIf information in the parafovea is used to decide what word a
    bouma is (and that's clearly happening because at the top end only 1/3 of text
    is foveated)\r\nthen that's reading.\u201D \r\n\r\nI took this to be your description
    of how we <em>actually</em> read. I tried to show that your facts are skewed and
    your conclusions misleading, because they fail to take into account well-documented
    and widely accepted constraints on parafoveal vision.\r\n\r\nNow you say: \u201CA
    text face designer interested in marking a non-trivial increase in reading performance
    isn't concerned with how people <em>usually</em> read; he's concerned with how
    they <em>might</em> read under the right conditions.\u201D I think your ideas
    about how people <em>might</em> read don't recognize hard-wired perceptual psychophysical
    constraints, or that upper limit saccades are, if I'm not mistaken typically followed
    by regressions, that is, they've gone too far. The thread of sense has become
    interrupted.\r\n\r\nNevertheless, I do think, as hinted at above that the parafoveal
    preview benefit can be enhanced by strategic moves in some of the directions you
    describe.\r\n\r\nI think that the time required for robust sense-following and
    accurate meaning construction are the real constraints on speed, not improperly
    leveraging the parafovea. The actual foveal uptake of information takes much less
    time than 1/4 of a second."
  created: '2011-12-28 19:37:31'
- author:
    name: "T\xE9 Rowan"
    picture: 121227
  body: "> <cite>So the question becomes: how do we make boumas more distinctive?</cite>\r\n\r\nYa
    folken ever wondered why the 'g' is so often double-storied while the 'q' never
    is? As long as the letters can be told apart cheaply, especially in parafoveal
    vision, the boumas can and will be resolved cheaply."
  created: '2011-12-28 19:57:13'
- author:
    name: John Hudson
    picture: 110397
  body: "Chris: <em>It is like saying, when talking about water, which is the more
    important, the hydrogen or the oxygen.</em>\r\n\r\nNot really, because if you
    give someone a black pen and a black piece of paper and ask them to write something,
    they'll still write the same letter shapes that they would if writing on white
    paper. We know what the figure shapes of letters are independent of our perception
    of the ground, and hence I find it reasonable to consider that we bias those figure
    shapes just as we bias the figure shapes of deer against a backdrop of trees.
    Indeed, given the great variety of weight and proportion in letters that we recognise
    as the same figure forms, necessarily independent of the shapes and sizes of the
    internal and intervening ground, it seems to me that the <em>structure</em> of
    the figure form is not only biased but the essential component, more than the
    area or edge of either black or white. We can't claim that a super heavy and a
    hairline letter 'a' are recognised on any basis but their shared figural structure,
    since the black is otherwise so dissimilar and the white even more so."
  created: '2011-12-28 22:15:44'
- author:
    name: John Hudson
    picture: 110397
  body: "Hrant: <em>The subconscious brain, being driven by efficiency, tries to eat\r\nup
    text in the largest chunks possible.</em>\r\n\r\nI don't think that is proven,
    and it isn't necessarily a good intuition either. Efficiency does not always reside
    in eating up the largest chunk possible, as you'll discover if you try to eat
    a piece of cake that way while your older sister nibbles at hers and finishes
    first (thereby winning the coveted last slice on the plate). The key notion for
    efficiency seems to me whatever constitutes 'bite size' in reading, i.e. what
    is the optimal size of the perceptual unit for speed, accuracy and endurance (comfort
    over time)? Two things that seem obvious to me are that a) letters have a built-in
    advantage over sub-letter and super-letter elements as perceptual units in that
    they are self-contained visually and often linguistically (more so in many languages
    than in English), and b) the optimal perceptual unit varies as we read, most obviously
    relative to word length and familiarity. So I have no difficulty accepting that
    some of the time the optimal perceptual unit is something larger than a single
    letter, especially in the case of short and common words, whether that is conceived
    as a bouma or a particular role architecture or a particular gridded arrangement.
    But I don't think it is likely, let alone proven, that the brain is always trying
    to consume the biggest chunks of text possible. On the contrary, the process of
    becoming a good reader must involve the brain learning from experience how much
    of a text to bite off; which is why experienced readers make fewer regressions
    than inexperienced ones and do better in accuracy tests than so-called speed readers,
    who bite off more than they can chew."
  created: '2011-12-28 22:31:12'
- author:
    name: enne_son
    picture: 109487
  body: "[John] <em>letters have a built-in advantage over sub-letter and super-letter
    elements as perceptual units in that they are self-contained visually and often
    linguistically (more so in many languages than in English), and b) the optimal
    perceptual unit varies as we read, most obviously relative to word length and
    familiarity.\r\n\r\nJohn, think in perceptual processing terms. To facilitate
    this I suggest it is important to distinguish between units of perception and
    units of processing, tokenizable parts of composite structures, and featural primitives.\r\n\r\nWords
    have a built-in advantage over letters as perceptual units in that they are space-delimited
    and internally cohesive bounded maps of blacks and whites. To get to letters a
    preliminary segmentation (tokenization) must occur within this unit that designer
    try their darndest to make internally cohesive, that is, to make into a single
    unit, a perceptual unit.* Letters are the tokenizable parts of composite structures
    and the composite structures have gestalt integrity. \r\n\r\nEvery perceptual
    scientist I know begins with feature detection or feature analytic processing.
    To me features (in the alphabetic domain) are things like expressedness and closure.
    In my scheme the units of processing in glyph-like structures are role-units.
    Most psychologist collapse the two (features and role-units). \r\n\r\nIf, at the
    role-unit level, blacks are in phase and whites rhythmically coordinated, the
    segmentation is psycho-physically discourged or inhibited. This is why I think
    a single-tiered cross-letter gathering of role-units (protoypical <em>structures</em>
    \u2014 white and black \u2014 not literal <em>shapes</em>) with attention to their
    local combination characteristics and global distribution across word-integral
    between-letter reference points is the best way to address the recognitional problem.\r\n\r\n*
    Should designers stop trying to do this? Don't designers try to acheive gestalt
    cohesion by making letters <em>less</em> self-contained and more open to eachother?"
  created: '2011-12-28 23:46:23'
- author:
    name: hrant
    picture: 110403
  body: "> Diverging boumas, if you will, is one of the forces driving script evolution.\r\n\r\nI
    wish. As far as I've seen (and it does make sense) divergence is only\r\nimplemented
    at the level of individual symbols, and that only in extreme\r\ncases (like \"1\"
    vs \"7\" where the latter is given a middle bar). This is not\r\nsurprising because
    layman consciousness cannot grasp immersive reading;\r\nit only grasps legibility,
    and that only in an informal, reactionary way.\r\n\r\n> well-documented and widely
    accepted constraints on parafoveal vision.\r\n\r\nAs a rule simpler data is more
    reliable. I think these \"constraints\"\r\nmight be the result of poor testing.
    How do you explain the simpler,\r\nmore reliable data showing that saccades can
    far exceed letterwise\r\ndecipherment resolution?\r\n\r\n> upper limit saccades
    are, if I'm not\r\n> mistaken typically followed by regressions\r\n\r\nI've never
    seen that.\r\nIf you show me that <em>all</em> saccades that exceed the\r\nfovea's
    span (4-5 letters) result in a regression\r\n(or faulty comprehension) then I'm
    with you.\r\n\r\n> the parafoveal preview benefit can be enhanced\r\n\r\nIf it
    can be enhanced to the point of picking out boumas, that\r\nmeans the capability
    is there... Why this parafoveaphobia?  :-)\r\n\r\n> The actual foveal uptake of
    information\r\n> takes much less time than 1/4 of a second.\r\n\r\nI'd say that
    reinforces my view!\r\nI posit that the remainder of the effort is going into
    reading the parafovea.\r\n\r\n> if you give someone a black pen and a black piece
    of paper\r\n> and ask them to write something, they'll still write the same\r\n>
    letter shapes that they would if writing on white paper.\r\n\r\nYou can't be serious.\r\nTry
    writing with your eyes closed.\r\n\r\n> We can't claim that a super heavy and
    a hairline letter 'a' are\r\n> recognised on any basis but their shared figural
    structure, since\r\n> the black is otherwise so dissimilar and the white even
    more so.\r\n\r\nBut they're <em>not</em> dissimilar, in the ways that count.\r\n\r\n>
    The key notion for efficiency seems to me\r\n> whatever constitutes 'bite size'
    in reading\r\n\r\nActually, I agree.\r\nBut it doesn't make sense for that to
    be letters, because clusters\r\nof them occur in high frequencies* and furthermore
    are easier\r\nto pick out in the blurry parafovea.\r\n\r\n* And for example \"th\"
    is much more frequent than \"z\".\r\n\r\nWhat I'd ask you to consider is this:
    if short and common words are\r\npicked up as wholes, why not increasingly long
    and decreasingly\r\ncommon as a reader's experience increases? Language after
    all is\r\nincredibly redundant - English is around 50%. So the more you\r\nread
    the more you can be sufficiently sure that blurry cluster in\r\nthe parafovea
    is what you think it is and take the leap, literally.\r\n\r\n> experienced readers
    make fewer regressions than inexperienced ones\r\n\r\nThis is only true when the
    reader isn't being challenged, either\r\nin terms of time pressure or difficulty
    of the material. My feeling\r\nis that the proportion of regressions is maintained
    at the top end;\r\nit's the length of saccades that increases with experience.\r\n\r\n>
    Don't designers try to acheive gestalt cohesion by making\r\n> letters less self-contained
    and more open to each other?\r\n\r\nNot enough. And painting the letters necessarily\r\nimpedes
    that, even if one believes in the White.\r\n\r\nhhp\r\n"
  created: '2011-12-29 00:16:17'
- author:
    name: enne_son
    picture: 109487
  body: Hrant, I guess I just don't buy your pattern of interpreting, questioning
    and assimilating data. I suspect the feeling is mutual. You don't find my conclusions
    compelling, and I don't find your arguments well founded. Yet I am interested
    in some of the things you are working at.
  created: '2011-12-29 00:44:33'
- author:
    name: hrant
    picture: 110403
  body: "I'm certainly not nearly as versed in the science as you are, and\r\nyou
    know I'm a believer in science. But it has to make sense, and\r\nthe core questions
    (like how saccades can far exceed the acuity\r\nof the fovea) have to be answered
    before we go much deeper.\r\n\r\nI guess there are many levels of \"answers\",
    and we each try\r\nto grasp the level that can best serve our near-term future.\r\n\r\nhhp\r\n"
  created: '2011-12-29 00:48:43'
- author:
    name: enne_son
    picture: 109487
  body: "[Hrant] <em>I'm a believer in science</em>. \r\n\r\nI think that, to make
    bold statements about grasping immersive reading you need also to immerse yourself
    in the science. My view goes against the conventional understanding of reading,
    \ but developed and is developing in constant conversation with a wealth of literature
    from various subdomains and in the context of conflicting perspectives within
    the literature. My apriori going in were and are shaped by paying close attention
    to the obsessions and attunements of masters of the craft of type-design and typography,
    as well as to initiatives like yours and Bloemsma's.\r\n\r\nAs I said in Thessaloniki
    years ago, it's an ever-expanding sea to drink and a conflicting maze of wandering
    paths, but it can be wonderfully productive."
  created: '2011-12-29 01:17:58'
- author:
    name: enne_son
    picture: 109487
  body: "Hrant, is your idea that saccades are made when the reading system <em>already
    has</em> an idea about or knows what the n+1 or n+2 word is (where n is the fixated
    word)? The purpose of a fixation is then 1) to verify or falsify, and 2) to bring
    more words into parafoveal view?\r\n\r\nI can understand the appeal of this, but
    I doubt it\u2019s how immersive reading actually works. \r\n\r\nThis also helps
    me understand your line of questioning, the logic behind your snippet retorts,
    and that you might think all my foveal \u201Crapid automatic visual word-form
    resolution\u201D stuff is grossly inflated and largely beside the point, <em>and</em>
    that the parallel letter recognition view is right in the domain of foveal vision.\r\n\r\nMy
    understanding is that saccades are made when a foveally-based visual word-form
    resolution event has occurred, and because we <em>don\u2019t</em> know from parafoveal
    preview what the n+1 or n+2 word is. The reason why some words are skipped and
    why the next saccade will go to the n+2 word instead is because of the anticipatory
    structure of sense-following which seems to be oriented to bringing substance
    words into view.\r\n\r\nA basic principle for me is that, though the <em>unit
    of perception</em> is typically the word, rapid automatic visual word-form resolution
    requires robust perceptual discrimination affordance at least to the level of
    role-units  / letter parts / features. I take this to be confirmed beyond the
    shadow of a reasonable doubt by Pelli\u2019s work. Luckiesh expresses this by
    laying emphasis on the visibility or clear seeing of the critical details as a
    first reqirement for ease of reading."
  created: '2011-12-29 12:08:43'
- author:
    name: enne_son
    picture: 109487
  body: "Earlier I wrote: \u201Cupper limit saccades are, if I'm not mistaken typically
    followed by regressions.\u201D\r\n\r\nHrant contested this. \r\n\r\nIn his comprehensive
    1998 review article \u201CEye Movements in Reading and Information Processing:
    20 Years of Research\u201D <a href=\"http://people.usd.edu/~schieber/docs/Rayner1998.pdf\">[available
    here]</a> Keith Rayner writes: \u201C[\u2026] saccades vary from 1 to over 15
    letter spaces. [\u2026] Saccades as long as 15 letter spaces are quite rare and
    often occur immediately following a regression in which readers typically make
    a long saccade to place the eyes ahead of where they were prior to making the
    regression.\u201D\r\n\r\n\r\n"
  created: '2011-12-29 17:55:32'
- author:
    name: enne_son
    picture: 109487
  body: Yes, I was correcting my error.
  created: '2011-12-29 18:09:58'
- author:
    name: hrant
    picture: 110403
  body: "Peter:\r\n1) You said long saccades are typically <em>followed</em> by regressions.\r\n2)
    Things like \"rare\", \"often\" etc. leave room for what I'm saying.\r\n3) What
    about between 5 and 15?\r\n\r\nFrom where I stand I see no proof that the parafovea\r\ncannot
    read boumas, and some evidence that it can.\r\n\r\nMore soon.\r\n\r\nhhp\r\n"
  created: '2011-12-29 18:13:05'
- author:
    name: hrant
    picture: 110403
  body: "To be fair though: if very long saccades only serve to skip\r\nover previously
    read boumas, then that negates my claim.\r\nHowever, to me anything more than
    ~10 has implications\r\nin terms of the parafovea's role.\r\n\r\nhhp\r\n"
  created: '2011-12-29 18:16:03'
- author:
    name: hrant
    picture: 110403
  body: "Layman's version:\r\nhttp://themicrofoundry.com/ss_read1.html\r\n(I don't
    know why that segment is suddenly going wrong font...)\r\n\r\nBasically I think
    the fovea and parafovea are each used for what\r\nthey're good at: the former
    for its acuity, the latter for its range.\r\n\r\nSo we fixate on something, and
    simultaneously read what are in effect\r\nsingle-letter (but see below) boumas
    in the fovea and multi-letter\r\nboumas in the parafovea (in the direction of
    reading only). The depth\r\nto which we can read in the parafovea depends on how
    high-frequency\r\nand distinctive the given boumas are. The location of the next
    fixation\r\nis simply where our confidence (which gets built up over time with\r\nexperience,
    and also depends on the difficulty of the material) has\r\nrun out. So we fixate
    on something because we have no choice in terms\r\nof picking out all the boumas
    with sufficient confidence; and we\r\nregress when the next fixation reveals a
    problem with the boumas the\r\nparafovea gave us in the previous fixation - but
    that's OK because it\r\nmeans we're making good speed overall.\r\n\r\nI have yet
    to hear a better explanation that addressed the fact that\r\nsaccades far exceed
    the letterwise acuity of the fovea. If Pelli for\r\nexample implies that long
    saccades cannot be functional, his data\r\nmust be flawed because they exist!
    The subconscious brain is much\r\nmore clever than any researcher. The data cannot
    lead the way, only\r\nour logic can do that.\r\n\r\nI previously wrote:\r\n> As
    Larson has convinced me at least, the fovea\r\n> does not need more than individual
    letters.\r\n\r\nActually I do see room to move on that: if the brain\r\ncan pick
    out multi-letter boumas in the fovea, I guess\r\nthere's no reason it shouldn't,
    since that saves time.\r\nI just don't know if the processing overhead (I mean\r\nonce
    the boumas are known) makes that moot or not.\r\n\r\nIn the parafovea we have
    no choice because individual\r\nletters cannot be identified with enough confidence.\r\n\r\nhhp\r\n"
  created: '2011-12-29 19:09:52'
- author:
    name: John Hudson
    picture: 110397
  body: "Peter: <em>To get to letters a preliminary segmentation (tokenization) must
    occur within this unit that designer try their darndest to make internally cohesive,
    that is, to make into a single unit, a perceptual unit.</em>\r\n\r\nI don't think
    this is what designers are doing, although I understand that many of them may
    <em>think</em> that is what they are doing. I think what designers are actually
    doing is making the necessarily different (distinctly recognisable) letters visually
    similar in a variety of ways, such that no letter strays into a different spatial
    frequency channel or otherwise disrupts the reader. Part of this does involve
    what I call knitting of words -- making internally cohesive, as you say --: creating
    a flexible but reasonably consistent internal periodicity in the arrangement of
    features, which establishes the integrity of the word as a textual linguistic
    unit, but I don't think it follows that this implies making a word into a single
    perceptual unit. Obviously we perceive words as visual units, thanks to inter-word
    spacing and internal integrity (even in the parafovea and importantly for navigation),
    but it doesn't follow that we treat words as perceptual units for recognition
    purposes: it may well be that segmentation of the internally cohesive word is
    normal and necessary. Certainly that seems to be the case for all but the shortest
    and commonest words. I'm quite happy to accept that segmentation may occur at
    levels above, below and through the letter level, but once one gets within the
    word unit, as one must, letters seem to be to have a bias in being linguistically
    assignable things."
  created: '2011-12-29 19:29:04'
- author:
    name: Nick Shinn
    picture: 110193
  body: "The brain is quite capable of suggesting what its perceptors search for and
    acquire in low-data areas of vision, after all, such a process works seamlessly
    to fill in the blind spot. Call it cloning, after Photoshop.\r\n\r\nThe brain
    decodes a streaming cascade of jumbled percepts (Peter\u2019s term), continually
    directing the fovea towards emergent meaning as, upon closer inspection, shapeless
    forms become coherent words."
  created: '2011-12-29 19:31:09'
- author:
    name: John Hudson
    picture: 110397
  body: "Hrant: <em>You can't be serious. Try writing with your eyes closed.</em>\r\n\r\nOkay,
    I did. Actually, the admittedly short specimen looked somewhat better than my
    usual writing. The problem with writing with one's eyes closed isn't the shaping
    of the letters or their spacing -- muscle memory is good at this --, its the growing
    sense of disorientation regarding the page as a whole, which limits one to short
    sequences. I suppose if one practised, one might be able to do longer, and presumably
    many people who have gone blind in later life have managed to write."
  created: '2011-12-29 19:35:19'
- author:
    name: hrant
    picture: 110403
  body: "> The problem with writing with one's eyes closed\r\n> isn't the shaping
    of the letters or their spacing\r\n\r\nI think stand-alone letters can be formed
    decently\r\nwithout looking, but visual feedback is immediately\r\nhelpful when
    you put down the second letter... which\r\nis when the white really kicks in!\r\n\r\nhhp\r\n"
  created: '2011-12-29 19:46:42'
- author:
    name: enne_son
    picture: 109487
  body: "John, the word <em>segmentation</em> might be misleading. Here it means taking
    discrete groups of 2 or 3 features (units of processing) and processing them in
    separate channels. I compare this to running a three- to five-legged race, where
    you have to team up with a neighbour that has identical shoelaces to yours. It\u2019s
    awkward and involves a two-stage process, the first being feature (= leg) binding
    after you\u2019ve figure out who your race partners are. \r\n\r\nThere are other
    problems as well, associated with the explicit labeling of letters. Because at
    this level phonetic equivalents come on line, there is a phonetic disambiguation
    overhead problem, which requires a significant array of feed-back loops to solve.
    David Boulton in his series of interviews for his Children of the Code website
    brings this up repeatedly. Huey in 1906 thought there had to be an <em>inhibition
    of incipient recognitions for letters</em> for the reading system to work efficiently.\r\n\r\nThese
    things aren't decisive for selecting between your and my alternatives. Both I
    think are strong hypotheses. You'll probably grant that. There will have to be
    a way to decide between the two."
  created: '2011-12-29 20:36:38'
- author:
    name: enne_son
    picture: 109487
  body: "[Hrant]\r\n\r\nhttp://themicrofoundry.com/ss_read1.html\r\n\r\n1) I think
    the wikipedia graphic is more accurate. See:\r\nhttp://upload.wikimedia.org/wikipedia/commons/e/e4/EyeFixationsReading.gif\r\n\r\n2)
    Try using mongrels instead of blurring. See:\r\nhttp://www.journalofvision.org/content/9/12/13/F2.expansion.html\r\nhttp://www.journalofvision.org/content/9/12/13.full\r\n\r\n3)
    Bring your images down to text sizes rather than display sizes, and limit viewing
    time to 1/4 to 1/2 second."
  created: '2011-12-29 20:43:42'
- author:
    name: John Hudson
    picture: 110397
  body: "Peter: <em>Because at this level phonetic equivalents come on line, there
    is a phonetic disambiguation overhead problem, which requires a significant array
    of feed-back loops to solve. David Boulton in his series of interviews for his
    Children of the Code website brings this up repeatedly. Huey in 1906 thought there
    had to be an inhibition of incipient recognitions for letters for the reading
    system to work efficiently.</em>\r\n\r\nIn the case of non-phonetic spelling systems
    this does appear to present an issue, but I think it is answered by understanding
    letter recognition in a role-unit way in word recognition, i.e. the place of the
    letter within the word is crucial to efficient word recognition so may override
    potentially ambiguous phonetic associations. That is, it isn't necessary to inhibit
    incipient letter recognition per se if one readily inhibits phonetic associations
    by filtering based on the letter role within the word. By the time one has recognised
    letters and correctly identified their place in the word, one is at the word recognition
    stage, and phonetic association is something that I would consider a bypassed
    mechanism, something to which the reader falls back in the case of unfamiliar
    words."
  created: '2011-12-29 20:56:59'
- author:
    name: enne_son
    picture: 109487
  body: John, there are other things that could be brought to the table, but this
    will do for now, at least for me on this tangent.
  created: '2011-12-29 21:09:15'
- author:
    name: hrant
    picture: 110403
  body: "> http://upload.wikimedia.org/wikipedia/commons/e/e4/EyeFixationsReading.gif\r\n\r\nCool.\r\nWhy
    only lateral though?\r\n\r\n> Try using mongrels instead of blurring.\r\n\r\nI'd
    love to. Photoshop filter?  :-)\r\n\r\nBTW it's important to realize that the
    blurring\r\nI show there is... allegorical - it's really the idea\r\nof loss of
    acuity that counts. And since that page\r\nis for laymen I don't mind that simplification.\r\n\r\nYou
    might have noted another simplification there:\r\nI'm saying that whole words
    are taken in instead of\r\nletters, while in fact I believe that clusters of\r\nletters
    (so parts of words) are the typical bouma.\r\n\r\n> Bring your images down to
    text sizes rather\r\n> than display sizes, and limit viewing time\r\n> to 1/4
    to 1/2 second.\r\n\r\nThat actually can't work - and I don't just mean practically.\r\nTaking
    conscious action is based on conscious understanding,\r\nnot actual experience.
    Think for example of how electron orbits\r\nare shown; in really it's nothing
    like that.\r\n\r\nhhp\r\n"
  created: '2011-12-29 21:31:23'
- author:
    name: k.l.
    picture: 110875
  body: "hhp \u2013 <cite>The subconscious brain ...</cite>\r\n\r\nI think '<em>un</em>conscious'
    would have done the job while avoiding a specific theory. (Left <em>Inception</em>
    for an overdose of 'subconscious'.)"
  created: '2011-12-29 22:16:39'
- author:
    name: John Hudson
    picture: 110397
  body: I had the same thought, Karsten, and have rumbled with Hrant over his use
    of 'subconscious' in the past.
  created: '2011-12-29 22:24:08'
- author:
    name: hrant
    picture: 110403
  body: "Really? To me \"unconscious\" sounds too much like being knocked out...\r\nBut
    OK, let me read up some terminology and get back to you.\r\n\r\nhhp\r\n"
  created: '2011-12-29 22:32:35'
- author:
    name: enne_son
    picture: 109487
  body: "For information on how the mongrels are done, you'll have to consult the
    text of the paper in the link I provided, or the authors.\r\n\r\nBy keeping the
    display size and the unlimited timing you give a false impression of what's possible
    to gather in parafoveal vision. Using a line of mongrels keyed to distance from
    the fixation point, and a limited time window, will give you and the layman a
    much better simulation of what parafoveal vision allows. Your explanation sounds
    reasonable given your misleading simulations, and in the absence of exposure to
    the burgeoning literature on the effect of crowding in parafoveal vision.\r\n\r\nI'll
    stick to my version of when and why eye movements occur:\r\nhttp://typophile.com/node/88563?page=2#comment-489660"
  created: '2011-12-29 22:43:34'
- author:
    name: hrant
    picture: 110403
  body: "> By keeping the display size and the unlimited timing you give a\r\n> false
    impression of what's possible to gather in parafoveal vision.\r\n\r\nWithout both
    of those things I couldn't give <em>any</em> impression.\r\nShould I give a caveat
    to that effect? Maybe. But I still think\r\nthe main idea I'm trying to convey
    is being communicated.\r\n\r\n> Using a line of mongrels keyed to distance from\r\n>
    the fixation point, and a limited time window\r\n\r\nBut I assume you mean mongrels
    <em>at</em> the fixation point.\r\nWith this I agree (I just don't have the means).
    However\r\ngiving people limited time simply cannot work to convey\r\nanything
    more than a \"Huh?\".\r\n\r\nRemember, I'm not running an experiment (although
    that\r\ndoes have some merit), I'm trying to explain something to\r\npeople's
    consciousness.\r\n\r\nFrom that previous post:\r\n> The reason why some words
    are skipped and why the next saccade\r\n> will go to the n+2 word instead is because
    of the anticipatory\r\n> structure of sense-following which seems to be oriented
    to\r\n> bringing substance words into view.\r\n\r\nOK, could you explain this
    in long/simpler form?\r\n\r\nhhp\r\n"
  created: '2011-12-29 22:55:35'
- author:
    name: hrant
    picture: 110403
  body: "OK, I'll make you a deal: I'll switch to \"unconscious\" as\r\nsoon as somebody
    finds a good replacement for \"stroke\".  :-)\r\n\r\nhhp\r\n"
  created: '2011-12-29 23:00:28'
- author:
    name: enne_son
    picture: 109487
  body: "[Hrant] <em>However giving people limited time simply cannot work to convey\r\nanything
    more than a \"Huh?\"</em>\r\n\r\nExactly! It will provide an accurate simulation
    of the problem parafoveal vision faces. The \"Huh?\" is why the thing needs to
    be brought into foveal vision where it will appear in unscrambled view.\r\n\r\n[Yes,
    mongrels at the fixation point.] \r\n[A longer simpler explanation of what I mean
    by the anticipatory structure of sense-following will have to wait. I has to do
    with semantic and syntactic expectations.]\r\n\r\n"
  created: '2011-12-29 23:17:47'
- author:
    name: hrant
    picture: 110403
  body: "> The \"Huh?\" is why the thing needs to be brought into\r\n> foveal vision
    where it will appear in unscrambled view.\r\n\r\nBut that's not my version. No
    matter what it looks like the stuff\r\nis being jumped over, without loss of meaning.
    So I think the brain\r\ncan figure out the mongrels* (up to a point). Remember,
    boumas\r\ndon't have to be made of letters. Hmmm, it's actually pretty cool to\r\nthink
    there might be a secret dictionary of symbols that our brain\r\naccumulates and
    processes in order to read.\r\n\r\n* Assuming they're even real.\r\n\r\nhhp\r\n"
  created: '2011-12-29 23:25:48'
- author:
    name: enne_son
    picture: 109487
  body: "<em>But that's not my version.</em>\r\n\r\nI know.\r\n\r\n<em>No matter what
    it looks like the stuff is being jumped over, without loss of meaning.</em>\r\n\r\nAccording
    to the Keith Rayner review, by and large only \u201Cfunction\u201D words are skipped,
    not \u201Ccontent\u201D words, and even those, only about 25 percent of the time.
    What\u2019s skipped is skipped because in these instances coarse featural coding
    has provided in enough information about what's there to make full visual word-form
    resolution unneccessary. The same can not be said for the new word that gets fixated
    in.\r\n\r\n<em>Assuming they're even real.</em>\r\n\r\nTo make a judgment about
    that, you'll need to read the Balas paper."
  created: '2011-12-30 00:43:56'
- author:
    name: hrant
    picture: 110403
  body: "With my contention being that there's no qualitative difference\r\nbetween
    function words and content words, it's just that the\r\nmuch lower absolute and
    contextual frequencies of the latter\r\nrequire more experience, more foveal proximity
    and more\r\ndistinctive boumas to be saccaded over.\r\n\r\nhhp\r\n"
  created: '2011-12-30 00:52:53'
- author:
    name: enne_son
    picture: 109487
  body: "[Hrant] <em>it's just that the much lower absolute and contextual frequencies
    of the latter require more experience, more foveal proximity and more distinctive
    boumas to be saccaded over.</em>\r\n\r\nThe last two conditions sound like Hangul.
    Are Hangul words saccaded over?"
  created: '2011-12-30 01:38:50'
- author:
    name: hrant
    picture: 110403
  body: "I don't know. Certainly looking at how some key non-\r\nLatin scripts are
    read would provide invaluable clues.\r\n\r\nhhp\r\n"
  created: '2011-12-30 01:48:33'
- author:
    name: "T\xE9 Rowan"
    picture: 121227
  body: A replacement for 'stroke'? Hmm... A 'bullet' seems to be quite common.  :-|
  created: '2011-12-30 14:54:30'
- author:
    name: John Hudson
    picture: 110397
  body: "Hrant: <em>With my contention being that there's no qualitative difference
    between function words and content words, it's just that the much lower absolute
    and contextual frequencies of the latter require more experience, more foveal
    proximity and more distinctive boumas to be saccaded over.</em>\r\n\r\nIt's a
    reasonable hypothesis that frequency accounts for the bias for skipping function
    words, but I wouldn't rule out their role as a factor. By function words, I understand
    syntactically functional words, i.e. those that organise the sense of an utterance.
    Since there is a limited number of syntactical organisations of sense, and these
    are quite regular in languages such as English that have fairly consistent word
    ordering and heavy reliance on function words -- contra languages with extensive
    noun declension, flexible word order, and agglutination --, it seems to me quite
    likely that we can often skip perception of function words because our brains
    fill in the syntax readily and accurately."
  created: '2011-12-30 19:53:37'
- author:
    name: John Hudson
    picture: 110397
  body: "Hrant: <em>I'll switch to \"unconscious\" as soon as somebody finds a good
    replacement for \"stroke\".</em>\r\n\r\nI think it's possible to take 'stroke'
    as a metaphor, rather than accepting the stroke as a theory, but I understand
    your desire for an alternative. Tim Donaldson just says 'line', but that seems
    to me to fail to capture the sense of area of the black, and perhaps suggests
    something to you too much like a skeleton. The best descriptive alternative I
    can come up with is too much of a mouthful: bounded structural element."
  created: '2011-12-30 20:18:01'
- author:
    name: enne_son
    picture: 109487
  body: "[John] <em>bounded structural element</em>\r\n\r\nNice!\r\n\r\nMy <em>role-unit</em>
    is, and has always been, a \u201Cbounded structural element\u201D of an intermediate
    complexity somewhere between simple features and letter wholes. Role units are
    prototypical structures, not literal shapes.\r\n\r\nI used to use just <em>role</em>,
    and got terms like <em>role-architecture</em> and <em>role-architecturally evoked
    form</em> from that. Bill Berkson suggested I use <em>role-unit</em> instead.\r\n\r\nI
    picked up <em>role</em> from Douglas Hofstadter\u2019s 1982 \u201CMetafont, Metamathematics,
    and Metaphysics: Comments on Donald Knuth's Article \u2018The Concept of a Meta-Font\u2019\u201D.
    For Hofstadter, roles can be filled in different ways. For example an old-style
    a fills the a bowl-role in a different ways than a didoni a.\r\n\r\nFor the introduction
    of the term <em>role</em> into typographic discourse, see: Hofstadter, Douglas
    R., \u201CMetafont, Metamathematics, and Metaphysics: Comments on Donald Knuth's
    Article \u2018The Concept of a Meta-Font\u2019\u201D <em>Visible Language</em>,
    Vol. XVI no. 4, pp. 309-338 (republished in Hofstadter's book Metamagical Themas,
    NY: Basic Books, 1985)\r\n\r\nA manuscript version is available here:\r\nftp://ftp.cs.indiana.edu/pub/techreports/TR136.pdf"
  created: '2011-12-30 21:51:50'
- author:
    name: enne_son
    picture: 109487
  body: "John, earlier I said:\r\nthe visual system\r\n(1) breaks stimulus words down
    into oriented lines and curves, to the point where\r\n(2) responsiveness to aspect,
    closure and expressedness accumulates and\r\n(3) resolution or \u2018quantization\u2019
    into role-units occurs.\r\n\r\nFor (1) let's say instead that in the context of
    edge detection and the detection of surface polarity the visual system binds to
    this information from the coding of feature primitives such as orientation, linearity
    and curvature, to the point where [\u2026]\r\n\r\nIf your \u201Cbounded structural
    elements\u201D are my \u201Crole-units,\u201D can we agree that (1) through (3)
    descibe the first stages of visual word-form resolution?\r\n\r\nIn other words,
    can we agree that these terms are not simply descriptive conveniences, but might
    also represent the elemental units of processing."
  created: '2012-01-03 16:34:12'
- author:
    name: enne_son
    picture: 109487
  body: "Hrant, about the \u201Cwell-documented and widely accepted constraints on
    parafoveal vision,\u201D which you thought \u201Cmight be the result of poor testing,\u201D
    see this just-released and, by the looks of it, comprehensive paper: \u201CPeripheral
    vision and pattern recognition: A review,\u201D by Hans Strasburger, Ingo Rentschler,
    Martin Ju\u0308ttner\r\n\r\nhttp://www.journalofvision.org/content/11/5/13.abstract?etoc"
  created: '2012-01-03 16:56:12'
date: '2011-12-24 00:14:41'
node_type: forum
title: Defining notan's edge

---
