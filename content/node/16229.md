---
author:
  name: ebensorkin
  picture: 109987
body: "This may be pretty obvious but I am not sure...\r\n\r\nAre some glyphs rendered
  useless in Open type?\r\n\r\nFor instance, the standard 'macintosh roman' glyph
  set has 'macron' or '00AF' in unicode.\r\n\r\nThis glyph would be combined with
  another glyph (perhaps a 'U') to create a combined letter in the pre-Unicode world.\r\n\r\nHowever,
  in Unicode you can actually incude all the glyphs as fully formed or complete single
  glyphs. \r\n\r\nSo does this mean that 'macron' is not needed anymore - at least
  in an Open type font that includes all the instances of macron use you want to support?\r\n\r\nOr
  are there any arguements for keeping 'macron'? \r\n\r\nDo you for instance, need
  it on some keyboards and/or OSs to invoke the new complete Unicode glyph?\r\n\r\nFor
  bonus points, how do you safely add glyphs from additional code areas in fontlab?
  Having re-read the documentation I am still feeling oddly sqeamish.\r\n"
comments:
- author:
    name: Mark Simonson
    picture: 110448
  body: "You never know what users may want to do. For example, there is no such Unicode
    point for \"ndieresis,\" and yet, you have no doubt seen this:\r\n\r\n[img:sites/default/files/old-images/SpinalTapLogo.jpg]\r\n\r\n<em>how
    do you safely add glyphs from additional code areas in fontlab? </em>\r\n\r\nSimple.
    Select \"Unicode ranges\" mode in the font window, choose a code range from the
    pop-up menu and start adding glyphs."
  created: '2005-11-14 03:12:25'
- author:
    name: WurdBendur
    picture: 110861
  body: "When writing about diacritics like the macron (\xAF) or others, it may be
    necessary to show them without combining them. This is especially useful in educational
    texts on languages.\r\n\r\nI always make sure to include any non-combining diacritics
    in my fonts primarily for this purpose."
  created: '2005-11-14 06:37:53'
- author:
    name: John Hudson
    picture: 110397
  body: "The macron and other accent characters in the Mac Roman and other 8-bit codepages
    are spacing characters. In other words, they are not meant to be combined with
    base letters, and have advanced widths greater than zero. Proper combining mark
    characters are in the Unicode 0300 block, and are zero-width characters that can
    be combined on base letters or in mark stacks. A non-combining mark is canonically
    equivalent in Unicode to the space character plus a combining mark, so either
    method is accepted to display the mark without a visible base.\r\n\r\nNot all
    combinations of base + mark are separately encoded in Unicode; indeed, most are
    not. The expectation is that combining marks will be used with base characters
    to form additional diacritic combinations, using OpenType GPOS <mark> and <mkmk>
    features to correctly position the marks.\r\n\r\nIn the interests of processing
    efficiency, if text contains e.g. A plus a combining acute character, and the
    font used includes the precompose Aacute character, this will be autuomatically
    mapped on Windows in applications using the Unscribe text processor. This is a
    buffered character level mapping, which is faster than glyph level mapping in
    the <ccmp> layout feature or GPOS mark positioning,"
  created: '2005-11-14 07:44:23'
- author:
    name: ebensorkin
    picture: 109987
  body: "Mark, that quip kept me laughing for way too long. Thanks for the reasurance.
    Can I go back to Names mode afterwards? Or is that unimportant, because it's just
    a 'lens' for viewing whatever glyphs are there in the font?\r\n\r\nJoseph, that's
    a good point.\r\n\r\nJohn, that was the complete kind of explanation I was hoping
    for! Thanks very much! I wondered if the old ways were granfatherered in. But
    you mean \"Not all combinations \" rather than \"Note all\" - right?"
  created: '2005-11-14 08:43:36'
- author:
    name: John Hudson
    picture: 110397
  body: Yes. Duly edited. Witness the dangers of tired people typing after several
    glasses of wine.
  created: '2005-11-14 11:34:54'
- author:
    name: Mark Simonson
    picture: 110448
  body: "<em>Can I go back to Names mode afterwards? Or is that unimportant, because
    it\u2019s just a \u2018lens\u2019 for viewing whatever glyphs are there in the
    font?</em>\r\n\r\nThere are some situations where having it set to Names mode
    makes a difference when generating a TrueType font. I'm not sure if there are
    similar issues with Unicode Range mode. I generally leave mine set to Codepage
    mode."
  created: '2005-11-14 13:17:14'
- author:
    name: twardoch
    picture: 110427
  body: "Mark, \r\n\r\nfor OpenType fonts, there is no difference at all when generating
    fonts in Unicode or Codepage mode. Only Names mode matters in FontLab 4.6, but
    matters far less in FontLab Studio 5. \r\n\r\nJohn, \r\n\r\n> if text contains
    e.g. A plus a combining acute \r\n> character, and the font used includes the
    \r\n> precompose Aacute character, this will be \r\n> autuomatically mapped on
    Windows in \r\n> applications using the Unscribe text \r\n> processor. \r\n> This
    is a buffered character level mapping, \r\n> which is faster than glyph level
    mapping \r\n> in the layout feature or GPOS mark positioning,\r\n\r\n...but which
    will only work on one particular operating system that supports OpenType layout
    features. Cocoa in Mac OS X needs the \"ccmp\" feature to correctly render canonically
    decomposed text. Adobe applications currently don't do anything (neither apply
    ccmp nor character-level composition) but this may change in future. \r\n\r\nAdam"
  created: '2005-11-14 16:00:07'
- author:
    name: Mark Simonson
    picture: 110448
  body: "<em>for OpenType fonts, there is no difference at all when generating fonts
    in Unicode or Codepage mode. Only Names mode matters in FontLab 4.6, but matters
    far less in FontLab Studio 5.</em>\r\n\r\nThat's what I thought. I have always
    found this sometimes dependency on current glyph viewing mode to be irksome. It
    has fostered a certain superstitiousness in my use of FontLab. Good to know this
    has been addressed in FLS5. Can't wait for the Mac version."
  created: '2005-11-14 16:19:49'
- author:
    name: .
  body: "Indeed, all accents should be available to users to roll their own - with
    some kerning - versions of non-standard accents. Although the ndieresis which
    Mark mentions is necessary for the setting of Malagasy, the language of Madagascar,
    which is why I have it in my glyphset.\r\n\r\nThis site is a very useful tool
    for type types:\r\nhttp://www.eki.ee/letter/\r\n\r\nThanks to OpenType, \"Obsolescence
    is obsolete\"; all of the old stuff can sit alongside the new."
  created: '2005-11-14 18:21:44'
- author:
    name: Si_Daniels
    picture: 110446
  body: "An in production version of TNR showing combining mark positioning via OpenType.
    I've turned on Word's coloured diacritics feature so the marks (in particular
    combining ogonek) show up.  \r\n\r\n[img:sites/default/files/old-images/otcombiningmarks.jpg]\r\n\r\n[img:sites/default/files/old-images/otcombiningmarks2.jpg]"
  created: '2005-11-14 18:59:04'
- author:
    name: hrant
    picture: 110403
  body: "That \"d\" is a Vietnamese kickboxer overdosing.\r\n\r\nhhp\r\n"
  created: '2005-11-14 19:08:41'
- author:
    name: John Hudson
    picture: 110397
  body: "<em>Indeed, all accents should be available to users to roll their own -
    with some kerning...</em>\r\n\r\nAck! This is how we used to do it, but mark positioning
    really should be independent of kerning. If you kern a mark over a base, then
    you need to positively kern the mark to the next base to restore the spacing between
    the bases. It's a mess, and if the user applies tracking you are screwed.\r\n\r\nFor
    this was GPOS mark positioning invented, and you should hammer on your favourite
    app developers until the lazy buggers support it."
  created: '2005-11-15 01:11:41'
- author:
    name: John Hudson
    picture: 110397
  body: "Dropping the dot from the i in Sp\u0131n\u0308al Tap to emphasise the m\xEBt\xE4l
    umlaut was genius. I think I'll make this a contextual lookup in all my fonts
    from now on...\r\n\r\ni -> dotless i\r\nS p | n dieresisiscomb a l space T a p"
  created: '2005-11-15 01:16:01'
- author:
    name: dezcom
    picture: 109959
  body: "Looks like you've tapped into a new realm :-)\r\n\r\nChrisL"
  created: '2005-11-15 02:26:14'
- author:
    name: Mark Simonson
    picture: 110448
  body: Great idea, John! Every OT font should have that feature. :-)
  created: '2005-11-15 02:47:19'
- author:
    name: Si_Daniels
    picture: 110446
  body: "Perhaps we should get this over with now... eleven things the Spinal Tap
    font should have. I'll start you off...\r\n\r\n11. Ligature for the number '11'
    \r\n10. contextual glyphs that form Stonehenge when typed.\r\n9. a \"None more
    black\" weight.   \r\n\r\ner, actually this isn't such a good idea. Forget the
    whole thing.\r\n\r\nSi\r\n\r\n"
  created: '2005-11-15 04:54:37'
- author:
    name: ebensorkin
    picture: 109987
  body: "Since some OS's will automatically build some combinations of of roman letters
    and diacritics some of the time  ( if you use the fontlab anchor technique ) ;
    but not all OSs do it ...\r\n\r\nIs there any point in making ligature features
    ( liga ) for combinations to make things a bit easier for typists? I don't mean
    inventing new custom glyphs - just using 'liga' to point to the correct & intended
    Unicode glyph.\r\n\r\nIt would be pretty easy to do in the font itself - but would
    it help? \r\n\r\nIt could be complicated.\r\n\r\nFor instance, do Polish keyboards
    offer all the ogonek combinations as single characters? Or is there an one ogonek
    to combine with the other letters? Or some mixture? If there is an just the one
    ogonek then 'ligatures' or rather using the liga feature might make sense. Unless
    you could rely on the OS to do it. Which it sounds like you can't really do -
    yet.\r\n\r\nWhat about other languages and other diacritics? What's true for one
    diacritic in one case may not be for the next. Or for that same diacritic may
    be treated differently in another language's keyboard.\r\n\r\nWhen an OS handels
    this do you type the letters first & then the diacritic/accent? Or the other way
    round? And is that true in all languages & in all OSs?\r\n\r\nAnd when an OS does
    automatically combine a given set of letters & diacritics for you; would a liga
    feature conflict with that OS's type handeling feature? Could reversing the order
    of input ( diacritic & then letter or the reverse) allow both to co-exist?"
  created: '2005-11-19 09:36:37'
- author:
    name: .
  body: "Eben,\r\nyou should definitely spend some time with the Unicode table PDFs,
    as well as checking out the sites devoted to The World of Diacritics. I spend
    a lot of time on these sites:\r\nhttp://www.unicode.org/charts/\r\nhttp://www.eki.ee/letter/\r\nhttp://diacritics.typo.cz/index.php?id=1\r\n\r\nThere
    are Unicode indices for hundreds of accented glyphs, and different keyboard layouts
    map to accents differently, but the usual way things work is request accent, then
    request letter, which triggers the single glyph \"letteraccent\". \r\n\r\nWhich
    is why you can't just ask for a di(a)eresis + n to get the ndieresis accent needed
    for Spinal Tap: that glyph isn't mapped to a Unicode index, and system sotware
    doesn't recognise this as a valid combination. Hell, even with REAL accents, like
    lacute (uni013A), you can't use your U.S. keyboard layout and ask for an acute
    with an l under it. (This glyph is used in Slovak, and is supported by the 8859-2
    character map.)\r\n\r\nAnother reason not to try to make accented glyphs using
    liga is that some accents come in a few different forms. Adam very kindly showed
    me how one should make ogoneks, and the \"standard\" ogonek one uses in a sans
    font is usually too wide for the I and i, so you have to tweak.\r\n\r\nYet another
    reason: Tracking. When you track text in InDesign - by request or as a function
    of justified setting - at a certain point the ligas will \"split\" back into their
    component parts. Otherwise it would look silly. (I'm sure we've all seen loosely
    tracked text with fi and fl ligatures, which look like little siamese twins...)
    One exception to this rule is the Dutch \"ij\", which is actually a descendent
    of ydieresis, and is always a single character, even when tracked. Here's the
    sign for the local butcher:\r\nS  L  A  G  E  R  IJ\r\n\r\nAs always when developing
    type, you have to follow certain conventions, and you have to follow the standards.
    Not because slavishness is good, but because software and wetware (aka \"users\")
    know how to do things one way, and you shouldn't ask them to learn a new way of
    doing things just for your font. Build your types to be out-of-the-box usable
    by anyone, and if you have \"special\" functionality, make it available for expert
    users."
  created: '2005-11-19 18:39:07'
- author:
    name: John Hudson
    picture: 110397
  body: "Eben, no you would not use the 'liga' feature to access precomposed diacritic
    glyphs from base + combining mark sequences, you would use the 'ccmp' feature,
    which is designed for this purpose. I would include 'ccmp' feature lookups for
    all precomposed diacritic glyphs in the font, despite the fact that some applications
    may use character level composition for diacritics with their own Unicode values.
    This provides fallback for an application that supported 'ccmp' but did not do
    such character level processing. Of course, 'ccmp' must be used for any diacritic
    glyph that does not have its own Unicode value.\r\n\r\n'liga' is a bad idea for
    diacritic composition because the user can turn it off. 'rlig' would be better
    in that regard, but 'ccmp' is expressly designed for this purpose (and can also
    be used for glyph decomposition)."
  created: '2005-11-19 19:43:43'
- author:
    name: twardoch
    picture: 110427
  body: "John, \r\n\r\nI think your message got somehow truncated. \r\n\r\nChester,
    \r\n\r\nthe legitimate way of encoding an \"n with tilde\" is to use \"n\" followed
    by the \"combining tilde\". The layout system should take care of the proper rendering
    of that combination -- either by appropriately positioning the tilde over n, or
    by substituting the sequence by a precomposed glyph. \r\n\r\nThis is discussed
    in my article: \r\nhttp://groups.msn.com/fontlab/tipsandtricks.msnw?action=get_message&mview=0&ID_Message=3403\r\n\r\nThe
    appropriate feature for that use is \"ccmp\", not \"liga\". \r\n\r\nRegards, \r\nAdam\r\n\r\n"
  created: '2005-11-22 01:01:05'
- author:
    name: John Hudson
    picture: 110397
  body: "<em>I think your message got somehow truncated.</em>\r\n\r\nOh yes, so it
    did. I have fixed it now. I keep forgetting that Typophile treats anything withing
    pointy brackets as HTML. Which is a Very Annoying Thing."
  created: '2005-11-22 03:13:13'
- author:
    name: .
  body: "Thanks for clarifying, Adam. Of course one doesn't use liga for accented
    glyphs; I was responding to Eben's question, although your article is complete
    and trumps my little comment all to heck.\r\n\r\nWhich raises a point: the E with
    acute and dotbelow which is needed for Yoruba should get a Unicode index ASAP,
    as should n with dieresis. As should every accented glyph used in every language.
    (Proper languages, that is. Not Klingon.)\r\n\r\nIn the meantime, we should assign
    such glyphs private use area Unicode indices so that they can be accessed the
    annoying way in a pinch.\r\n\r\nMy fiftieth of a dollar."
  created: '2005-11-22 03:29:57'
- author:
    name: ebensorkin
    picture: 109987
  body: Thanks everybody!
  created: '2005-11-22 04:01:45'
- author:
    name: Thomas Phinney
    picture: 128358
  body: "<cite>Which raises a point: the E with acute and dotbelow which is needed
    for Yoruba should get a Unicode index ASAP, as should n with dieresis. As should
    every accented glyph used in every language.</cite>\r\n\r\nActually, that would
    go against one of the principles of Unicode. Unicode explicitly says that they
    only encode precomposed accented glyphs for purposes of compatibility with existing
    standard encodings. For all such combinations outside of common/standard encodings,
    they expect dynamic composition of accented characters.\r\n\r\nRegards,\r\n\r\nT"
  created: '2005-11-23 04:28:27'
- author:
    name: John Hudson
    picture: 110397
  body: 'Further to what Thomas just wrote: it is pretty much guaranteed that no more
    precomposed diacritic characters will be added to Unicode, not only for the reasons
    that Tom indicates, but also because of stability agreements with other standards
    organisations that prevent addition of any new canonical decompositions.'
  created: '2005-11-23 05:28:27'
- author:
    name: .
  body: "Sorry Yorubans! That sucks for them. And for the Malagasy. They should just
    change their orthography like the residents of Koeln and Duesseldorf have. Maybe
    the French will also drop their accents. (Yeah, right.)\r\n\r\nI guess I'm a Polyanna
    for thinking that the Unicode Consortium was actually interested in documented
    all of the written languages of the world. I though that was their goal. Silly
    me."
  created: '2005-11-23 05:32:17'
- author:
    name: John Hudson
    picture: 110397
  body: "Chester, there is no significant difference between having precomposed diacritics
    in Unicode and having sequences of bases and combining marks. Many hundreds of
    languages rely on combining mark sequences, and these languages are fully supported
    by Unicode and by Unicode-savvy systems and applications. Keyboard layouts frequently
    make the encoding model invisible to the user: he presses a key and gets \xC9\u0323
    and that gets rendered using one of several possible character->glyph options.
    He may neither know nor care whether that diacritic is encoded as one, two or
    three characters.\r\n\r\nThe only reason there are <em>any</em> precomposed diacritic
    characters in Unicode is for one-to-one backwards compatibility with pre-existing
    character set standards which, unsurprisingly, happen to be mainly for majority
    writing systems of industrialised nations. But if you take into account some of
    the Unicode normalisation forms, even these writing systems may end up being largely
    encoded using combining mark sequences in future. The W3C consortium, for example,
    recommends a normalisation form that involves canonical decomposition, so it is
    quite likely that future browsers and XML document handlers will break down even
    common European diacritics like \xE9 into e plus combining acute.\r\n\r\nNormalisation
    is the process of determining a standard encoding for character clusters that
    could be encoded in multiple ways. That \xC9\u0323 diacritic, for instance, could
    be encoded in three different ways: \u20390045, 0323\u203A, \u203900C9, 0301,
    0323\u203A or \u203900C9, 0323, 0301\u203A, all of which should be rendered identically
    and all of which have totally equivalent semantics for the reader. But if you
    want to search, sort or compare text strings, it is essential that a single canonically
    correct, normalised order is used to encode \xC9\u0323, and for this purpose fully
    decomposed combining mark sequences are highly desirable. From a text processing
    perspective, combining mark sequences are actually preferable to precomposed diacritic
    characters, since the latter need to be decomposed for the most efficient normalisation."
  created: '2005-11-23 07:13:56'
- author:
    name: twardoch
    picture: 110427
  body: "In addition to what Tom and John wrote, I should mention that adding new
    precomposed characters has one more disadvantage: if you add a single codepoint,
    say for the Yoruba E with acute and dot below, then for all existing applications
    and systems that use older versions of the Unicode Standard, the codepoint is
    just an opaque codepoint with no meaning. At best, they will recognize that it's
    a letter at all but will no nothing about a resonable sorting order or the mapping
    between a lowercase and the uppercase variant. If you encode the character in
    the normal (decomposed) way, then even older applications will know that we are
    talking about a Latin E with a bunch of diacritics. Even if they won't necessarily
    know it's Yoruba, they'll be able to infer many more properties that from a new
    precomposed codepoint. For example, an application will most likely sort the word
    starting with such character somewhere after the plain \"E\", it will figure out
    that the lowercase counterpart is \"e\" followed by the respective diacritics
    etc. \r\n\r\nTypesetting applications should take care of the correct presentation
    and of the fact that the character should be treated as one character and not
    three when moving cursor, selecting text, counting letters etc. This has nothing
    to do with the way the text is encoded. \r\n\r\nAdding more codepoints to Unicode
    will not help Yoruba -- on the contrary, it will marginalize it more!  \r\n\r\nRegards,
    \r\nAdam\r\n\r\n"
  created: '2005-11-23 14:12:17'
date: '2005-11-14 01:52:36'
title: Are some glyphs rendered useless in Open type?

---
